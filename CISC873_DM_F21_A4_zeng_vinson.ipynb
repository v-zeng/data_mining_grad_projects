{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1oe-B0jEKhWXu--vySXe9m_STIoeA57ME",
      "authorship_tag": "ABX9TyNTbkGj9Wg2tCqEDg3yOuci",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "a13cd4b243c14db2a2f0a1db8894d745": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_6ad13ebb799a4c5cbbcab3fae6334aef",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_a808705a49f340dda708acf6e57c8f64",
              "IPY_MODEL_1bfc8bdf42984aab9344006a749ad934",
              "IPY_MODEL_c424e0e403c94721a71894c77d16402f"
            ]
          }
        },
        "6ad13ebb799a4c5cbbcab3fae6334aef": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "a808705a49f340dda708acf6e57c8f64": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_e434dbe7e30745eb8842b77ea9d8725a",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_0d42ef78f0ac4cdfb4198b602dec4cbb"
          }
        },
        "1bfc8bdf42984aab9344006a749ad934": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_84e2eccff09745749af22884c2fc3ca9",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 7627,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 7627,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_266688e267ff42718a0abdb158c88d05"
          }
        },
        "c424e0e403c94721a71894c77d16402f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_75536ee9b2f847a5bcbc255551652060",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 7627/7627 [01:23&lt;00:00, 100.80it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_d1cf9bcda02f4986ae84517ff34a24de"
          }
        },
        "e434dbe7e30745eb8842b77ea9d8725a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "0d42ef78f0ac4cdfb4198b602dec4cbb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "84e2eccff09745749af22884c2fc3ca9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "266688e267ff42718a0abdb158c88d05": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "75536ee9b2f847a5bcbc255551652060": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "d1cf9bcda02f4986ae84517ff34a24de": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "bb3ad7b268244b4394df87e525dc4bbb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_bd477c19cd614db796ab3c9d1e62f897",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_f9bd25f5f4ea43a09f794cf88713d6bb",
              "IPY_MODEL_bdd0a0acc53a4d458fe453bb2f58660d",
              "IPY_MODEL_ca8d959a71864499b47a85f8c90d10ee"
            ]
          }
        },
        "bd477c19cd614db796ab3c9d1e62f897": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "f9bd25f5f4ea43a09f794cf88713d6bb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_78600874db2b42c3801236eda0e38fde",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_e49b646ab783411eaa40b8d5b7b796cc"
          }
        },
        "bdd0a0acc53a4d458fe453bb2f58660d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_97ce20dfb4294627a689b72b299c5010",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 7360,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 7360,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_97036f624c634e4080fd8d3848db5f1f"
          }
        },
        "ca8d959a71864499b47a85f8c90d10ee": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_ed54be9780c241a0b8e60909ae8a7c0c",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 7360/7360 [01:23&lt;00:00, 89.56it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_8461fcc3b70143149edd078d401f2a5e"
          }
        },
        "78600874db2b42c3801236eda0e38fde": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "e49b646ab783411eaa40b8d5b7b796cc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "97ce20dfb4294627a689b72b299c5010": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "97036f624c634e4080fd8d3848db5f1f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "ed54be9780c241a0b8e60909ae8a7c0c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "8461fcc3b70143149edd078d401f2a5e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "4481a335c5064fa485be00cff78fc2d5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_cdc36ef2a57b4ea6bf53306e543e444b",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_94eab3b2b57a4bc3b418c54b231815c1",
              "IPY_MODEL_42917ef7c44243c4b6bc6035bd770207",
              "IPY_MODEL_b4d060f50014497b9870854879d6b09a"
            ]
          }
        },
        "cdc36ef2a57b4ea6bf53306e543e444b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "94eab3b2b57a4bc3b418c54b231815c1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_60ae64b67c4b4010854063832952c46a",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_9d006100549941bb8f6c2c490f63ab62"
          }
        },
        "42917ef7c44243c4b6bc6035bd770207": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_84986ea633c44b60a04a8e11b84d075c",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 7627,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 7627,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_7aa2ea8b9eb5487f888b7090d897307d"
          }
        },
        "b4d060f50014497b9870854879d6b09a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_288f9e83b77743faa38e368c8a108502",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 7627/7627 [01:27&lt;00:00, 92.64it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_0781bb7cee294f2f9bb9296f24ca6d3d"
          }
        },
        "60ae64b67c4b4010854063832952c46a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "9d006100549941bb8f6c2c490f63ab62": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "84986ea633c44b60a04a8e11b84d075c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "7aa2ea8b9eb5487f888b7090d897307d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "288f9e83b77743faa38e368c8a108502": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "0781bb7cee294f2f9bb9296f24ca6d3d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "8f1325fb999a4a3fb445c6137f778d39": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_60e19b4d7baf4d4282b6eb1971ed8a3b",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_d14d73673b9146198c58a1a327418322",
              "IPY_MODEL_ba94280055584316b8cbbdd14ff38f55",
              "IPY_MODEL_595287a6241b4bc2a623f8de1a114996"
            ]
          }
        },
        "60e19b4d7baf4d4282b6eb1971ed8a3b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "d14d73673b9146198c58a1a327418322": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_d94089a7a91846dcb8a2a2f2992d3726",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_30c3fdfae9a34afda1220e59ae9719ef"
          }
        },
        "ba94280055584316b8cbbdd14ff38f55": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_51cde017aabc45a296c54b85bdcf446d",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 7360,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 7360,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_950318146df34ee59c366ee6c5169703"
          }
        },
        "595287a6241b4bc2a623f8de1a114996": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_65478b3bb3644eb0b55de17fa3c93c68",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 7360/7360 [01:22&lt;00:00, 88.40it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_809a90e638c64231836b829c8d260351"
          }
        },
        "d94089a7a91846dcb8a2a2f2992d3726": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "30c3fdfae9a34afda1220e59ae9719ef": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "51cde017aabc45a296c54b85bdcf446d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "950318146df34ee59c366ee6c5169703": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "65478b3bb3644eb0b55de17fa3c93c68": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "809a90e638c64231836b829c8d260351": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "08a403d348a747e382ea7e1c6efea57f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_f7b0b5a2531944748969ca929d2b1b7b",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_d13d413ddeab44819241824e829ad6ae",
              "IPY_MODEL_f3ff3fd3a5ef4d2891d31544b8880cba",
              "IPY_MODEL_b107416463c04a1d82e280cff234a222"
            ]
          }
        },
        "f7b0b5a2531944748969ca929d2b1b7b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "d13d413ddeab44819241824e829ad6ae": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_fb3c0086fe954de990d85df4b7cc502f",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_3be9b04094994bedbf15815b52c76a9f"
          }
        },
        "f3ff3fd3a5ef4d2891d31544b8880cba": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_1a626ac078ec4cc09436663a84a03bfc",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 7627,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 7627,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_29d136ddee2f488ba0e0a90befb6c9e3"
          }
        },
        "b107416463c04a1d82e280cff234a222": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_ea223011aabd4fe381830998c5d7d226",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 7627/7627 [01:27&lt;00:00, 94.38it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_a8f40631ea004e72a3b31007bfa8b2bb"
          }
        },
        "fb3c0086fe954de990d85df4b7cc502f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "3be9b04094994bedbf15815b52c76a9f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "1a626ac078ec4cc09436663a84a03bfc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "29d136ddee2f488ba0e0a90befb6c9e3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "ea223011aabd4fe381830998c5d7d226": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "a8f40631ea004e72a3b31007bfa8b2bb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "b03f02dc1c544bb19196cc5a0879d603": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_0cd6272e054e4f6090ffce4ba31fe033",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_b1462f7536e14188a46dfd538a8e7c49",
              "IPY_MODEL_60ff077cdf02446dbccd8db385f5fcc6",
              "IPY_MODEL_885ff4901c1442a69ad6870f81fdfccf"
            ]
          }
        },
        "0cd6272e054e4f6090ffce4ba31fe033": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "b1462f7536e14188a46dfd538a8e7c49": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_ebe69d7520c84e3eaa1c5985e796b037",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_bea98d320474460793f100e829f5036e"
          }
        },
        "60ff077cdf02446dbccd8db385f5fcc6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_8f402be85419472c828e1c5263882215",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 7360,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 7360,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_691e5d39b44149149640fe5d579d820a"
          }
        },
        "885ff4901c1442a69ad6870f81fdfccf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_aa5cfe60f9b84b3785ae29bf4b86d488",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 7360/7360 [01:22&lt;00:00, 88.15it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_d45c36a7c7f146a3a02bbb2df3dd5f74"
          }
        },
        "ebe69d7520c84e3eaa1c5985e796b037": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "bea98d320474460793f100e829f5036e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "8f402be85419472c828e1c5263882215": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "691e5d39b44149149640fe5d579d820a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "aa5cfe60f9b84b3785ae29bf4b86d488": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "d45c36a7c7f146a3a02bbb2df3dd5f74": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "cd0f95b3d4da4a058d7a58e8bc003a4d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_8c3c58c31c194fc8b0d9d3b28f9d06a5",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_3ccc9f966ec34c109541e2bb165d55ea",
              "IPY_MODEL_20e314fd186e44e5b86492ad6e112f87",
              "IPY_MODEL_7ccf547baa514d2d98a6c59ee53f53ee"
            ]
          }
        },
        "8c3c58c31c194fc8b0d9d3b28f9d06a5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "3ccc9f966ec34c109541e2bb165d55ea": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_beb5f587e2914ee7885ae60f992565d9",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 42%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_c7379b05b4fe48aa9fffba85c6b4dcf1"
          }
        },
        "20e314fd186e44e5b86492ad6e112f87": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_1cc5f20714cc4379b2b8d8e7ac4d3fe9",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "",
            "max": 7627,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 3211,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_d095ebec04064c05ae80e37f58f90cb7"
          }
        },
        "7ccf547baa514d2d98a6c59ee53f53ee": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_70af00e9bc6248589c53a3e3fb451a81",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 3211/7627 [00:42&lt;01:02, 70.13it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_997c2f37be984d07b650bee43732192d"
          }
        },
        "beb5f587e2914ee7885ae60f992565d9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "c7379b05b4fe48aa9fffba85c6b4dcf1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "1cc5f20714cc4379b2b8d8e7ac4d3fe9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "d095ebec04064c05ae80e37f58f90cb7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "70af00e9bc6248589c53a3e3fb451a81": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "997c2f37be984d07b650bee43732192d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "09ad639cf5954ed498906591ed5df2bf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_cac3a555a5e645fa8cd528e300de5d15",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_ae9ccce96a6746f881a6821d056d3b93",
              "IPY_MODEL_c8cbd4c7e9ed407fb9fe384bfa75a4fa",
              "IPY_MODEL_35124d8919404b5c9920ddd3d849703b"
            ]
          }
        },
        "cac3a555a5e645fa8cd528e300de5d15": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "ae9ccce96a6746f881a6821d056d3b93": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_9540cede07684adc9ef01afbf20e0022",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_087fa2c7acb5470681fe6e73a2879a78"
          }
        },
        "c8cbd4c7e9ed407fb9fe384bfa75a4fa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_d1f37b2a7b8741f7a0f22ed557d94406",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 7627,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 7627,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_a193d59bc6eb41778b3eec315592425d"
          }
        },
        "35124d8919404b5c9920ddd3d849703b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_5dde69f8d6fc45b8842a612337405afd",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 7627/7627 [01:43&lt;00:00, 84.44it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_cd99cf4f380c45e097c19da2a5544fd5"
          }
        },
        "9540cede07684adc9ef01afbf20e0022": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "087fa2c7acb5470681fe6e73a2879a78": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "d1f37b2a7b8741f7a0f22ed557d94406": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "a193d59bc6eb41778b3eec315592425d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "5dde69f8d6fc45b8842a612337405afd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "cd99cf4f380c45e097c19da2a5544fd5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "9ff140905e57422cb5ca19867338be5b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_2bd9fa89e2fe411db7cdc85798d44b85",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_f24c091632944478a664420a521226f3",
              "IPY_MODEL_1c79a82c17c940d4902450220729ffa2",
              "IPY_MODEL_445590ec268840f0825631fc34f1a7b0"
            ]
          }
        },
        "2bd9fa89e2fe411db7cdc85798d44b85": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "f24c091632944478a664420a521226f3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_65dcb22151fb493e98e09a1f249ac1a0",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_b8e7bb47080b4321bb6cc40493291788"
          }
        },
        "1c79a82c17c940d4902450220729ffa2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_3c1d01dbce3b4d5e987fc22ae7a33d79",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 7627,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 7627,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_b2dbec4bc10542d3afb31539b0d70238"
          }
        },
        "445590ec268840f0825631fc34f1a7b0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_81df72c43ec942a59d3c6d4aa847a76b",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 7627/7627 [01:35&lt;00:00, 86.63it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_a172bcbef1bb4bd9b523c7d79f2bd993"
          }
        },
        "65dcb22151fb493e98e09a1f249ac1a0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "b8e7bb47080b4321bb6cc40493291788": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "3c1d01dbce3b4d5e987fc22ae7a33d79": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "b2dbec4bc10542d3afb31539b0d70238": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "81df72c43ec942a59d3c6d4aa847a76b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "a172bcbef1bb4bd9b523c7d79f2bd993": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "17dd8f70f6804bb988a3c6e1153c922a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_2fb56b53c22546b2891e7dcac88a08b1",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_c33442490c344236ada9baa8a969fe7f",
              "IPY_MODEL_f50b48791b78418cbc8da0c6f9e4b39e",
              "IPY_MODEL_00897492ec8e440c9eb4c3badfcda5e3"
            ]
          }
        },
        "2fb56b53c22546b2891e7dcac88a08b1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "c33442490c344236ada9baa8a969fe7f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_b3c0ab07c09544e28c77e05e5c366692",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_74a06df1e5714dfe9ecc65aff9387aec"
          }
        },
        "f50b48791b78418cbc8da0c6f9e4b39e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_ee46281013f8444c9f5fef7be0e63bb4",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 7360,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 7360,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_4d58a01e841543c9807f30cdb937a3ff"
          }
        },
        "00897492ec8e440c9eb4c3badfcda5e3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_ca8a629af0b4499d93c22c42bbab5e02",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 7360/7360 [01:28&lt;00:00, 84.14it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_9bb4f86196c546c0b5a729ee485f9aee"
          }
        },
        "b3c0ab07c09544e28c77e05e5c366692": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "74a06df1e5714dfe9ecc65aff9387aec": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "ee46281013f8444c9f5fef7be0e63bb4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "4d58a01e841543c9807f30cdb937a3ff": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "ca8a629af0b4499d93c22c42bbab5e02": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "9bb4f86196c546c0b5a729ee485f9aee": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "2e39a17fa8fa45a6946c9765af874bc5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_7c75261168d64c55b6bdb9c76e22d218",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_63100d8e57de4deea59629ab593c804e",
              "IPY_MODEL_1f9a17df59ec4792897b667d27828ad7",
              "IPY_MODEL_5479b9359a5641d58f1a1ca134e7e9bf"
            ]
          }
        },
        "7c75261168d64c55b6bdb9c76e22d218": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "63100d8e57de4deea59629ab593c804e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_f9138f3de0594b9f85cd35c6b0ed3370",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "  6%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_d3dc49c373ae4dd0a39fc3e72823e1a5"
          }
        },
        "1f9a17df59ec4792897b667d27828ad7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_43dd4cb4c14d496d9a9b0a8cf23c47eb",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "danger",
            "max": 7627,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 480,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_14d2eb27fdd942da927d89dafb3ed731"
          }
        },
        "5479b9359a5641d58f1a1ca134e7e9bf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_bb85c95ac7b04f34a20b8186a1c1a6ad",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 480/7627 [00:05&lt;01:23, 85.15it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_e36cdf42fcaf4585861d71e4897ac28f"
          }
        },
        "f9138f3de0594b9f85cd35c6b0ed3370": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "d3dc49c373ae4dd0a39fc3e72823e1a5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "43dd4cb4c14d496d9a9b0a8cf23c47eb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "14d2eb27fdd942da927d89dafb3ed731": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "bb85c95ac7b04f34a20b8186a1c1a6ad": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "e36cdf42fcaf4585861d71e4897ac28f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "89cac7b9da714d1b920b897e057eefba": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_aa482a22d03b4ac4bd42459eeb34890d",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_5c0c9af5dffe41209f94a2b214e90055",
              "IPY_MODEL_a871780c94c946d6aa5c09452ccc5634",
              "IPY_MODEL_3814057e7cb5465da1abb5267e03373e"
            ]
          }
        },
        "aa482a22d03b4ac4bd42459eeb34890d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "5c0c9af5dffe41209f94a2b214e90055": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_7cb37aeaeb9a44d8bfb636b264ae5a3c",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_1bb7ae4f631f4f5494fe2ac185373ebf"
          }
        },
        "a871780c94c946d6aa5c09452ccc5634": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_7c31318e42264466bf1f879191dbf9d4",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 7627,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 7627,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_0d77094de0864e4db4cc20366cc5d029"
          }
        },
        "3814057e7cb5465da1abb5267e03373e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_5d015791e3194b44a954b338e4f8ad33",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 7627/7627 [01:26&lt;00:00, 88.89it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_d655ab160cf04bff9f297b95b1636aa6"
          }
        },
        "7cb37aeaeb9a44d8bfb636b264ae5a3c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "1bb7ae4f631f4f5494fe2ac185373ebf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "7c31318e42264466bf1f879191dbf9d4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "0d77094de0864e4db4cc20366cc5d029": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "5d015791e3194b44a954b338e4f8ad33": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "d655ab160cf04bff9f297b95b1636aa6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "8325028fe578436babb486c1a255fd4b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_207f21601ea647a9acc174622f0865bc",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_277151ade0c949079bb16a3ea43ce6bc",
              "IPY_MODEL_ae63af268ef24547b438d750b663d3ce",
              "IPY_MODEL_9e33dbd4623a4e9c8ba68c3675495aa2"
            ]
          }
        },
        "207f21601ea647a9acc174622f0865bc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "277151ade0c949079bb16a3ea43ce6bc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_30e6421f20ae40b7b1a7335653781cd8",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_023ab4f5f9594b02b9319954ce053167"
          }
        },
        "ae63af268ef24547b438d750b663d3ce": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_50c6a19985474966b974f10212e8306d",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 7360,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 7360,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_4c93ff863e204f4d8d0bbdec71933d71"
          }
        },
        "9e33dbd4623a4e9c8ba68c3675495aa2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_aeff19da0ba04dc6b1bf97be1a8c9bf3",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 7360/7360 [01:28&lt;00:00, 84.56it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_94479f8ffd7743ec913107367c1e2fe3"
          }
        },
        "30e6421f20ae40b7b1a7335653781cd8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "023ab4f5f9594b02b9319954ce053167": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "50c6a19985474966b974f10212e8306d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "4c93ff863e204f4d8d0bbdec71933d71": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "aeff19da0ba04dc6b1bf97be1a8c9bf3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "94479f8ffd7743ec913107367c1e2fe3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "70fa367794724c1594e3f2ab3c1c325a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_236ab9a6304040b48c4a32fd62b559da",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_1988306b4343417b908a92283dd0b4d6",
              "IPY_MODEL_c6d23cf65b8e4822a45db67e74a897c1",
              "IPY_MODEL_fe92d03038b3417fb3e714493b7b2009"
            ]
          }
        },
        "236ab9a6304040b48c4a32fd62b559da": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "1988306b4343417b908a92283dd0b4d6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_2978afdda1a049788973fc3ab63b34d4",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_82a3eba3e87c44e7b5c294e0ce867ead"
          }
        },
        "c6d23cf65b8e4822a45db67e74a897c1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_59ca679591994e3ca492c0f8368f26ed",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 7627,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 7627,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_227c98984e7f4e1799b2ff5ed39d689b"
          }
        },
        "fe92d03038b3417fb3e714493b7b2009": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_3150738e2e1041f6a35bc290b17a1d48",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 7627/7627 [01:29&lt;00:00, 89.19it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_a7a6aeff67394352bd1022bbeb073fb3"
          }
        },
        "2978afdda1a049788973fc3ab63b34d4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "82a3eba3e87c44e7b5c294e0ce867ead": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "59ca679591994e3ca492c0f8368f26ed": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "227c98984e7f4e1799b2ff5ed39d689b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "3150738e2e1041f6a35bc290b17a1d48": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "a7a6aeff67394352bd1022bbeb073fb3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "b3ee53a8cc7f4b04bb11210c835c4622": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_3565ec3170d148aeb31b5c0e4938b8e9",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_cb5cf8df3c944dc182665d10a6f2b668",
              "IPY_MODEL_ea4a572a256340aeb998bdd7f672093a",
              "IPY_MODEL_daa11880d9114635b465d0d6ddd3117c"
            ]
          }
        },
        "3565ec3170d148aeb31b5c0e4938b8e9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "cb5cf8df3c944dc182665d10a6f2b668": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_03d3f441e5bc4515988855f497186f42",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_bb3fc2b7f69f4b75acc05c9f55173b90"
          }
        },
        "ea4a572a256340aeb998bdd7f672093a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_56354de99bc0449e8f20d37e49897789",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 7360,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 7360,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_99c7916ea52d4a53b6ac473c3edcb160"
          }
        },
        "daa11880d9114635b465d0d6ddd3117c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_5fd34dcca80a46af93b1b32bed561a2a",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 7360/7360 [01:24&lt;00:00, 86.22it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_4633b2317bd24fa8853481dfe49f658e"
          }
        },
        "03d3f441e5bc4515988855f497186f42": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "bb3fc2b7f69f4b75acc05c9f55173b90": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "56354de99bc0449e8f20d37e49897789": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "99c7916ea52d4a53b6ac473c3edcb160": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "5fd34dcca80a46af93b1b32bed561a2a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "4633b2317bd24fa8853481dfe49f658e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "01dda017f2294d4bb3f9cfad62834cab": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_f7d252205fa847a8b5264f2c93a92cf6",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_54bf1be6359e42ecb36d51d916d82006",
              "IPY_MODEL_bf0cd69b20d242769d5b03ee5506b558",
              "IPY_MODEL_80c8257dd0f7402a84bd9917ddfa45b2"
            ]
          }
        },
        "f7d252205fa847a8b5264f2c93a92cf6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "54bf1be6359e42ecb36d51d916d82006": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_2269a0bfe4e64fa19b12b2917bebcb44",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_fdcd27f77f4e450f8e827a7889ee9133"
          }
        },
        "bf0cd69b20d242769d5b03ee5506b558": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_fd7b203e301c4d3db5820939ed97b6e7",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 7627,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 7627,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_de9aadf17fd242a8b6f7589bca752896"
          }
        },
        "80c8257dd0f7402a84bd9917ddfa45b2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_aef0cbe8dcbb455e9a23cc876bbacb34",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 7627/7627 [01:25&lt;00:00, 96.20it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_998090d2982f4c1198f80cd9c1214e05"
          }
        },
        "2269a0bfe4e64fa19b12b2917bebcb44": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "fdcd27f77f4e450f8e827a7889ee9133": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "fd7b203e301c4d3db5820939ed97b6e7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "de9aadf17fd242a8b6f7589bca752896": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "aef0cbe8dcbb455e9a23cc876bbacb34": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "998090d2982f4c1198f80cd9c1214e05": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "9515901eebc141de820985958b1fb3f3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_ee848233c173467eab3235b48099d7d4",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_e39f86b535a347bab63a8e7f5b779c2e",
              "IPY_MODEL_e076a4e86d794e6f8b2ea98ab03234f0",
              "IPY_MODEL_1f8dad1bd1d14fb2a79c9b0687e0e8d1"
            ]
          }
        },
        "ee848233c173467eab3235b48099d7d4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "e39f86b535a347bab63a8e7f5b779c2e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_7a39ba0c848d4bb0a8f946f882404b34",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_b7979d21404c4a4e9aeb2ed08f81939a"
          }
        },
        "e076a4e86d794e6f8b2ea98ab03234f0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_695d8a1973bb4a8d93fe17c8a8aec828",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 7360,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 7360,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_62e3fe56c4d54331afe11ce672905470"
          }
        },
        "1f8dad1bd1d14fb2a79c9b0687e0e8d1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_4ecea144aaba4ee68ac8d753fe9ae470",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 7360/7360 [01:32&lt;00:00, 67.29it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_3379ab86840f4fa2bac188cf5bf8978c"
          }
        },
        "7a39ba0c848d4bb0a8f946f882404b34": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "b7979d21404c4a4e9aeb2ed08f81939a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "695d8a1973bb4a8d93fe17c8a8aec828": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "62e3fe56c4d54331afe11ce672905470": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "4ecea144aaba4ee68ac8d753fe9ae470": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "3379ab86840f4fa2bac188cf5bf8978c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "4eb4cc900b3d450fad02fb820028ef1d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_0200e0b685314bb6a27d565934414e87",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_0b636acd683b4f3a83ee7520f9ac0f38",
              "IPY_MODEL_502897b532234336a3e16b76888e6591",
              "IPY_MODEL_380f64a2db064adc89996d87298330a6"
            ]
          }
        },
        "0200e0b685314bb6a27d565934414e87": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "0b636acd683b4f3a83ee7520f9ac0f38": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_3e58c67d803b4c598fb4a706dd887cf4",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_c84ea6e8d91e4773939f3f88ccc7c2ae"
          }
        },
        "502897b532234336a3e16b76888e6591": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_cd0fb2a41e1b451db33cd58233a83124",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 7627,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 7627,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_806e500ec153429dabe36be7b9782e8b"
          }
        },
        "380f64a2db064adc89996d87298330a6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_72581956aa55462fb6fad7eb5c8f1ed2",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 7627/7627 [01:23&lt;00:00, 95.01it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_e105852f04da454dab04fbb78d2733f9"
          }
        },
        "3e58c67d803b4c598fb4a706dd887cf4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "c84ea6e8d91e4773939f3f88ccc7c2ae": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "cd0fb2a41e1b451db33cd58233a83124": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "806e500ec153429dabe36be7b9782e8b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "72581956aa55462fb6fad7eb5c8f1ed2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "e105852f04da454dab04fbb78d2733f9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "d6507eb078024c1ca43166c38e12b557": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_7e9a5774ffd64ac3a151f9511eb3a051",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_061b1a3ae94c4887a9dcbe863c9a9c7c",
              "IPY_MODEL_f4f2ecde492c43188ca4043bdbf414b6",
              "IPY_MODEL_93d3049ac829454cbc899955d4367908"
            ]
          }
        },
        "7e9a5774ffd64ac3a151f9511eb3a051": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "061b1a3ae94c4887a9dcbe863c9a9c7c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_b04861ea112f4fc2bb29ea9324ca3491",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_93190f8c059e435784c00c590c08c259"
          }
        },
        "f4f2ecde492c43188ca4043bdbf414b6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_11cbcc3f441b4863af24c9014dfa7712",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 7360,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 7360,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_d3934c374efc449085ff5e521b6b9c45"
          }
        },
        "93d3049ac829454cbc899955d4367908": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_9ad00219efb04b5bb06f635cd54a5f0d",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 7360/7360 [01:17&lt;00:00, 97.14it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_95910c2ecb4443baa33a75d24d2da254"
          }
        },
        "b04861ea112f4fc2bb29ea9324ca3491": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "93190f8c059e435784c00c590c08c259": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "11cbcc3f441b4863af24c9014dfa7712": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "d3934c374efc449085ff5e521b6b9c45": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "9ad00219efb04b5bb06f635cd54a5f0d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "95910c2ecb4443baa33a75d24d2da254": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "b2a249f69d494efbb9149aaa61d7a991": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_2a9782171814454aa191e1d0c73e629b",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_c9717639910845bab86d2b8c2296e5aa",
              "IPY_MODEL_f2a4a9e3e8cf42e38b095c64f9e1317f",
              "IPY_MODEL_bb086071c54141c38aa49d29163e7ead"
            ]
          }
        },
        "2a9782171814454aa191e1d0c73e629b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "c9717639910845bab86d2b8c2296e5aa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_6a40ce4671cd4b8895ac5025856b1a5f",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_9d6c81133df146a893631082e9ccfcae"
          }
        },
        "f2a4a9e3e8cf42e38b095c64f9e1317f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_6c127fd81e634012b6db2abd3030efa9",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 7627,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 7627,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_4e696ede1fab48fbbee147b2615a082b"
          }
        },
        "bb086071c54141c38aa49d29163e7ead": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_546426f7b645426db32aed99d6b51200",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 7627/7627 [01:21&lt;00:00, 109.01it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_f7441508ab0e4ab999b7fb7e34f5e623"
          }
        },
        "6a40ce4671cd4b8895ac5025856b1a5f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "9d6c81133df146a893631082e9ccfcae": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "6c127fd81e634012b6db2abd3030efa9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "4e696ede1fab48fbbee147b2615a082b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "546426f7b645426db32aed99d6b51200": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "f7441508ab0e4ab999b7fb7e34f5e623": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "60bde454b1984215bea5e51558115079": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_1d9ca7a19e024061b7145e56d059eb00",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_6f1e680bcb0749acb22cdd5bd206eea0",
              "IPY_MODEL_589a0688ecf844bfa248c9ce95585f13",
              "IPY_MODEL_b53b75c3c86b4beaaee8641c27c9bff3"
            ]
          }
        },
        "1d9ca7a19e024061b7145e56d059eb00": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "6f1e680bcb0749acb22cdd5bd206eea0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_95b732346307492ca2e0f7a8fe7e8925",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_202d432512b143bdaca921811c90271f"
          }
        },
        "589a0688ecf844bfa248c9ce95585f13": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_2887ee0f11de49bba66b17a11492be9e",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 7360,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 7360,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_fe04f5d8cb9c43df85051b7229a00e89"
          }
        },
        "b53b75c3c86b4beaaee8641c27c9bff3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_823b7d142cef4bce96b7ec44fa20e309",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 7360/7360 [01:18&lt;00:00, 92.32it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_317991a6e77c48749842e9b2192fbe0a"
          }
        },
        "95b732346307492ca2e0f7a8fe7e8925": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "202d432512b143bdaca921811c90271f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "2887ee0f11de49bba66b17a11492be9e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "fe04f5d8cb9c43df85051b7229a00e89": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "823b7d142cef4bce96b7ec44fa20e309": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "317991a6e77c48749842e9b2192fbe0a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "988292bf479c4575aff2f27c4db37201": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_4aa41749dd3141ff88c43d79914fd7c4",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_283f043765d34cbcafe926c06e7c2d13",
              "IPY_MODEL_4c820ec431f749a4ab3c39136c640803",
              "IPY_MODEL_264ee4dc926642ca8362906f269a55ac"
            ]
          }
        },
        "4aa41749dd3141ff88c43d79914fd7c4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "283f043765d34cbcafe926c06e7c2d13": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_21bc189f2cb342aa83dd822e87bd9f40",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_eade1d47febc454bbdcb12d6c86481e1"
          }
        },
        "4c820ec431f749a4ab3c39136c640803": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_c95f5667c2b946739eb7ad73c49f01ac",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 7627,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 7627,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_0e96b5325daa48cca469c88cd306d488"
          }
        },
        "264ee4dc926642ca8362906f269a55ac": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_a97bae54ddeb4f64baa87db48f1cca1b",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 7627/7627 [01:27&lt;00:00, 89.85it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_ad97b403cb894443ac7788159f7a6458"
          }
        },
        "21bc189f2cb342aa83dd822e87bd9f40": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "eade1d47febc454bbdcb12d6c86481e1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "c95f5667c2b946739eb7ad73c49f01ac": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "0e96b5325daa48cca469c88cd306d488": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "a97bae54ddeb4f64baa87db48f1cca1b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "ad97b403cb894443ac7788159f7a6458": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "b6bef90831d94fd9ab94f358ce509454": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_7355bb71e91944b7a7cac0f4c2ec666c",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_b4667ab88af24a039c6c899b1f181cb6",
              "IPY_MODEL_39a8b635ac3c423ab5eb147f1f552dd5",
              "IPY_MODEL_8c32c48b94c64b8f9280b5bf6e1177be"
            ]
          }
        },
        "7355bb71e91944b7a7cac0f4c2ec666c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "b4667ab88af24a039c6c899b1f181cb6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_fbe205f9156d46d88798bf4406179282",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_fce7621ec1234c6eaeaecb9a53286214"
          }
        },
        "39a8b635ac3c423ab5eb147f1f552dd5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_0875849edadc40a6974b6246ddf54ab4",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 7360,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 7360,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_58a5075fe5f34aa0aad91cd48440fe07"
          }
        },
        "8c32c48b94c64b8f9280b5bf6e1177be": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_629e00b6fb2848fdae5155cdee67a4a9",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 7360/7360 [01:18&lt;00:00, 94.92it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_ee6d31fedf20412b82da6af163f67060"
          }
        },
        "fbe205f9156d46d88798bf4406179282": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "fce7621ec1234c6eaeaecb9a53286214": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "0875849edadc40a6974b6246ddf54ab4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "58a5075fe5f34aa0aad91cd48440fe07": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "629e00b6fb2848fdae5155cdee67a4a9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "ee6d31fedf20412b82da6af163f67060": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "04f05b0c955444e2a9baeadcea4aa399": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_4c6513b6af48429c96d81efee9e71f7f",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_36802cbffd4b49ad9e443614f7337699",
              "IPY_MODEL_51857f3ffd32418e840d586c8a2ee1cc",
              "IPY_MODEL_27d18efda46c4a8fa769cbe91ca1cb1c"
            ]
          }
        },
        "4c6513b6af48429c96d81efee9e71f7f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "36802cbffd4b49ad9e443614f7337699": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_02b0cabb205c463b92847b8f9b2a1955",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_6d2f2642a0d84d8e81357866c7d98a24"
          }
        },
        "51857f3ffd32418e840d586c8a2ee1cc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_77a9f617469e4f0b89df655cf481fd8b",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 7627,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 7627,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_432b4c976ca54b8cbd3b701cab57aef1"
          }
        },
        "27d18efda46c4a8fa769cbe91ca1cb1c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_0a2575df909c4f6fa0d5eed8d50988d7",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 7627/7627 [01:28&lt;00:00, 99.10it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_cc804bfdc4084f2283109a492497a947"
          }
        },
        "02b0cabb205c463b92847b8f9b2a1955": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "6d2f2642a0d84d8e81357866c7d98a24": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "77a9f617469e4f0b89df655cf481fd8b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "432b4c976ca54b8cbd3b701cab57aef1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "0a2575df909c4f6fa0d5eed8d50988d7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "cc804bfdc4084f2283109a492497a947": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "44361c1f263f4514856db1be5183a05b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_a1afc3e12f234207afbd5b9ddd02dbaf",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_35ea90cc45144251b48ed4938e52a782",
              "IPY_MODEL_79778a7580b84f6fbda6a8980ec2e4e4",
              "IPY_MODEL_4a25a545adc84ceda1ae76ef5728aa09"
            ]
          }
        },
        "a1afc3e12f234207afbd5b9ddd02dbaf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "35ea90cc45144251b48ed4938e52a782": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_9c8288856d96428489eaaa1007e42e7c",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_d0700a37f2184c8b84594bfd452325a0"
          }
        },
        "79778a7580b84f6fbda6a8980ec2e4e4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_ebd675c034994808b2fa2c71a6d8f41f",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 7360,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 7360,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_1af0034a5f9b487fb324c1e01ea8c654"
          }
        },
        "4a25a545adc84ceda1ae76ef5728aa09": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_6772fa1035a04e78beab73f8d2b7cf7c",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 7360/7360 [01:24&lt;00:00, 94.02it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_fb33c5f52e9d4b2094c1b07aeee89b96"
          }
        },
        "9c8288856d96428489eaaa1007e42e7c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "d0700a37f2184c8b84594bfd452325a0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "ebd675c034994808b2fa2c71a6d8f41f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "1af0034a5f9b487fb324c1e01ea8c654": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "6772fa1035a04e78beab73f8d2b7cf7c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "fb33c5f52e9d4b2094c1b07aeee89b96": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/v-zeng/data_mining_grad_projects/blob/main/CISC873_DM_F21_A4_zeng_vinson.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s4yUSb2p7rQl"
      },
      "source": [
        "### **Airbnb price category prediction**\n",
        "\n",
        "Student: Vinson Zeng\n",
        "\n",
        "Student #: 05550960"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NcDACqcD7zYR"
      },
      "source": [
        "✔️ **Meme competition:**\n",
        "\n",
        "![](https://drive.google.com/uc?export=iew&id=16gi5Pt5Lyt1KfGnLYd_otiBBW2lVwP3v)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cLXB8ke674no"
      },
      "source": [
        "✔️ **Understand the template:**\n",
        "\n",
        "The objective is the predict a listing price for an Airbnb listing based on its characteristics from text descriptions and images. The pricing is binned into three categories for classification, beginner, plus, and premium (0, 1, 2, respectively). The image data is preprocessed by converting to grayscale and resizing to 64 by 64 pixels and then converted to a 3D array of zeros. Price and type for the listings are encoded. A vocabulary is built from the training data, in which text is tokenized and fit on the text data. Text is preprocessed by transforming to sequences and padding before it is embedded. Both image and text data concatenated before passing through dense layers with softmax activation for multi-class classification. Hyperparameter tuning for the template includes examining learning rate, choosing an optimizer and a loss function, and deciding batch size and the number of epochs. We can determine if hyperparameters are good if they decrease the losses and increase model scores with successive iterations for both training and validation.\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O5ReqNQe76mI"
      },
      "source": [
        "\n",
        "✔️ **Problem Formulation:**\n",
        "Define the problem. What is the input? What is the output? What data mining function is required? What could be the challenges? What is the impact? What is an ideal solution?\n",
        "\n",
        "The problem is multiclass classification, to classify listings as beginner (0), plus (1), or premium (2). The input is text and image data from the airbnb listings from different areas in Montreal during 2019. The function required is classification. Challenges include determining parameters and hyperparameters, the types and number of layers, adjusting for over and underfitting. Too few layers and nodes could limit the learning ability of the model and too many of either could result in overfitting and increased training time. Preprocessing is always a challenge, as garbage in = garbage out. The model would ideally be simple and efficient to keep training time down and to yield a high performing score in the form of Sparse Categorical Accuracy.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m44vjMtK9nir"
      },
      "source": [
        "✔️ Answer the questions below (briefly):\n",
        "\n",
        "**🌈What is the default model for text data in the template? Is it a good one for sequential data? Why?**\n",
        "\n",
        "The default model uses a feed-forward model. The signal/data travels one way, from input to output. It is not the best for sequential data because it may be difficult to learn anything other than a linear function. It does not retain its state while processing the next sequence of inputs. This template model processes an input and moves onto the next one disregarding its sequence. The back propagated error signal decreases or increases exponentially as a function from the end layer.\n",
        "\n",
        "**🌈What is gradient vanishing and gradient explosion, and how GRU/LSTM tries to mitigate this problem?**\n",
        "\n",
        "Vanishing gradient is when the derivative gets smaller through each layder during backpropagation Weight updates become very small and training takes longer. Exploding gradient is when the derivative gets larger with every layer during backpropagation. The gradient may never converge due to high weight values with an exploding gradient. Both GRU and LSTM essentially have memory cells, which can help to maintain the values needed through the neural network.\n",
        "\n",
        "**🌈What is multi-objective/multi-task learning?** **What is multi-modality learning?** **How this assignment fits into those paradigm?**\n",
        "\n",
        "Multi-task learning is where multiple learning tasks are solved simultaneously, while utilizing differences and commonalities across tasks. Multi-modality learning refers to relating information from multiple sources. This assignment is multi-task due to the multiple-classifications and it is multi-modal due to the text and image data.\n",
        "\n",
        "**🌈How attention mechanism can help with the learning process?**\n",
        "\n",
        "The attention mechanism emphasizes important parts of data. It identifies which parts the network should provide more processing power towards by utilizing all hidden states of the input sequence during decoding.\n",
        "\n",
        "**🌈In the template, we use early stopping. What is the purpose?**\n",
        "\n",
        "Early stopping helps to avoid overfitting. It acts as a form of regularization."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xP9hwSY0FzbS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "53ae9b14-f5d3-4d86-940c-dae728d6b3d6"
      },
      "source": [
        "# you can also download the data by running the following line (linux only)\n",
        "# if you already got the data from kaggle, you can skip this cell.\n",
        "\n",
        "! wget https://github.com/CISC-873/Information-2021/releases/download/data/a4.zip\n",
        "! unzip -q a4.zip"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2021-11-18 00:44:51--  https://github.com/CISC-873/Information-2021/releases/download/data/a4.zip\n",
            "Resolving github.com (github.com)... 140.82.114.4\n",
            "Connecting to github.com (github.com)|140.82.114.4|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://github-releases.githubusercontent.com/406495726/4d095bba-8b9b-4be4-8738-83f8ff5b0d18?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20211118%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20211118T004411Z&X-Amz-Expires=300&X-Amz-Signature=24ba7d914445811153beda9467b6928f9f47570042b8d3fd3e6875d00b9582f8&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=406495726&response-content-disposition=attachment%3B%20filename%3Da4.zip&response-content-type=application%2Foctet-stream [following]\n",
            "--2021-11-18 00:44:51--  https://github-releases.githubusercontent.com/406495726/4d095bba-8b9b-4be4-8738-83f8ff5b0d18?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20211118%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20211118T004411Z&X-Amz-Expires=300&X-Amz-Signature=24ba7d914445811153beda9467b6928f9f47570042b8d3fd3e6875d00b9582f8&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=406495726&response-content-disposition=attachment%3B%20filename%3Da4.zip&response-content-type=application%2Foctet-stream\n",
            "Resolving github-releases.githubusercontent.com (github-releases.githubusercontent.com)... 185.199.108.154, 185.199.109.154, 185.199.110.154, ...\n",
            "Connecting to github-releases.githubusercontent.com (github-releases.githubusercontent.com)|185.199.108.154|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 639078419 (609M) [application/octet-stream]\n",
            "Saving to: ‘a4.zip’\n",
            "\n",
            "a4.zip              100%[===================>] 609.47M  34.3MB/s    in 11s     \n",
            "\n",
            "2021-11-18 00:45:03 (53.3 MB/s) - ‘a4.zip’ saved [639078419/639078419]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rhLIZk2eXIAe"
      },
      "source": [
        "### **Template**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CUikIIG4XHJO"
      },
      "source": [
        "# load modules\n",
        "import os\n",
        "\n",
        "import pandas as pd\n",
        "from tqdm.notebook import tqdm\n",
        "from PIL import Image\n",
        "import pandas as pd\n",
        "import os\n",
        "import numpy as np\n",
        "\n",
        "xy_train_df = pd.read_csv('train_xy.csv') # read training data into dataframe\n",
        "x_test_df = pd.read_csv('test_x.csv') # read test data into dataframe"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "a13cd4b243c14db2a2f0a1db8894d745",
            "6ad13ebb799a4c5cbbcab3fae6334aef",
            "a808705a49f340dda708acf6e57c8f64",
            "1bfc8bdf42984aab9344006a749ad934",
            "c424e0e403c94721a71894c77d16402f",
            "e434dbe7e30745eb8842b77ea9d8725a",
            "0d42ef78f0ac4cdfb4198b602dec4cbb",
            "84e2eccff09745749af22884c2fc3ca9",
            "266688e267ff42718a0abdb158c88d05",
            "75536ee9b2f847a5bcbc255551652060",
            "d1cf9bcda02f4986ae84517ff34a24de"
          ]
        },
        "id": "omUeqnrMXHZC",
        "outputId": "6649e9b4-40a4-4c95-a657-abbe35e73b11"
      },
      "source": [
        "# preprocess image data\n",
        "\n",
        "def load_image(file): # create function for loading images\n",
        "    try: # try this code\n",
        "        image = Image.open( # open and identify image file\n",
        "            file\n",
        "        ).convert('LA').resize((64, 64)) # convert to grayscale with alpha channel, resize to 64 by 64 pixels\n",
        "        arr = np.array(image) # return 3D array of image\n",
        "    except: # execute this code when an exception arises\n",
        "        arr = np.zeros((64, 64, 2)) # create 3D array of zeros with shape as (x,y,z)\n",
        "    return arr # return array\n",
        "\n",
        "\n",
        "# loading images:\n",
        "x_image = np.array([load_image(i) for i in tqdm(xy_train_df.image)]) # load training images as arrays with progress bar\n",
        "\n",
        "# loading summary: (force convert some of the non-string cell to string)\n",
        "x_text = xy_train_df.summary.astype('str')\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a13cd4b243c14db2a2f0a1db8894d745",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "  0%|          | 0/7627 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 286
        },
        "id": "QvDuwvp8nfZ9",
        "outputId": "2be08268-587f-4af4-f2a4-3dc76b4cc6d2"
      },
      "source": [
        "# check image loading\n",
        "import matplotlib.pyplot as plt\n",
        "plt.imshow(x_image[0, :, :, 0]) # plot first image from 'x_image'"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7f0445411410>"
            ]
          },
          "metadata": {},
          "execution_count": 4
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0WJnhhY2tGVz",
        "outputId": "9a69f05d-70ab-4621-baf4-1570cf6cbbe9"
      },
      "source": [
        "from sklearn.model_selection import train_test_split # import function from module\n",
        "\n",
        "# labels:\n",
        "y_price = xy_train_df.price # subset price column\n",
        "y_type = xy_train_df.type.astype('category').cat.codes # encode type category variables\n",
        "len_price = len(y_price.unique()) # number of unique items in price category\n",
        "len_type = len(y_type.unique()) # number of unique items in type category\n",
        "print('unique values for price category', len_price, y_price.unique()) # print number of unique items and values for price category\n",
        "print('unique values for type category', len_type, y_type.unique()) # print number of unique items and values for type category\n",
        "\n",
        "# splitting:\n",
        "\n",
        "x_tr_image, x_vl_image, x_tr_text, x_vl_text, y_tr_price, y_vl_price, y_tr_type, y_vl_type = train_test_split(\n",
        "    x_image, # split image arrays into random train and validation subsets\n",
        "    x_text, # split series into random train and validation subsets\n",
        "    y_price, # split series into random train and validation subsets\n",
        "    y_type, # split series into random train and validation subsets\n",
        "    test_size=0.2) # training 80% validation/test 20% of data\n",
        "\n",
        "print(np.shape(x_tr_image)) # print independent image feature training set shape\n",
        "print(np.shape(x_vl_image)) # print independent image feature validation set shape\n",
        "print(np.shape(y_tr_price)) # print dependent price feature training set shape\n",
        "print(np.shape(y_vl_price)) # print dependent price feature validation set shape\n",
        "print(np.shape(y_tr_type)) # print dependent type feature training set shape\n",
        "print(np.shape(y_vl_type)) # print dependent type feature validation set shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "unique values for price category 3 [1 0 2]\n",
            "unique values for type category 24 [ 1 17 22 10 18 20  5  2  8  4 23 13 15 16 14 11 19  0 21  3  6 12  7  9]\n",
            "(6101, 64, 64, 2)\n",
            "(1526, 64, 64, 2)\n",
            "(6101,)\n",
            "(1526,)\n",
            "(6101,)\n",
            "(1526,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MUmQPxOjs8zC",
        "outputId": "8115e89e-57b5-450f-f9b2-2ad53c4895a4"
      },
      "source": [
        "# preprocess text data\n",
        "\n",
        "# import modules and functions\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from sklearn.model_selection import train_test_split\n",
        "from pprint import pprint\n",
        "\n",
        "vocab_size = 40000 # set vocab_size variable to 40000\n",
        "max_len = 100 # # set max_len variable to 100\n",
        "\n",
        "\n",
        "# build vocabulary from training set\n",
        "tokenizer = Tokenizer(num_words=vocab_size) # set max number of words to keep for text tokenization\n",
        "tokenizer.fit_on_texts(x_tr_text) # create vocabulary index based on word frequency\n",
        "\n",
        "# create preprocessing function for text list\n",
        "def _preprocess(list_of_text): # param: list_of_text\n",
        "    return pad_sequences( # return padded sequences with same length\n",
        "        tokenizer.texts_to_sequences(list_of_text), # transforms each text to sequence of integers\n",
        "        maxlen=max_len, # set maximum length of all sequences\n",
        "        padding='post', # set to pad end of sequences\n",
        "    )\n",
        "\n",
        "\n",
        "# padding is done inside:\n",
        "x_tr_text_id = _preprocess(x_tr_text)\n",
        "x_vl_text_id = _preprocess(x_vl_text)\n",
        "\n",
        "# print shapes of padded arrays\n",
        "print(x_tr_text_id.shape)\n",
        "print(x_vl_text_id.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(6101, 100)\n",
            "(1526, 100)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TV2bFRKRBfvL"
      },
      "source": [
        "pprint(tokenizer.sequences_to_texts(x_tr_text_id[:5])) # pretty-print first five sequences in list to text"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "31cmPQM2Bnyl",
        "outputId": "b97826c4-7fd0-4bc2-82c2-9b1770b39406"
      },
      "source": [
        "print('total words in the dictionary:', tokenizer.num_words) # print total words kept in dictionary"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total words in the dictionary: 40000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_QkkRmqYR1Zm",
        "outputId": "4251319f-1e01-4cc8-aab0-1368e515e788"
      },
      "source": [
        "# import modules and functions\n",
        "from __future__ import absolute_import, division, print_function, unicode_literals\n",
        "import collections\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.layers import Conv2D, Flatten, Dense, MaxPool2D\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "# set input text and image shapes\n",
        "in_text = keras.Input(batch_shape=(None, max_len)) # set max length for input text\n",
        "in_image = keras.Input(batch_shape=(None, 64, 64, 2)) # set shape for input image\n",
        "\n",
        "# text part\n",
        "embedded = keras.layers.Embedding(tokenizer.num_words, 100)(in_text) # turn positive integers (indexes) into dense vectors of fixed size\n",
        "averaged = tf.reduce_mean(embedded, axis=1) # reduce input_tensor along dimensions given in axis using mean of elements across dimensions in axis\n",
        "\n",
        "\n",
        "# image part\n",
        "cov = Conv2D(32, (16, 16))(in_image) # 2D convolution layer with 32 filters and 16 by 16 kernel_size\n",
        "pl = MaxPool2D((16, 16))(cov) # max pooling operation for 2D spatial data with 16 by 16 pool_size\n",
        "flattened = Flatten()(pl) # flatten input to 1D array\n",
        "\n",
        "\n",
        "# fusion:\n",
        "fused = tf.concat([averaged, flattened], axis=-1) # concatenate tensors along one dimension\n",
        "\n",
        "# multi-objectives (each is a multi-class classification)\n",
        "p_price = Dense(len_price, activation='softmax', name='price')(fused) # dense layer with units equal to number of unique items in price category, softmax activation function\n",
        "p_type = Dense(len_type, activation='softmax', name='type')(fused) # dense layer with units equal to number of unique items in type category, softmax activation\n",
        "\n",
        "# create model by specifying inputs and outputs\n",
        "model = keras.Model(\n",
        "    inputs={\n",
        "        'summary': in_text, # input text is listing summary\n",
        "        'image': in_image # input image\n",
        "    },\n",
        "    outputs={\n",
        "        'price': p_price, # output predicted price\n",
        "        'type': p_type, # output predicted type\n",
        "    },\n",
        ")\n",
        "\n",
        "# configure model\n",
        "model.compile(\n",
        "    optimizer=Adam(), # use 'Adam' optimizer\n",
        "    loss={\n",
        "        'price': 'sparse_categorical_crossentropy', # loss for 'price' output\n",
        "        'type': 'sparse_categorical_crossentropy', # loss for 'type' output\n",
        "    },\n",
        "    loss_weights={\n",
        "        'price': 0.5, # weight for 'price' loss\n",
        "        'type': 0.5, # weight for 'type' loss\n",
        "    },\n",
        "    metrics={\n",
        "        'price': ['SparseCategoricalAccuracy'], # metric for 'price'\n",
        "        'type': ['SparseCategoricalAccuracy'], # metric for 'type'\n",
        "    },\n",
        ")\n",
        "\n",
        "# summary for model\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_2 (InputLayer)           [(None, 64, 64, 2)]  0           []                               \n",
            "                                                                                                  \n",
            " input_1 (InputLayer)           [(None, 100)]        0           []                               \n",
            "                                                                                                  \n",
            " conv2d (Conv2D)                (None, 49, 49, 32)   16416       ['input_2[0][0]']                \n",
            "                                                                                                  \n",
            " embedding (Embedding)          (None, 100, 100)     4000000     ['input_1[0][0]']                \n",
            "                                                                                                  \n",
            " max_pooling2d (MaxPooling2D)   (None, 3, 3, 32)     0           ['conv2d[0][0]']                 \n",
            "                                                                                                  \n",
            " tf.math.reduce_mean (TFOpLambd  (None, 100)         0           ['embedding[0][0]']              \n",
            " a)                                                                                               \n",
            "                                                                                                  \n",
            " flatten (Flatten)              (None, 288)          0           ['max_pooling2d[0][0]']          \n",
            "                                                                                                  \n",
            " tf.concat (TFOpLambda)         (None, 388)          0           ['tf.math.reduce_mean[0][0]',    \n",
            "                                                                  'flatten[0][0]']                \n",
            "                                                                                                  \n",
            " price (Dense)                  (None, 3)            1167        ['tf.concat[0][0]']              \n",
            "                                                                                                  \n",
            " type (Dense)                   (None, 24)           9336        ['tf.concat[0][0]']              \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 4,026,919\n",
            "Trainable params: 4,026,919\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5al7E5VstHyC",
        "outputId": "61b1d8cc-2cca-41c5-babd-f7f6fdc72480"
      },
      "source": [
        "# fit model on data while monitoring performance on a validation split of 0.2\n",
        "history = model.fit(\n",
        "    x={\n",
        "        'summary': x_tr_text_id, # text training data\n",
        "        'image': x_tr_image # image training data\n",
        "    },\n",
        "    y={\n",
        "        'price': y_tr_price, # text training target data\n",
        "        'type': y_tr_type, # type training target data\n",
        "    },\n",
        "    epochs=20, # 20 cycles through training data\n",
        "    batch_size=16, # number of samples processed before model is updated\n",
        "    validation_data=(\n",
        "        {\n",
        "            'summary': x_vl_text_id, # text validation data\n",
        "            'image': x_vl_image # image validation data\n",
        "         },\n",
        "        {\n",
        "            'price': y_vl_price, # price validation target data\n",
        "            'type': y_vl_type, # type validation target data\n",
        "        }),\n",
        "    validation_split=0.2, # split training and validation 80/20\n",
        "    callbacks=[ # stop training when monitored metric has stopped improving after specified number of epochs\n",
        "        tf.keras.callbacks.EarlyStopping(monitor='val_price_loss', patience=5, ) # monitor loss for validation price with patience of 5 epochs\n",
        "    ],\n",
        "    verbose=1 # progress bar\n",
        ")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "305/305 [==============================] - 56s 179ms/step - loss: 26.9791 - price_loss: 22.9414 - type_loss: 31.0167 - price_sparse_categorical_accuracy: 0.4967 - type_sparse_categorical_accuracy: 0.5859 - val_loss: 12.8168 - val_price_loss: 11.4452 - val_type_loss: 14.1884 - val_price_sparse_categorical_accuracy: 0.5921 - val_type_sparse_categorical_accuracy: 0.6339\n",
            "Epoch 2/20\n",
            "305/305 [==============================] - 54s 178ms/step - loss: 11.5697 - price_loss: 8.4107 - type_loss: 14.7286 - price_sparse_categorical_accuracy: 0.5092 - type_sparse_categorical_accuracy: 0.5912 - val_loss: 16.4096 - val_price_loss: 11.6509 - val_type_loss: 21.1682 - val_price_sparse_categorical_accuracy: 0.5684 - val_type_sparse_categorical_accuracy: 0.7207\n",
            "Epoch 3/20\n",
            "305/305 [==============================] - 54s 178ms/step - loss: 7.7976 - price_loss: 5.4550 - type_loss: 10.1402 - price_sparse_categorical_accuracy: 0.5404 - type_sparse_categorical_accuracy: 0.5992 - val_loss: 6.4827 - val_price_loss: 5.2466 - val_type_loss: 7.7189 - val_price_sparse_categorical_accuracy: 0.4627 - val_type_sparse_categorical_accuracy: 0.6372\n",
            "Epoch 4/20\n",
            "305/305 [==============================] - 54s 178ms/step - loss: 4.6095 - price_loss: 3.4697 - type_loss: 5.7494 - price_sparse_categorical_accuracy: 0.5539 - type_sparse_categorical_accuracy: 0.6145 - val_loss: 4.5982 - val_price_loss: 3.0633 - val_type_loss: 6.1331 - val_price_sparse_categorical_accuracy: 0.5274 - val_type_sparse_categorical_accuracy: 0.5053\n",
            "Epoch 5/20\n",
            "305/305 [==============================] - 54s 178ms/step - loss: 8.0024 - price_loss: 6.5037 - type_loss: 9.5011 - price_sparse_categorical_accuracy: 0.5518 - type_sparse_categorical_accuracy: 0.6135 - val_loss: 5.2148 - val_price_loss: 3.8101 - val_type_loss: 6.6196 - val_price_sparse_categorical_accuracy: 0.5643 - val_type_sparse_categorical_accuracy: 0.6708\n",
            "Epoch 6/20\n",
            "305/305 [==============================] - 54s 178ms/step - loss: 8.8285 - price_loss: 5.7578 - type_loss: 11.8991 - price_sparse_categorical_accuracy: 0.5672 - type_sparse_categorical_accuracy: 0.6125 - val_loss: 10.1922 - val_price_loss: 7.4104 - val_type_loss: 12.9740 - val_price_sparse_categorical_accuracy: 0.6085 - val_type_sparse_categorical_accuracy: 0.6233\n",
            "Epoch 7/20\n",
            "305/305 [==============================] - 54s 178ms/step - loss: 16.5481 - price_loss: 9.2546 - type_loss: 23.8417 - price_sparse_categorical_accuracy: 0.5506 - type_sparse_categorical_accuracy: 0.6105 - val_loss: 8.8002 - val_price_loss: 5.0098 - val_type_loss: 12.5906 - val_price_sparse_categorical_accuracy: 0.6143 - val_type_sparse_categorical_accuracy: 0.7060\n",
            "Epoch 8/20\n",
            "305/305 [==============================] - 54s 178ms/step - loss: 5.3892 - price_loss: 3.6026 - type_loss: 7.1758 - price_sparse_categorical_accuracy: 0.6129 - type_sparse_categorical_accuracy: 0.6377 - val_loss: 6.0624 - val_price_loss: 4.3174 - val_type_loss: 7.8073 - val_price_sparse_categorical_accuracy: 0.4914 - val_type_sparse_categorical_accuracy: 0.5184\n",
            "Epoch 9/20\n",
            "305/305 [==============================] - 55s 179ms/step - loss: 10.3016 - price_loss: 5.4264 - type_loss: 15.1769 - price_sparse_categorical_accuracy: 0.5988 - type_sparse_categorical_accuracy: 0.6324 - val_loss: 5.2398 - val_price_loss: 3.3871 - val_type_loss: 7.0924 - val_price_sparse_categorical_accuracy: 0.5176 - val_type_sparse_categorical_accuracy: 0.5012\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "bb3ad7b268244b4394df87e525dc4bbb",
            "bd477c19cd614db796ab3c9d1e62f897",
            "f9bd25f5f4ea43a09f794cf88713d6bb",
            "bdd0a0acc53a4d458fe453bb2f58660d",
            "ca8d959a71864499b47a85f8c90d10ee",
            "78600874db2b42c3801236eda0e38fde",
            "e49b646ab783411eaa40b8d5b7b796cc",
            "97ce20dfb4294627a689b72b299c5010",
            "97036f624c634e4080fd8d3848db5f1f",
            "ed54be9780c241a0b8e60909ae8a7c0c",
            "8461fcc3b70143149edd078d401f2a5e"
          ]
        },
        "id": "rvuxrR0wtJF9",
        "outputId": "b6978890-8230-415e-81f1-abe2b1c83fde"
      },
      "source": [
        "# preprocess test data for text and image\n",
        "x_test_summary = _preprocess(x_test_df.summary.astype(str)) # preprocess test summary data\n",
        "x_test_image = np.array([load_image(i) for i in tqdm(x_test_df.image)]) # load test images as arrays with progress bar\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "bb3ad7b268244b4394df87e525dc4bbb",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "  0%|          | 0/7360 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O_ORbRwJCn50",
        "outputId": "a4a5b961-3418-46b3-dfe0-631497d3e864"
      },
      "source": [
        "# evaluate model on test data\n",
        "y_predict = model.predict( # use model to predict\n",
        "    {\n",
        "        'summary': x_test_summary, # text test data\n",
        "        'image': x_test_image # image test data\n",
        "    }\n",
        ")\n",
        "\n",
        "price_predicted = y_predict['price'] # target prediction\n",
        "print(price_predicted) # print predictions\n",
        "price_category_predicted = np.argmax(price_predicted, axis=1) # return indices of maximum values along an axis\n",
        "print(price_category_predicted) # print predicted categories for targets\n",
        "\n",
        "# create submission\n",
        "pd.DataFrame(\n",
        "    {'id': x_test_df.id,\n",
        "     'price': price_category_predicted}).to_csv('sample_submissionTemplate.csv', index=False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[9.97428954e-01 2.47765705e-03 9.33638512e-05]\n",
            " [9.99999881e-01 1.46350857e-07 1.04000120e-09]\n",
            " [1.51264025e-02 9.84822512e-01 5.10161553e-05]\n",
            " ...\n",
            " [9.95864987e-01 4.06544236e-03 6.95266863e-05]\n",
            " [9.14229631e-01 8.57704356e-02 2.91805913e-09]\n",
            " [9.37023282e-01 6.26062527e-02 3.70566646e-04]]\n",
            "[0 0 1 ... 0 0 0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZkiuE3bl5Ktw"
      },
      "source": [
        "### **Trial0**\n",
        "\n",
        "val_price_loss: 3.0633, does not improve after fourth epoch\n",
        "\n",
        "val_type_sparse_categorical_accuracy: 0.5012\n",
        "\n",
        "submission categorization accuracy: 0.50951\n",
        "\n",
        "Validation and test scores are similar, does not seem to be underfitting or overfitting. For trial0 I will normalize the range of pixels from 0 to 1. I predict the accuracy should improve."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "4481a335c5064fa485be00cff78fc2d5",
            "cdc36ef2a57b4ea6bf53306e543e444b",
            "94eab3b2b57a4bc3b418c54b231815c1",
            "42917ef7c44243c4b6bc6035bd770207",
            "b4d060f50014497b9870854879d6b09a",
            "60ae64b67c4b4010854063832952c46a",
            "9d006100549941bb8f6c2c490f63ab62",
            "84986ea633c44b60a04a8e11b84d075c",
            "7aa2ea8b9eb5487f888b7090d897307d",
            "288f9e83b77743faa38e368c8a108502",
            "0781bb7cee294f2f9bb9296f24ca6d3d",
            "8f1325fb999a4a3fb445c6137f778d39",
            "60e19b4d7baf4d4282b6eb1971ed8a3b",
            "d14d73673b9146198c58a1a327418322",
            "ba94280055584316b8cbbdd14ff38f55",
            "595287a6241b4bc2a623f8de1a114996",
            "d94089a7a91846dcb8a2a2f2992d3726",
            "30c3fdfae9a34afda1220e59ae9719ef",
            "51cde017aabc45a296c54b85bdcf446d",
            "950318146df34ee59c366ee6c5169703",
            "65478b3bb3644eb0b55de17fa3c93c68",
            "809a90e638c64231836b829c8d260351"
          ]
        },
        "id": "ZpPS_DhY5Pi_",
        "outputId": "ea485c43-4e0c-4196-f72f-4ab020d00c0b"
      },
      "source": [
        "# Trial code cell\n",
        "\n",
        "# load modules\n",
        "import os\n",
        "\n",
        "import pandas as pd\n",
        "from tqdm.notebook import tqdm\n",
        "from PIL import Image\n",
        "import pandas as pd\n",
        "import os\n",
        "import numpy as np\n",
        "\n",
        "xy_train_df = pd.read_csv('train_xy.csv') # read training data into dataframe\n",
        "x_test_df = pd.read_csv('test_x.csv') # read test data into dataframe\n",
        "\n",
        "#===============================================================================\n",
        "\n",
        "# preprocess image data\n",
        "\n",
        "def load_image(file): # create function for loading images\n",
        "    try: # try this code\n",
        "        image = Image.open( # open and identify image file\n",
        "            file\n",
        "        ).convert('LA').resize((64, 64)) # convert to greyscale with alpha channel, resize to 64 by 64 pixels\n",
        "        arr = np.array(image) # return 3D array of image\n",
        "    except: # execute this code when an exception arises\n",
        "        arr = np.zeros((64, 64, 2)) # create 3D array of zeros with shape as (x,y,z)\n",
        "    return arr # return array\n",
        "\n",
        "\n",
        "# loading images:\n",
        "x_image = np.array([load_image(i) for i in tqdm(xy_train_df.image)]) # load training images as arrays with progress bar\n",
        "\n",
        "# loading summary: (force convert some of the non-string cell to string)\n",
        "x_text = xy_train_df.summary.astype('str')\n",
        "\n",
        "\n",
        "#===============================================================================\n",
        "\n",
        "from sklearn.model_selection import train_test_split # import function from module\n",
        "\n",
        "# labels:\n",
        "y_price = xy_train_df.price # subset price column\n",
        "y_type = xy_train_df.type.astype('category').cat.codes # encode type category variables\n",
        "len_price = len(y_price.unique()) # number of unique items in price category\n",
        "len_type = len(y_type.unique()) # number of unique items in type category\n",
        "# print('unique values for price category', len_price, y_price.unique()) # print number of unique items and values for price category\n",
        "# print('unique values for type category', len_type, y_type.unique()) # print number of unique items and values for type category\n",
        "\n",
        "# splitting:\n",
        "\n",
        "x_tr_image, x_vl_image, x_tr_text, x_vl_text, y_tr_price, y_vl_price, y_tr_type, y_vl_type = train_test_split(\n",
        "    x_image, # split image arrays into random train and validation subsets\n",
        "    x_text, # split series into random train and validation subsets\n",
        "    y_price, # split series into random train and validation subsets\n",
        "    y_type, # split series into random train and validation subsets\n",
        "    test_size=0.2) # training 80% validation/test 20% of data\n",
        "\n",
        "# scale image values to range of 0 to 1\n",
        "x_tr_image = x_tr_image/64.0\n",
        "x_vl_image = x_vl_image/64.0\n",
        "\n",
        "# print(np.shape(x_tr_image)) # print independent image feature training set shape\n",
        "# print(np.shape(x_vl_image)) # print independent image feature validation set shape\n",
        "# print(np.shape(y_tr_price)) # print dependent price feature training set shape\n",
        "# print(np.shape(y_vl_price)) # print dependent price feature validation set shape\n",
        "# print(np.shape(y_tr_type)) # print dependent type feature training set shape\n",
        "# print(np.shape(y_vl_type)) # print dependent type feature validation set shape\n",
        "\n",
        "#===============================================================================\n",
        "\n",
        "# preprocess text data\n",
        "\n",
        "# import modules and functions\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from sklearn.model_selection import train_test_split\n",
        "from pprint import pprint\n",
        "\n",
        "vocab_size = 40000 # set vocab_size variable to 40000\n",
        "max_len = 100 # # set max_len variable to 100\n",
        "\n",
        "\n",
        "# build vocabulary from training set\n",
        "tokenizer = Tokenizer(num_words=vocab_size) # set max number of words to keep for text tokenization\n",
        "tokenizer.fit_on_texts(x_tr_text) # create vocabulary index based on word frequency\n",
        "\n",
        "# create preprocessing function for text list\n",
        "def _preprocess(list_of_text): # param: list_of_text\n",
        "    return pad_sequences( # return padded sequences with same length\n",
        "        tokenizer.texts_to_sequences(list_of_text), # transforms each text to sequence of integers\n",
        "        maxlen=max_len, # set maximum length of all sequences\n",
        "        padding='post', # set to pad end of sequences\n",
        "    )\n",
        "\n",
        "\n",
        "# padding is done inside:\n",
        "x_tr_text_id = _preprocess(x_tr_text)\n",
        "x_vl_text_id = _preprocess(x_vl_text)\n",
        "\n",
        "# # print shapes of padded arrays\n",
        "# print(x_tr_text_id.shape)\n",
        "# print(x_vl_text_id.shape)\n",
        "\n",
        "#===============================================================================\n",
        "\n",
        "# import modules and functions\n",
        "from __future__ import absolute_import, division, print_function, unicode_literals\n",
        "import collections\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.layers import Conv2D, Flatten, Dense, MaxPool2D\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "# set input text and image shapes\n",
        "in_text = keras.Input(batch_shape=(None, max_len)) # set max length for input text\n",
        "in_image = keras.Input(batch_shape=(None, 64, 64, 2)) # set shape for input image\n",
        "\n",
        "# text part\n",
        "embedded = keras.layers.Embedding(tokenizer.num_words, 100)(in_text) # turn positive integers (indexes) into dense vectors of fixed size\n",
        "averaged = tf.reduce_mean(embedded, axis=1) # reduce input_tensor along dimensions given in axis using mean of elements across dimensions in axis\n",
        "\n",
        "\n",
        "# image part\n",
        "cov = Conv2D(32, (16, 16))(in_image) # 2D convolution layer with 32 filters and 16 by 16 kernel_size\n",
        "pl = MaxPool2D((16, 16))(cov) # max pooling operation for 2D spatial data with 16 by 16 pool_size\n",
        "flattened = Flatten()(pl) # flatten input to 1D array\n",
        "\n",
        "\n",
        "# fusion:\n",
        "fused = tf.concat([averaged, flattened], axis=-1) # concatenate tensors along one dimension\n",
        "\n",
        "# multi-objectives (each is a multi-class classification)\n",
        "p_price = Dense(len_price, activation='softmax', name='price')(fused) # dense layer with units equal to number of unique items in price category, softmax activation function\n",
        "p_type = Dense(len_type, activation='softmax', name='type')(fused) # dense layer with units equal to number of unique items in type category, softmax activation\n",
        "\n",
        "# create model by specifying inputs and outputs\n",
        "model = keras.Model(\n",
        "    inputs={\n",
        "        'summary': in_text, # input text is listing summary\n",
        "        'image': in_image # input image\n",
        "    },\n",
        "    outputs={\n",
        "        'price': p_price, # output predicted price\n",
        "        'type': p_type, # output predicted type\n",
        "    },\n",
        ")\n",
        "\n",
        "# configure model\n",
        "model.compile(\n",
        "    optimizer=Adam(), # use 'Adam' optimizer\n",
        "    loss={\n",
        "        'price': 'sparse_categorical_crossentropy', # loss for 'price' output\n",
        "        'type': 'sparse_categorical_crossentropy', # loss for 'type' output\n",
        "    },\n",
        "    loss_weights={\n",
        "        'price': 0.5, # weight for 'price' loss\n",
        "        'type': 0.5, # weight for 'type' loss\n",
        "    },\n",
        "    metrics={\n",
        "        'price': ['SparseCategoricalAccuracy'], # metric for 'price'\n",
        "        'type': ['SparseCategoricalAccuracy'], # metric for 'type'\n",
        "    },\n",
        ")\n",
        "\n",
        "# summary for model\n",
        "model.summary()\n",
        "\n",
        "#===============================================================================\n",
        "\n",
        "# fit model on data while monitoring performance on a validation split of 0.2\n",
        "history = model.fit(\n",
        "    x={\n",
        "        'summary': x_tr_text_id, # text training data\n",
        "        'image': x_tr_image # image training data\n",
        "    },\n",
        "    y={\n",
        "        'price': y_tr_price, # text training target data\n",
        "        'type': y_tr_type, # type training target data\n",
        "    },\n",
        "    epochs=20, # 20 cycles through training data\n",
        "    batch_size=16, # number of samples processed before model is updated\n",
        "    validation_data=(\n",
        "        {\n",
        "            'summary': x_vl_text_id, # text validation data\n",
        "            'image': x_vl_image # image validation data\n",
        "         },\n",
        "        {\n",
        "            'price': y_vl_price, # price validation target data\n",
        "            'type': y_vl_type, # type validation target data\n",
        "        }),\n",
        "    validation_split=0.2, # split training and validation 80/20\n",
        "    callbacks=[ # stop training when monitored metric has stopped improving after specified number of epochs\n",
        "        tf.keras.callbacks.EarlyStopping(monitor='val_price_loss', patience=5, ) # monitor loss for validation price with patience of 5 epochs\n",
        "    ],\n",
        "    verbose=1 # progress bar\n",
        ")\n",
        "\n",
        "#===============================================================================\n",
        "\n",
        "# preprocess test data for text and image\n",
        "x_test_summary = _preprocess(x_test_df.summary.astype(str)) # preprocess test summary data\n",
        "x_test_image = np.array([load_image(i) for i in tqdm(x_test_df.image)]) # load test images as arrays with progress bar\n",
        "\n",
        "# scale images for test data to range of 0 to 1\n",
        "x_test_image = x_test_image/64.0\n",
        "\n",
        "#===============================================================================\n",
        "\n",
        "\n",
        "# evaluate model on test data\n",
        "y_predict = model.predict( # use model to predict\n",
        "    {\n",
        "        'summary': x_test_summary, # text test data\n",
        "        'image': x_test_image # image test data\n",
        "    }\n",
        ")\n",
        "\n",
        "price_predicted = y_predict['price'] # target prediction\n",
        "# print(price_predicted) # print predictions\n",
        "price_category_predicted = np.argmax(price_predicted, axis=1) # return indices of maximum values along an axis\n",
        "# print(price_category_predicted) # print predicted categories for targets\n",
        "\n",
        "# create submission\n",
        "pd.DataFrame(\n",
        "    {'id': x_test_df.id,\n",
        "     'price': price_category_predicted}).to_csv('sample_submission0.csv', index=False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "4481a335c5064fa485be00cff78fc2d5",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "  0%|          | 0/7627 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_2 (InputLayer)           [(None, 64, 64, 2)]  0           []                               \n",
            "                                                                                                  \n",
            " input_1 (InputLayer)           [(None, 100)]        0           []                               \n",
            "                                                                                                  \n",
            " conv2d (Conv2D)                (None, 49, 49, 32)   16416       ['input_2[0][0]']                \n",
            "                                                                                                  \n",
            " embedding (Embedding)          (None, 100, 100)     4000000     ['input_1[0][0]']                \n",
            "                                                                                                  \n",
            " max_pooling2d (MaxPooling2D)   (None, 3, 3, 32)     0           ['conv2d[0][0]']                 \n",
            "                                                                                                  \n",
            " tf.math.reduce_mean (TFOpLambd  (None, 100)         0           ['embedding[0][0]']              \n",
            " a)                                                                                               \n",
            "                                                                                                  \n",
            " flatten (Flatten)              (None, 288)          0           ['max_pooling2d[0][0]']          \n",
            "                                                                                                  \n",
            " tf.concat (TFOpLambda)         (None, 388)          0           ['tf.math.reduce_mean[0][0]',    \n",
            "                                                                  'flatten[0][0]']                \n",
            "                                                                                                  \n",
            " price (Dense)                  (None, 3)            1167        ['tf.concat[0][0]']              \n",
            "                                                                                                  \n",
            " type (Dense)                   (None, 24)           9336        ['tf.concat[0][0]']              \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 4,026,919\n",
            "Trainable params: 4,026,919\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "Epoch 1/20\n",
            "305/305 [==============================] - 55s 177ms/step - loss: 1.0211 - price_loss: 0.9171 - type_loss: 1.1250 - price_sparse_categorical_accuracy: 0.5834 - type_sparse_categorical_accuracy: 0.7561 - val_loss: 1.0186 - val_price_loss: 0.8464 - val_type_loss: 1.1909 - val_price_sparse_categorical_accuracy: 0.6241 - val_type_sparse_categorical_accuracy: 0.7453\n",
            "Epoch 2/20\n",
            "305/305 [==============================] - 54s 176ms/step - loss: 0.9037 - price_loss: 0.8082 - type_loss: 0.9991 - price_sparse_categorical_accuracy: 0.6359 - type_sparse_categorical_accuracy: 0.7615 - val_loss: 0.9469 - val_price_loss: 0.7884 - val_type_loss: 1.1054 - val_price_sparse_categorical_accuracy: 0.6503 - val_type_sparse_categorical_accuracy: 0.7453\n",
            "Epoch 3/20\n",
            "305/305 [==============================] - 53s 175ms/step - loss: 0.8397 - price_loss: 0.7427 - type_loss: 0.9366 - price_sparse_categorical_accuracy: 0.6693 - type_sparse_categorical_accuracy: 0.7627 - val_loss: 0.9801 - val_price_loss: 0.8055 - val_type_loss: 1.1547 - val_price_sparse_categorical_accuracy: 0.6503 - val_type_sparse_categorical_accuracy: 0.7363\n",
            "Epoch 4/20\n",
            "305/305 [==============================] - 54s 176ms/step - loss: 0.7643 - price_loss: 0.6750 - type_loss: 0.8536 - price_sparse_categorical_accuracy: 0.7076 - type_sparse_categorical_accuracy: 0.7701 - val_loss: 0.8905 - val_price_loss: 0.7556 - val_type_loss: 1.0253 - val_price_sparse_categorical_accuracy: 0.6683 - val_type_sparse_categorical_accuracy: 0.7453\n",
            "Epoch 5/20\n",
            "305/305 [==============================] - 54s 176ms/step - loss: 0.7018 - price_loss: 0.6217 - type_loss: 0.7819 - price_sparse_categorical_accuracy: 0.7418 - type_sparse_categorical_accuracy: 0.7783 - val_loss: 0.8814 - val_price_loss: 0.7563 - val_type_loss: 1.0066 - val_price_sparse_categorical_accuracy: 0.6642 - val_type_sparse_categorical_accuracy: 0.7502\n",
            "Epoch 6/20\n",
            "305/305 [==============================] - 54s 176ms/step - loss: 0.6425 - price_loss: 0.5678 - type_loss: 0.7172 - price_sparse_categorical_accuracy: 0.7701 - type_sparse_categorical_accuracy: 0.7959 - val_loss: 0.8725 - val_price_loss: 0.7433 - val_type_loss: 1.0017 - val_price_sparse_categorical_accuracy: 0.6724 - val_type_sparse_categorical_accuracy: 0.7510\n",
            "Epoch 7/20\n",
            "305/305 [==============================] - 54s 178ms/step - loss: 0.5941 - price_loss: 0.5245 - type_loss: 0.6637 - price_sparse_categorical_accuracy: 0.7848 - type_sparse_categorical_accuracy: 0.8082 - val_loss: 0.8574 - val_price_loss: 0.7454 - val_type_loss: 0.9695 - val_price_sparse_categorical_accuracy: 0.6667 - val_type_sparse_categorical_accuracy: 0.7576\n",
            "Epoch 8/20\n",
            "305/305 [==============================] - 54s 178ms/step - loss: 0.5480 - price_loss: 0.4943 - type_loss: 0.6018 - price_sparse_categorical_accuracy: 0.8008 - type_sparse_categorical_accuracy: 0.8256 - val_loss: 0.8683 - val_price_loss: 0.7558 - val_type_loss: 0.9807 - val_price_sparse_categorical_accuracy: 0.6675 - val_type_sparse_categorical_accuracy: 0.7568\n",
            "Epoch 9/20\n",
            "305/305 [==============================] - 55s 179ms/step - loss: 0.5046 - price_loss: 0.4537 - type_loss: 0.5555 - price_sparse_categorical_accuracy: 0.8174 - type_sparse_categorical_accuracy: 0.8432 - val_loss: 0.9141 - val_price_loss: 0.7967 - val_type_loss: 1.0316 - val_price_sparse_categorical_accuracy: 0.6454 - val_type_sparse_categorical_accuracy: 0.7355\n",
            "Epoch 10/20\n",
            "305/305 [==============================] - 54s 178ms/step - loss: 0.4694 - price_loss: 0.4278 - type_loss: 0.5111 - price_sparse_categorical_accuracy: 0.8311 - type_sparse_categorical_accuracy: 0.8533 - val_loss: 0.8992 - val_price_loss: 0.7866 - val_type_loss: 1.0118 - val_price_sparse_categorical_accuracy: 0.6716 - val_type_sparse_categorical_accuracy: 0.7568\n",
            "Epoch 11/20\n",
            "305/305 [==============================] - 54s 178ms/step - loss: 0.4178 - price_loss: 0.3804 - type_loss: 0.4553 - price_sparse_categorical_accuracy: 0.8514 - type_sparse_categorical_accuracy: 0.8732 - val_loss: 0.9428 - val_price_loss: 0.8478 - val_type_loss: 1.0379 - val_price_sparse_categorical_accuracy: 0.6282 - val_type_sparse_categorical_accuracy: 0.7510\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "8f1325fb999a4a3fb445c6137f778d39",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "  0%|          | 0/7360 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wY_V1O-SP8i9"
      },
      "source": [
        "### **Trial1**\n",
        "\n",
        "Trial0 results:\n",
        "\n",
        "val_price_loss: 0.7433, does not improve after sixth epoch\n",
        "\n",
        "type_sparse_categorical_accuracy: 0.7959\n",
        "\n",
        "val_type_sparse_categorical_accuracy: 0.7510\n",
        "\n",
        "submission categorization accuracy: 0.63609\n",
        "\n",
        "There is overfitting occuring as the training accuracy is greater than the validation accuracy. Both are greater than the test submission accuracy. I will attempt to regularize by applying a dropout of 0.5 (50%) after the pooling layer. This should prevent overfitting and yield a training and validation score that are closer."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "08a403d348a747e382ea7e1c6efea57f",
            "f7b0b5a2531944748969ca929d2b1b7b",
            "d13d413ddeab44819241824e829ad6ae",
            "f3ff3fd3a5ef4d2891d31544b8880cba",
            "b107416463c04a1d82e280cff234a222",
            "fb3c0086fe954de990d85df4b7cc502f",
            "3be9b04094994bedbf15815b52c76a9f",
            "1a626ac078ec4cc09436663a84a03bfc",
            "29d136ddee2f488ba0e0a90befb6c9e3",
            "ea223011aabd4fe381830998c5d7d226",
            "a8f40631ea004e72a3b31007bfa8b2bb",
            "b03f02dc1c544bb19196cc5a0879d603",
            "0cd6272e054e4f6090ffce4ba31fe033",
            "b1462f7536e14188a46dfd538a8e7c49",
            "60ff077cdf02446dbccd8db385f5fcc6",
            "885ff4901c1442a69ad6870f81fdfccf",
            "ebe69d7520c84e3eaa1c5985e796b037",
            "bea98d320474460793f100e829f5036e",
            "8f402be85419472c828e1c5263882215",
            "691e5d39b44149149640fe5d579d820a",
            "aa5cfe60f9b84b3785ae29bf4b86d488",
            "d45c36a7c7f146a3a02bbb2df3dd5f74"
          ]
        },
        "id": "lnVhRyd2P8Kf",
        "outputId": "6d0b621a-9e25-45e4-a280-c146f727e383"
      },
      "source": [
        "# Trial code cell\n",
        "\n",
        "# load modules\n",
        "import os\n",
        "\n",
        "import pandas as pd\n",
        "from tqdm.notebook import tqdm\n",
        "from PIL import Image\n",
        "import pandas as pd\n",
        "import os\n",
        "import numpy as np\n",
        "\n",
        "xy_train_df = pd.read_csv('train_xy.csv') # read training data into dataframe\n",
        "x_test_df = pd.read_csv('test_x.csv') # read test data into dataframe\n",
        "\n",
        "#===============================================================================\n",
        "\n",
        "# preprocess image data\n",
        "\n",
        "def load_image(file): # create function for loading images\n",
        "    try: # try this code\n",
        "        image = Image.open( # open and identify image file\n",
        "            file\n",
        "        ).convert('LA').resize((64, 64)) # convert to greyscale with alpha channel, resize to 64 by 64 pixels\n",
        "        arr = np.array(image) # return 3D array of image\n",
        "    except: # execute this code when an exception arises\n",
        "        arr = np.zeros((64, 64, 2)) # create 3D array of zeros with shape as (x,y,z)\n",
        "    return arr # return array\n",
        "\n",
        "\n",
        "# loading images:\n",
        "x_image = np.array([load_image(i) for i in tqdm(xy_train_df.image)]) # load training images as arrays with progress bar\n",
        "\n",
        "# loading summary: (force convert some of the non-string cell to string)\n",
        "x_text = xy_train_df.summary.astype('str')\n",
        "\n",
        "\n",
        "#===============================================================================\n",
        "\n",
        "from sklearn.model_selection import train_test_split # import function from module\n",
        "\n",
        "# labels:\n",
        "y_price = xy_train_df.price # subset price column\n",
        "y_type = xy_train_df.type.astype('category').cat.codes # encode type category variables\n",
        "len_price = len(y_price.unique()) # number of unique items in price category\n",
        "len_type = len(y_type.unique()) # number of unique items in type category\n",
        "# print('unique values for price category', len_price, y_price.unique()) # print number of unique items and values for price category\n",
        "# print('unique values for type category', len_type, y_type.unique()) # print number of unique items and values for type category\n",
        "\n",
        "# splitting:\n",
        "\n",
        "x_tr_image, x_vl_image, x_tr_text, x_vl_text, y_tr_price, y_vl_price, y_tr_type, y_vl_type = train_test_split(\n",
        "    x_image, # split image arrays into random train and validation subsets\n",
        "    x_text, # split series into random train and validation subsets\n",
        "    y_price, # split series into random train and validation subsets\n",
        "    y_type, # split series into random train and validation subsets\n",
        "    test_size=0.2) # training 80% validation/test 20% of data\n",
        "\n",
        "# scale image values to range of 0 to 1\n",
        "x_tr_image = x_tr_image/64.0\n",
        "x_vl_image = x_vl_image/64.0\n",
        "\n",
        "# print(np.shape(x_tr_image)) # print independent image feature training set shape\n",
        "# print(np.shape(x_vl_image)) # print independent image feature validation set shape\n",
        "# print(np.shape(y_tr_price)) # print dependent price feature training set shape\n",
        "# print(np.shape(y_vl_price)) # print dependent price feature validation set shape\n",
        "# print(np.shape(y_tr_type)) # print dependent type feature training set shape\n",
        "# print(np.shape(y_vl_type)) # print dependent type feature validation set shape\n",
        "\n",
        "#===============================================================================\n",
        "\n",
        "# preprocess text data\n",
        "\n",
        "# import modules and functions\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from sklearn.model_selection import train_test_split\n",
        "from pprint import pprint\n",
        "\n",
        "vocab_size = 40000 # set vocab_size variable to 40000\n",
        "max_len = 100 # # set max_len variable to 100\n",
        "\n",
        "\n",
        "# build vocabulary from training set\n",
        "tokenizer = Tokenizer(num_words=vocab_size) # set max number of words to keep for text tokenization\n",
        "tokenizer.fit_on_texts(x_tr_text) # create vocabulary index based on word frequency\n",
        "\n",
        "# create preprocessing function for text list\n",
        "def _preprocess(list_of_text): # param: list_of_text\n",
        "    return pad_sequences( # return padded sequences with same length\n",
        "        tokenizer.texts_to_sequences(list_of_text), # transforms each text to sequence of integers\n",
        "        maxlen=max_len, # set maximum length of all sequences\n",
        "        padding='post', # set to pad end of sequences\n",
        "    )\n",
        "\n",
        "\n",
        "# padding is done inside:\n",
        "x_tr_text_id = _preprocess(x_tr_text)\n",
        "x_vl_text_id = _preprocess(x_vl_text)\n",
        "\n",
        "# # print shapes of padded arrays\n",
        "# print(x_tr_text_id.shape)\n",
        "# print(x_vl_text_id.shape)\n",
        "\n",
        "#===============================================================================\n",
        "\n",
        "# import modules and functions\n",
        "from __future__ import absolute_import, division, print_function, unicode_literals\n",
        "import collections\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.layers import Conv2D, Flatten, Dense, MaxPool2D, Dropout # import dropout layer\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "# set input text and image shapes\n",
        "in_text = keras.Input(batch_shape=(None, max_len)) # set max length for input text\n",
        "in_image = keras.Input(batch_shape=(None, 64, 64, 2)) # set shape for input image\n",
        "\n",
        "# text part\n",
        "embedded = keras.layers.Embedding(tokenizer.num_words, 100)(in_text) # turn positive integers (indexes) into dense vectors of fixed size\n",
        "averaged = tf.reduce_mean(embedded, axis=1) # reduce input_tensor along dimensions given in axis using mean of elements across dimensions in axis\n",
        "\n",
        "\n",
        "# image part\n",
        "cov = Conv2D(32, (16, 16))(in_image) # 2D convolution layer with 32 filters and 16 by 16 kernel_size\n",
        "pl = MaxPool2D((16, 16))(cov) # max pooling operation for 2D spatial data with 16 by 16 pool_size\n",
        "# add dropout after pooling\n",
        "pl = Dropout(0.5)(pl) # 50% dropout rate\n",
        "flattened = Flatten()(pl) # flatten input to 1D array\n",
        "\n",
        "\n",
        "# fusion:\n",
        "fused = tf.concat([averaged, flattened], axis=-1) # concatenate tensors along one dimension\n",
        "\n",
        "# multi-objectives (each is a multi-class classification)\n",
        "p_price = Dense(len_price, activation='softmax', name='price')(fused) # dense layer with units equal to number of unique items in price category, softmax activation function\n",
        "p_type = Dense(len_type, activation='softmax', name='type')(fused) # dense layer with units equal to number of unique items in type category, softmax activation\n",
        "\n",
        "# create model by specifying inputs and outputs\n",
        "model = keras.Model(\n",
        "    inputs={\n",
        "        'summary': in_text, # input text is listing summary\n",
        "        'image': in_image # input image\n",
        "    },\n",
        "    outputs={\n",
        "        'price': p_price, # output predicted price\n",
        "        'type': p_type, # output predicted type\n",
        "    },\n",
        ")\n",
        "\n",
        "# configure model\n",
        "model.compile(\n",
        "    optimizer=Adam(), # use 'Adam' optimizer\n",
        "    loss={\n",
        "        'price': 'sparse_categorical_crossentropy', # loss for 'price' output\n",
        "        'type': 'sparse_categorical_crossentropy', # loss for 'type' output\n",
        "    },\n",
        "    loss_weights={\n",
        "        'price': 0.5, # weight for 'price' loss\n",
        "        'type': 0.5, # weight for 'type' loss\n",
        "    },\n",
        "    metrics={\n",
        "        'price': ['SparseCategoricalAccuracy'], # metric for 'price'\n",
        "        'type': ['SparseCategoricalAccuracy'], # metric for 'type'\n",
        "    },\n",
        ")\n",
        "\n",
        "# summary for model\n",
        "model.summary()\n",
        "\n",
        "#===============================================================================\n",
        "\n",
        "# fit model on data while monitoring performance on a validation split of 0.2\n",
        "history = model.fit(\n",
        "    x={\n",
        "        'summary': x_tr_text_id, # text training data\n",
        "        'image': x_tr_image # image training data\n",
        "    },\n",
        "    y={\n",
        "        'price': y_tr_price, # text training target data\n",
        "        'type': y_tr_type, # type training target data\n",
        "    },\n",
        "    epochs=20, # 20 cycles through training data\n",
        "    batch_size=16, # number of samples processed before model is updated\n",
        "    validation_data=(\n",
        "        {\n",
        "            'summary': x_vl_text_id, # text validation data\n",
        "            'image': x_vl_image # image validation data\n",
        "         },\n",
        "        {\n",
        "            'price': y_vl_price, # price validation target data\n",
        "            'type': y_vl_type, # type validation target data\n",
        "        }),\n",
        "    validation_split=0.2, # split training and validation 80/20\n",
        "    callbacks=[ # stop training when monitored metric has stopped improving after specified number of epochs\n",
        "        tf.keras.callbacks.EarlyStopping(monitor='val_price_loss', patience=5, ) # monitor loss for validation price with patience of 5 epochs\n",
        "    ],\n",
        "    verbose=1 # progress bar\n",
        ")\n",
        "\n",
        "#===============================================================================\n",
        "\n",
        "# preprocess test data for text and image\n",
        "x_test_summary = _preprocess(x_test_df.summary.astype(str)) # preprocess test summary data\n",
        "x_test_image = np.array([load_image(i) for i in tqdm(x_test_df.image)]) # load test images as arrays with progress bar\n",
        "\n",
        "# scale images for test data to range of 0 to 1\n",
        "x_test_image = x_test_image/64.0\n",
        "\n",
        "#===============================================================================\n",
        "\n",
        "\n",
        "# evaluate model on test data\n",
        "y_predict = model.predict( # use model to predict\n",
        "    {\n",
        "        'summary': x_test_summary, # text test data\n",
        "        'image': x_test_image # image test data\n",
        "    }\n",
        ")\n",
        "\n",
        "price_predicted = y_predict['price'] # target prediction\n",
        "# print(price_predicted) # print predictions\n",
        "price_category_predicted = np.argmax(price_predicted, axis=1) # return indices of maximum values along an axis\n",
        "# print(price_category_predicted) # print predicted categories for targets\n",
        "\n",
        "# create submission\n",
        "pd.DataFrame(\n",
        "    {'id': x_test_df.id,\n",
        "     'price': price_category_predicted}).to_csv('sample_submission1.csv', index=False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "08a403d348a747e382ea7e1c6efea57f",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "  0%|          | 0/7627 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_2 (InputLayer)           [(None, 64, 64, 2)]  0           []                               \n",
            "                                                                                                  \n",
            " conv2d (Conv2D)                (None, 49, 49, 32)   16416       ['input_2[0][0]']                \n",
            "                                                                                                  \n",
            " input_1 (InputLayer)           [(None, 100)]        0           []                               \n",
            "                                                                                                  \n",
            " max_pooling2d (MaxPooling2D)   (None, 3, 3, 32)     0           ['conv2d[0][0]']                 \n",
            "                                                                                                  \n",
            " embedding (Embedding)          (None, 100, 100)     4000000     ['input_1[0][0]']                \n",
            "                                                                                                  \n",
            " dropout (Dropout)              (None, 3, 3, 32)     0           ['max_pooling2d[0][0]']          \n",
            "                                                                                                  \n",
            " tf.math.reduce_mean (TFOpLambd  (None, 100)         0           ['embedding[0][0]']              \n",
            " a)                                                                                               \n",
            "                                                                                                  \n",
            " flatten (Flatten)              (None, 288)          0           ['dropout[0][0]']                \n",
            "                                                                                                  \n",
            " tf.concat (TFOpLambda)         (None, 388)          0           ['tf.math.reduce_mean[0][0]',    \n",
            "                                                                  'flatten[0][0]']                \n",
            "                                                                                                  \n",
            " price (Dense)                  (None, 3)            1167        ['tf.concat[0][0]']              \n",
            "                                                                                                  \n",
            " type (Dense)                   (None, 24)           9336        ['tf.concat[0][0]']              \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 4,026,919\n",
            "Trainable params: 4,026,919\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "Epoch 1/20\n",
            "305/305 [==============================] - 55s 176ms/step - loss: 1.3477 - price_loss: 1.2408 - type_loss: 1.4546 - price_sparse_categorical_accuracy: 0.5266 - type_sparse_categorical_accuracy: 0.6863 - val_loss: 1.0282 - val_price_loss: 0.8738 - val_type_loss: 1.1827 - val_price_sparse_categorical_accuracy: 0.6233 - val_type_sparse_categorical_accuracy: 0.7379\n",
            "Epoch 2/20\n",
            "305/305 [==============================] - 54s 176ms/step - loss: 1.0652 - price_loss: 0.9332 - type_loss: 1.1972 - price_sparse_categorical_accuracy: 0.5787 - type_sparse_categorical_accuracy: 0.7289 - val_loss: 0.9194 - val_price_loss: 0.8084 - val_type_loss: 1.0304 - val_price_sparse_categorical_accuracy: 0.6396 - val_type_sparse_categorical_accuracy: 0.7379\n",
            "Epoch 3/20\n",
            "305/305 [==============================] - 54s 176ms/step - loss: 0.9415 - price_loss: 0.8133 - type_loss: 1.0697 - price_sparse_categorical_accuracy: 0.6346 - type_sparse_categorical_accuracy: 0.7502 - val_loss: 0.9074 - val_price_loss: 0.7817 - val_type_loss: 1.0330 - val_price_sparse_categorical_accuracy: 0.6642 - val_type_sparse_categorical_accuracy: 0.7379\n",
            "Epoch 4/20\n",
            "305/305 [==============================] - 54s 177ms/step - loss: 0.8802 - price_loss: 0.7571 - type_loss: 1.0032 - price_sparse_categorical_accuracy: 0.6705 - type_sparse_categorical_accuracy: 0.7549 - val_loss: 0.9623 - val_price_loss: 0.8176 - val_type_loss: 1.1070 - val_price_sparse_categorical_accuracy: 0.6519 - val_type_sparse_categorical_accuracy: 0.7387\n",
            "Epoch 5/20\n",
            "305/305 [==============================] - 54s 176ms/step - loss: 0.8046 - price_loss: 0.6923 - type_loss: 0.9169 - price_sparse_categorical_accuracy: 0.6982 - type_sparse_categorical_accuracy: 0.7641 - val_loss: 0.8491 - val_price_loss: 0.7517 - val_type_loss: 0.9464 - val_price_sparse_categorical_accuracy: 0.6577 - val_type_sparse_categorical_accuracy: 0.7404\n",
            "Epoch 6/20\n",
            "305/305 [==============================] - 54s 176ms/step - loss: 0.7727 - price_loss: 0.6583 - type_loss: 0.8870 - price_sparse_categorical_accuracy: 0.7180 - type_sparse_categorical_accuracy: 0.7705 - val_loss: 0.8339 - val_price_loss: 0.7197 - val_type_loss: 0.9480 - val_price_sparse_categorical_accuracy: 0.6904 - val_type_sparse_categorical_accuracy: 0.7412\n",
            "Epoch 7/20\n",
            "305/305 [==============================] - 56s 182ms/step - loss: 0.7283 - price_loss: 0.6233 - type_loss: 0.8333 - price_sparse_categorical_accuracy: 0.7338 - type_sparse_categorical_accuracy: 0.7785 - val_loss: 0.8257 - val_price_loss: 0.7233 - val_type_loss: 0.9282 - val_price_sparse_categorical_accuracy: 0.6896 - val_type_sparse_categorical_accuracy: 0.7469\n",
            "Epoch 8/20\n",
            "305/305 [==============================] - 54s 178ms/step - loss: 0.6965 - price_loss: 0.5930 - type_loss: 0.8000 - price_sparse_categorical_accuracy: 0.7504 - type_sparse_categorical_accuracy: 0.7814 - val_loss: 0.8398 - val_price_loss: 0.7266 - val_type_loss: 0.9529 - val_price_sparse_categorical_accuracy: 0.6732 - val_type_sparse_categorical_accuracy: 0.7551\n",
            "Epoch 9/20\n",
            "305/305 [==============================] - 54s 177ms/step - loss: 0.6658 - price_loss: 0.5655 - type_loss: 0.7662 - price_sparse_categorical_accuracy: 0.7619 - type_sparse_categorical_accuracy: 0.7877 - val_loss: 0.9694 - val_price_loss: 0.8035 - val_type_loss: 1.1352 - val_price_sparse_categorical_accuracy: 0.6413 - val_type_sparse_categorical_accuracy: 0.7420\n",
            "Epoch 10/20\n",
            "305/305 [==============================] - 54s 176ms/step - loss: 0.6351 - price_loss: 0.5453 - type_loss: 0.7249 - price_sparse_categorical_accuracy: 0.7742 - type_sparse_categorical_accuracy: 0.7977 - val_loss: 0.8161 - val_price_loss: 0.7220 - val_type_loss: 0.9101 - val_price_sparse_categorical_accuracy: 0.6921 - val_type_sparse_categorical_accuracy: 0.7576\n",
            "Epoch 11/20\n",
            "305/305 [==============================] - 54s 176ms/step - loss: 0.5981 - price_loss: 0.5119 - type_loss: 0.6843 - price_sparse_categorical_accuracy: 0.7900 - type_sparse_categorical_accuracy: 0.8045 - val_loss: 0.8166 - val_price_loss: 0.7290 - val_type_loss: 0.9042 - val_price_sparse_categorical_accuracy: 0.6871 - val_type_sparse_categorical_accuracy: 0.7641\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b03f02dc1c544bb19196cc5a0879d603",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "  0%|          | 0/7360 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lfkblvsKmnDg"
      },
      "source": [
        "### **Trial2**\n",
        "\n",
        "Trial1 results:\n",
        "\n",
        "val_price_loss: 0.7197 , does not improve after sixth epoch\n",
        "\n",
        "type_sparse_categorical_accuracy: 0.7705\n",
        "\n",
        "val_type_sparse_categorical_accuracy: 0.7412\n",
        "\n",
        "The dropout layer appears to have mitigated some of the overfitting. The training and validation scores are not too far off from one another. I will attempt to improve the model performance in this trial by replacing the reduce_mean layer with a Gated Recurrent Unit (GRU) layer."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "cd0f95b3d4da4a058d7a58e8bc003a4d",
            "8c3c58c31c194fc8b0d9d3b28f9d06a5",
            "3ccc9f966ec34c109541e2bb165d55ea",
            "20e314fd186e44e5b86492ad6e112f87",
            "7ccf547baa514d2d98a6c59ee53f53ee",
            "beb5f587e2914ee7885ae60f992565d9",
            "c7379b05b4fe48aa9fffba85c6b4dcf1",
            "1cc5f20714cc4379b2b8d8e7ac4d3fe9",
            "d095ebec04064c05ae80e37f58f90cb7",
            "70af00e9bc6248589c53a3e3fb451a81",
            "997c2f37be984d07b650bee43732192d"
          ]
        },
        "id": "Tu-XLkzXms2X",
        "outputId": "fe6ad6ef-6359-4582-bc73-5d2b3596ba11"
      },
      "source": [
        "# Trial code cell\n",
        "\n",
        "# load modules\n",
        "import os\n",
        "\n",
        "import pandas as pd\n",
        "from tqdm.notebook import tqdm\n",
        "from PIL import Image\n",
        "import pandas as pd\n",
        "import os\n",
        "import numpy as np\n",
        "\n",
        "xy_train_df = pd.read_csv('train_xy.csv') # read training data into dataframe\n",
        "x_test_df = pd.read_csv('test_x.csv') # read test data into dataframe\n",
        "\n",
        "#===============================================================================\n",
        "\n",
        "# preprocess image data\n",
        "\n",
        "def load_image(file): # create function for loading images\n",
        "    try: # try this code\n",
        "        image = Image.open( # open and identify image file\n",
        "            file\n",
        "        ).convert('LA').resize((64, 64)) # convert to greyscale with alpha channel, resize to 64 by 64 pixels\n",
        "        arr = np.array(image) # return 3D array of image\n",
        "    except: # execute this code when an exception arises\n",
        "        arr = np.zeros((64, 64, 2)) # create 3D array of zeros with shape as (x,y,z)\n",
        "    return arr # return array\n",
        "\n",
        "\n",
        "# loading images:\n",
        "x_image = np.array([load_image(i) for i in tqdm(xy_train_df.image)]) # load training images as arrays with progress bar\n",
        "\n",
        "# loading summary: (force convert some of the non-string cell to string)\n",
        "x_text = xy_train_df.summary.astype('str')\n",
        "\n",
        "\n",
        "#===============================================================================\n",
        "\n",
        "from sklearn.model_selection import train_test_split # import function from module\n",
        "\n",
        "# labels:\n",
        "y_price = xy_train_df.price # subset price column\n",
        "y_type = xy_train_df.type.astype('category').cat.codes # encode type category variables\n",
        "len_price = len(y_price.unique()) # number of unique items in price category\n",
        "len_type = len(y_type.unique()) # number of unique items in type category\n",
        "# print('unique values for price category', len_price, y_price.unique()) # print number of unique items and values for price category\n",
        "# print('unique values for type category', len_type, y_type.unique()) # print number of unique items and values for type category\n",
        "\n",
        "# splitting:\n",
        "\n",
        "x_tr_image, x_vl_image, x_tr_text, x_vl_text, y_tr_price, y_vl_price, y_tr_type, y_vl_type = train_test_split(\n",
        "    x_image, # split image arrays into random train and validation subsets\n",
        "    x_text, # split series into random train and validation subsets\n",
        "    y_price, # split series into random train and validation subsets\n",
        "    y_type, # split series into random train and validation subsets\n",
        "    test_size=0.2) # training 80% validation/test 20% of data\n",
        "\n",
        "# scale image values to range of 0 to 1\n",
        "x_tr_image = x_tr_image/64.0\n",
        "x_vl_image = x_vl_image/64.0\n",
        "\n",
        "# print(np.shape(x_tr_image)) # print independent image feature training set shape\n",
        "# print(np.shape(x_vl_image)) # print independent image feature validation set shape\n",
        "# print(np.shape(y_tr_price)) # print dependent price feature training set shape\n",
        "# print(np.shape(y_vl_price)) # print dependent price feature validation set shape\n",
        "# print(np.shape(y_tr_type)) # print dependent type feature training set shape\n",
        "# print(np.shape(y_vl_type)) # print dependent type feature validation set shape\n",
        "\n",
        "#===============================================================================\n",
        "\n",
        "# preprocess text data\n",
        "\n",
        "# import modules and functions\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from sklearn.model_selection import train_test_split\n",
        "from pprint import pprint\n",
        "\n",
        "vocab_size = 40000 # set vocab_size variable to 40000\n",
        "max_len = 100 # # set max_len variable to 100\n",
        "\n",
        "\n",
        "# build vocabulary from training set\n",
        "tokenizer = Tokenizer(num_words=vocab_size) # set max number of words to keep for text tokenization\n",
        "tokenizer.fit_on_texts(x_tr_text) # create vocabulary index based on word frequency\n",
        "\n",
        "# create preprocessing function for text list\n",
        "def _preprocess(list_of_text): # param: list_of_text\n",
        "    return pad_sequences( # return padded sequences with same length\n",
        "        tokenizer.texts_to_sequences(list_of_text), # transforms each text to sequence of integers\n",
        "        maxlen=max_len, # set maximum length of all sequences\n",
        "        padding='post', # set to pad end of sequences\n",
        "    )\n",
        "\n",
        "\n",
        "# padding is done inside:\n",
        "x_tr_text_id = _preprocess(x_tr_text)\n",
        "x_vl_text_id = _preprocess(x_vl_text)\n",
        "\n",
        "# # print shapes of padded arrays\n",
        "# print(x_tr_text_id.shape)\n",
        "# print(x_vl_text_id.shape)\n",
        "\n",
        "#===============================================================================\n",
        "\n",
        "# import modules and functions\n",
        "from __future__ import absolute_import, division, print_function, unicode_literals\n",
        "import collections\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.layers import Conv2D, Flatten, Dense, MaxPool2D, Dropout # import dropout layer\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "# set input text and image shapes\n",
        "in_text = keras.Input(batch_shape=(None, max_len)) # set max length for input text\n",
        "in_image = keras.Input(batch_shape=(None, 64, 64, 2)) # set shape for input image\n",
        "\n",
        "# text part\n",
        "embedded = keras.layers.Embedding(tokenizer.num_words, 100)(in_text) # turn positive integers (indexes) into dense vectors of fixed size\n",
        "# averaged = tf.reduce_mean(embedded, axis=1) # reduce input_tensor along dimensions given in axis using mean of elements across dimensions in axis\n",
        "\n",
        "# GRU layer\n",
        "gru = tf.keras.layers.GRU(4)(embedded) # GRU layer with 4 units\n",
        "\n",
        "# image part\n",
        "cov = Conv2D(32, (16, 16))(in_image) # 2D convolution layer with 32 filters and 16 by 16 kernel_size\n",
        "pl = MaxPool2D((16, 16))(cov) # max pooling operation for 2D spatial data with 16 by 16 pool_size\n",
        "# add dropout after pooling\n",
        "pl = Dropout(0.5)(pl) # 20% dropout rate\n",
        "flattened = Flatten()(pl) # flatten input to 1D array\n",
        "\n",
        "\n",
        "# fusion:\n",
        "fused = tf.concat([gru, flattened], axis=-1) # concatenate tensors along one dimension, switched 'averaged' to 'gru'\n",
        "\n",
        "# multi-objectives (each is a multi-class classification)\n",
        "p_price = Dense(len_price, activation='softmax', name='price')(fused) # dense layer with units equal to number of unique items in price category, softmax activation function\n",
        "p_type = Dense(len_type, activation='softmax', name='type')(fused) # dense layer with units equal to number of unique items in type category, softmax activation\n",
        "\n",
        "# create model by specifying inputs and outputs\n",
        "model = keras.Model(\n",
        "    inputs={\n",
        "        'summary': in_text, # input text is listing summary\n",
        "        'image': in_image # input image\n",
        "    },\n",
        "    outputs={\n",
        "        'price': p_price, # output predicted price\n",
        "        'type': p_type, # output predicted type\n",
        "    },\n",
        ")\n",
        "\n",
        "# configure model\n",
        "model.compile(\n",
        "    optimizer=Adam(), # use 'Adam' optimizer\n",
        "    loss={\n",
        "        'price': 'sparse_categorical_crossentropy', # loss for 'price' output\n",
        "        'type': 'sparse_categorical_crossentropy', # loss for 'type' output\n",
        "    },\n",
        "    loss_weights={\n",
        "        'price': 0.5, # weight for 'price' loss\n",
        "        'type': 0.5, # weight for 'type' loss\n",
        "    },\n",
        "    metrics={\n",
        "        'price': ['SparseCategoricalAccuracy'], # metric for 'price'\n",
        "        'type': ['SparseCategoricalAccuracy'], # metric for 'type'\n",
        "    },\n",
        ")\n",
        "\n",
        "# summary for model\n",
        "model.summary()\n",
        "\n",
        "#===============================================================================\n",
        "\n",
        "# fit model on data while monitoring performance on a validation split of 0.2\n",
        "history = model.fit(\n",
        "    x={\n",
        "        'summary': x_tr_text_id, # text training data\n",
        "        'image': x_tr_image # image training data\n",
        "    },\n",
        "    y={\n",
        "        'price': y_tr_price, # text training target data\n",
        "        'type': y_tr_type, # type training target data\n",
        "    },\n",
        "    epochs=20, # 20 cycles through training data\n",
        "    batch_size=16, # number of samples processed before model is updated\n",
        "    validation_data=(\n",
        "        {\n",
        "            'summary': x_vl_text_id, # text validation data\n",
        "            'image': x_vl_image # image validation data\n",
        "         },\n",
        "        {\n",
        "            'price': y_vl_price, # price validation target data\n",
        "            'type': y_vl_type, # type validation target data\n",
        "        }),\n",
        "    validation_split=0.2, # split training and validation 80/20\n",
        "    callbacks=[ # stop training when monitored metric has stopped improving after specified number of epochs\n",
        "        tf.keras.callbacks.EarlyStopping(monitor='val_price_loss', patience=5, ) # monitor loss for validation price with patience of 5 epochs\n",
        "    ],\n",
        "    verbose=1 # progress bar\n",
        ")\n",
        "\n",
        "#===============================================================================\n",
        "\n",
        "# preprocess test data for text and image\n",
        "x_test_summary = _preprocess(x_test_df.summary.astype(str)) # preprocess test summary data\n",
        "x_test_image = np.array([load_image(i) for i in tqdm(x_test_df.image)]) # load test images as arrays with progress bar\n",
        "\n",
        "# scale images for test data to range of 0 to 1\n",
        "x_test_image = x_test_image/64.0\n",
        "\n",
        "#===============================================================================\n",
        "\n",
        "\n",
        "# evaluate model on test data\n",
        "y_predict = model.predict( # use model to predict\n",
        "    {\n",
        "        'summary': x_test_summary, # text test data\n",
        "        'image': x_test_image # image test data\n",
        "    }\n",
        ")\n",
        "\n",
        "price_predicted = y_predict['price'] # target prediction\n",
        "# print(price_predicted) # print predictions\n",
        "price_category_predicted = np.argmax(price_predicted, axis=1) # return indices of maximum values along an axis\n",
        "# print(price_category_predicted) # print predicted categories for targets\n",
        "\n",
        "# create submission\n",
        "pd.DataFrame(\n",
        "    {'id': x_test_df.id,\n",
        "     'price': price_category_predicted}).to_csv('sample_submission3.csv', index=False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "cd0f95b3d4da4a058d7a58e8bc003a4d",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "  0%|          | 0/7627 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NaVyRlmzsmtL"
      },
      "source": [
        "### **Trial3**\n",
        "\n",
        "Trial2 results:\n",
        "\n",
        "val_price_loss: 0.8479 , does not improve after fifth epoch\n",
        "\n",
        "type_sparse_categorical_accuracy: 0.7434\n",
        "\n",
        "val_type_sparse_categorical_accuracy: 0.7666\n",
        "\n",
        "Swapping the original reduce_mean layer with a GRU layer with units=4 seems to have resulted in some underfitting. I will try increasing the units to 100 to see if the model performance increases.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "09ad639cf5954ed498906591ed5df2bf",
            "cac3a555a5e645fa8cd528e300de5d15",
            "ae9ccce96a6746f881a6821d056d3b93",
            "c8cbd4c7e9ed407fb9fe384bfa75a4fa",
            "35124d8919404b5c9920ddd3d849703b",
            "9540cede07684adc9ef01afbf20e0022",
            "087fa2c7acb5470681fe6e73a2879a78",
            "d1f37b2a7b8741f7a0f22ed557d94406",
            "a193d59bc6eb41778b3eec315592425d",
            "5dde69f8d6fc45b8842a612337405afd",
            "cd99cf4f380c45e097c19da2a5544fd5",
            "3bcb4450b3c74d49a7741b3bc98eb7d5"
          ]
        },
        "id": "5T9im7a-spas",
        "outputId": "b51eb69d-5bb4-4b21-d775-7a65817b71f4"
      },
      "source": [
        "# Trial code cell\n",
        "\n",
        "# load modules\n",
        "import os\n",
        "\n",
        "import pandas as pd\n",
        "from tqdm.notebook import tqdm\n",
        "from PIL import Image\n",
        "import pandas as pd\n",
        "import os\n",
        "import numpy as np\n",
        "\n",
        "xy_train_df = pd.read_csv('train_xy.csv') # read training data into dataframe\n",
        "x_test_df = pd.read_csv('test_x.csv') # read test data into dataframe\n",
        "\n",
        "#===============================================================================\n",
        "\n",
        "# preprocess image data\n",
        "\n",
        "def load_image(file): # create function for loading images\n",
        "    try: # try this code\n",
        "        image = Image.open( # open and identify image file\n",
        "            file\n",
        "        ).convert('LA').resize((64, 64)) # convert to greyscale with alpha channel, resize to 64 by 64 pixels\n",
        "        arr = np.array(image) # return 3D array of image\n",
        "    except: # execute this code when an exception arises\n",
        "        arr = np.zeros((64, 64, 2)) # create 3D array of zeros with shape as (x,y,z)\n",
        "    return arr # return array\n",
        "\n",
        "\n",
        "# loading images:\n",
        "x_image = np.array([load_image(i) for i in tqdm(xy_train_df.image)]) # load training images as arrays with progress bar\n",
        "\n",
        "# loading summary: (force convert some of the non-string cell to string)\n",
        "x_text = xy_train_df.summary.astype('str')\n",
        "\n",
        "\n",
        "#===============================================================================\n",
        "\n",
        "from sklearn.model_selection import train_test_split # import function from module\n",
        "\n",
        "# labels:\n",
        "y_price = xy_train_df.price # subset price column\n",
        "y_type = xy_train_df.type.astype('category').cat.codes # encode type category variables\n",
        "len_price = len(y_price.unique()) # number of unique items in price category\n",
        "len_type = len(y_type.unique()) # number of unique items in type category\n",
        "# print('unique values for price category', len_price, y_price.unique()) # print number of unique items and values for price category\n",
        "# print('unique values for type category', len_type, y_type.unique()) # print number of unique items and values for type category\n",
        "\n",
        "# splitting:\n",
        "\n",
        "x_tr_image, x_vl_image, x_tr_text, x_vl_text, y_tr_price, y_vl_price, y_tr_type, y_vl_type = train_test_split(\n",
        "    x_image, # split image arrays into random train and validation subsets\n",
        "    x_text, # split series into random train and validation subsets\n",
        "    y_price, # split series into random train and validation subsets\n",
        "    y_type, # split series into random train and validation subsets\n",
        "    test_size=0.2) # training 80% validation/test 20% of data\n",
        "\n",
        "# scale image values to range of 0 to 1\n",
        "x_tr_image = x_tr_image/64.0\n",
        "x_vl_image = x_vl_image/64.0\n",
        "\n",
        "# print(np.shape(x_tr_image)) # print independent image feature training set shape\n",
        "# print(np.shape(x_vl_image)) # print independent image feature validation set shape\n",
        "# print(np.shape(y_tr_price)) # print dependent price feature training set shape\n",
        "# print(np.shape(y_vl_price)) # print dependent price feature validation set shape\n",
        "# print(np.shape(y_tr_type)) # print dependent type feature training set shape\n",
        "# print(np.shape(y_vl_type)) # print dependent type feature validation set shape\n",
        "\n",
        "#===============================================================================\n",
        "\n",
        "# preprocess text data\n",
        "\n",
        "# import modules and functions\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from sklearn.model_selection import train_test_split\n",
        "from pprint import pprint\n",
        "\n",
        "vocab_size = 40000 # set vocab_size variable to 40000\n",
        "max_len = 100 # # set max_len variable to 100\n",
        "\n",
        "\n",
        "# build vocabulary from training set\n",
        "tokenizer = Tokenizer(num_words=vocab_size) # set max number of words to keep for text tokenization\n",
        "tokenizer.fit_on_texts(x_tr_text) # create vocabulary index based on word frequency\n",
        "\n",
        "# create preprocessing function for text list\n",
        "def _preprocess(list_of_text): # param: list_of_text\n",
        "    return pad_sequences( # return padded sequences with same length\n",
        "        tokenizer.texts_to_sequences(list_of_text), # transforms each text to sequence of integers\n",
        "        maxlen=max_len, # set maximum length of all sequences\n",
        "        padding='post', # set to pad end of sequences\n",
        "    )\n",
        "\n",
        "\n",
        "# padding is done inside:\n",
        "x_tr_text_id = _preprocess(x_tr_text)\n",
        "x_vl_text_id = _preprocess(x_vl_text)\n",
        "\n",
        "# # print shapes of padded arrays\n",
        "# print(x_tr_text_id.shape)\n",
        "# print(x_vl_text_id.shape)\n",
        "\n",
        "#===============================================================================\n",
        "\n",
        "# import modules and functions\n",
        "from __future__ import absolute_import, division, print_function, unicode_literals\n",
        "import collections\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.layers import Conv2D, Flatten, Dense, MaxPool2D, Dropout # import dropout layer\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "# set input text and image shapes\n",
        "in_text = keras.Input(batch_shape=(None, max_len)) # set max length for input text\n",
        "in_image = keras.Input(batch_shape=(None, 64, 64, 2)) # set shape for input image\n",
        "\n",
        "# text part\n",
        "embedded = keras.layers.Embedding(tokenizer.num_words, 100)(in_text) # turn positive integers (indexes) into dense vectors of fixed size\n",
        "# averaged = tf.reduce_mean(embedded, axis=1) # reduce input_tensor along dimensions given in axis using mean of elements across dimensions in axis\n",
        "\n",
        "# GRU layer\n",
        "gru = tf.keras.layers.GRU(100)(embedded) # GRU layer with 100 units\n",
        "\n",
        "# image part\n",
        "cov = Conv2D(32, (16, 16))(in_image) # 2D convolution layer with 32 filters and 16 by 16 kernel_size\n",
        "pl = MaxPool2D((16, 16))(cov) # max pooling operation for 2D spatial data with 16 by 16 pool_size\n",
        "# add dropout after pooling\n",
        "pl = Dropout(0.5)(pl) # 50% dropout rate\n",
        "flattened = Flatten()(pl) # flatten input to 1D array\n",
        "\n",
        "\n",
        "# fusion:\n",
        "fused = tf.concat([gru, flattened], axis=-1) # concatenate tensors along one dimension, switched 'averaged' to 'gru'\n",
        "\n",
        "# multi-objectives (each is a multi-class classification)\n",
        "p_price = Dense(len_price, activation='softmax', name='price')(fused) # dense layer with units equal to number of unique items in price category, softmax activation function\n",
        "p_type = Dense(len_type, activation='softmax', name='type')(fused) # dense layer with units equal to number of unique items in type category, softmax activation\n",
        "\n",
        "# create model by specifying inputs and outputs\n",
        "model = keras.Model(\n",
        "    inputs={\n",
        "        'summary': in_text, # input text is listing summary\n",
        "        'image': in_image # input image\n",
        "    },\n",
        "    outputs={\n",
        "        'price': p_price, # output predicted price\n",
        "        'type': p_type, # output predicted type\n",
        "    },\n",
        ")\n",
        "\n",
        "# configure model\n",
        "model.compile(\n",
        "    optimizer=Adam(), # use 'Adam' optimizer\n",
        "    loss={\n",
        "        'price': 'sparse_categorical_crossentropy', # loss for 'price' output\n",
        "        'type': 'sparse_categorical_crossentropy', # loss for 'type' output\n",
        "    },\n",
        "    loss_weights={\n",
        "        'price': 0.5, # weight for 'price' loss\n",
        "        'type': 0.5, # weight for 'type' loss\n",
        "    },\n",
        "    metrics={\n",
        "        'price': ['SparseCategoricalAccuracy'], # metric for 'price'\n",
        "        'type': ['SparseCategoricalAccuracy'], # metric for 'type'\n",
        "    },\n",
        ")\n",
        "\n",
        "# summary for model\n",
        "model.summary()\n",
        "\n",
        "#===============================================================================\n",
        "\n",
        "# fit model on data while monitoring performance on a validation split of 0.2\n",
        "history = model.fit(\n",
        "    x={\n",
        "        'summary': x_tr_text_id, # text training data\n",
        "        'image': x_tr_image # image training data\n",
        "    },\n",
        "    y={\n",
        "        'price': y_tr_price, # text training target data\n",
        "        'type': y_tr_type, # type training target data\n",
        "    },\n",
        "    epochs=20, # 20 cycles through training data\n",
        "    batch_size=16, # number of samples processed before model is updated\n",
        "    validation_data=(\n",
        "        {\n",
        "            'summary': x_vl_text_id, # text validation data\n",
        "            'image': x_vl_image # image validation data\n",
        "         },\n",
        "        {\n",
        "            'price': y_vl_price, # price validation target data\n",
        "            'type': y_vl_type, # type validation target data\n",
        "        }),\n",
        "    validation_split=0.2, # split training and validation 80/20\n",
        "    callbacks=[ # stop training when monitored metric has stopped improving after specified number of epochs\n",
        "        tf.keras.callbacks.EarlyStopping(monitor='val_price_loss', patience=5, ) # monitor loss for validation price with patience of 5 epochs\n",
        "    ],\n",
        "    verbose=1 # progress bar\n",
        ")\n",
        "\n",
        "#===============================================================================\n",
        "\n",
        "# preprocess test data for text and image\n",
        "x_test_summary = _preprocess(x_test_df.summary.astype(str)) # preprocess test summary data\n",
        "x_test_image = np.array([load_image(i) for i in tqdm(x_test_df.image)]) # load test images as arrays with progress bar\n",
        "\n",
        "# scale images for test data to range of 0 to 1\n",
        "x_test_image = x_test_image/64.0\n",
        "\n",
        "#===============================================================================\n",
        "\n",
        "\n",
        "# evaluate model on test data\n",
        "y_predict = model.predict( # use model to predict\n",
        "    {\n",
        "        'summary': x_test_summary, # text test data\n",
        "        'image': x_test_image # image test data\n",
        "    }\n",
        ")\n",
        "\n",
        "price_predicted = y_predict['price'] # target prediction\n",
        "# print(price_predicted) # print predictions\n",
        "price_category_predicted = np.argmax(price_predicted, axis=1) # return indices of maximum values along an axis\n",
        "# print(price_category_predicted) # print predicted categories for targets\n",
        "\n",
        "# create submission\n",
        "pd.DataFrame(\n",
        "    {'id': x_test_df.id,\n",
        "     'price': price_category_predicted}).to_csv('sample_submission3.csv', index=False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "09ad639cf5954ed498906591ed5df2bf",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/7627 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_2 (InputLayer)           [(None, 64, 64, 2)]  0           []                               \n",
            "                                                                                                  \n",
            " conv2d (Conv2D)                (None, 49, 49, 32)   16416       ['input_2[0][0]']                \n",
            "                                                                                                  \n",
            " input_1 (InputLayer)           [(None, 100)]        0           []                               \n",
            "                                                                                                  \n",
            " max_pooling2d (MaxPooling2D)   (None, 3, 3, 32)     0           ['conv2d[0][0]']                 \n",
            "                                                                                                  \n",
            " embedding (Embedding)          (None, 100, 100)     4000000     ['input_1[0][0]']                \n",
            "                                                                                                  \n",
            " dropout (Dropout)              (None, 3, 3, 32)     0           ['max_pooling2d[0][0]']          \n",
            "                                                                                                  \n",
            " gru (GRU)                      (None, 100)          60600       ['embedding[0][0]']              \n",
            "                                                                                                  \n",
            " flatten (Flatten)              (None, 288)          0           ['dropout[0][0]']                \n",
            "                                                                                                  \n",
            " tf.concat (TFOpLambda)         (None, 388)          0           ['gru[0][0]',                    \n",
            "                                                                  'flatten[0][0]']                \n",
            "                                                                                                  \n",
            " price (Dense)                  (None, 3)            1167        ['tf.concat[0][0]']              \n",
            "                                                                                                  \n",
            " type (Dense)                   (None, 24)           9336        ['tf.concat[0][0]']              \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 4,087,519\n",
            "Trainable params: 4,087,519\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "Epoch 1/20\n",
            "305/305 [==============================] - 80s 254ms/step - loss: 1.3277 - price_loss: 1.2151 - type_loss: 1.4404 - price_sparse_categorical_accuracy: 0.5275 - type_sparse_categorical_accuracy: 0.6904 - val_loss: 0.9798 - val_price_loss: 0.8533 - val_type_loss: 1.1062 - val_price_sparse_categorical_accuracy: 0.6323 - val_type_sparse_categorical_accuracy: 0.7666\n",
            "Epoch 2/20\n",
            "305/305 [==============================] - 78s 255ms/step - loss: 1.0566 - price_loss: 0.9581 - type_loss: 1.1552 - price_sparse_categorical_accuracy: 0.5664 - type_sparse_categorical_accuracy: 0.7307 - val_loss: 0.9137 - val_price_loss: 0.8053 - val_type_loss: 1.0222 - val_price_sparse_categorical_accuracy: 0.6298 - val_type_sparse_categorical_accuracy: 0.7666\n",
            "Epoch 3/20\n",
            "305/305 [==============================] - 77s 253ms/step - loss: 0.9641 - price_loss: 0.8441 - type_loss: 1.0840 - price_sparse_categorical_accuracy: 0.6262 - type_sparse_categorical_accuracy: 0.7350 - val_loss: 0.9121 - val_price_loss: 0.7774 - val_type_loss: 1.0468 - val_price_sparse_categorical_accuracy: 0.6454 - val_type_sparse_categorical_accuracy: 0.7666\n",
            "Epoch 4/20\n",
            "305/305 [==============================] - 78s 257ms/step - loss: 0.8785 - price_loss: 0.7482 - type_loss: 1.0087 - price_sparse_categorical_accuracy: 0.6734 - type_sparse_categorical_accuracy: 0.7463 - val_loss: 0.8541 - val_price_loss: 0.7701 - val_type_loss: 0.9381 - val_price_sparse_categorical_accuracy: 0.6675 - val_type_sparse_categorical_accuracy: 0.7699\n",
            "Epoch 5/20\n",
            "305/305 [==============================] - 78s 256ms/step - loss: 0.8125 - price_loss: 0.6761 - type_loss: 0.9490 - price_sparse_categorical_accuracy: 0.7055 - type_sparse_categorical_accuracy: 0.7516 - val_loss: 0.8854 - val_price_loss: 0.8127 - val_type_loss: 0.9580 - val_price_sparse_categorical_accuracy: 0.6454 - val_type_sparse_categorical_accuracy: 0.7641\n",
            "Epoch 6/20\n",
            "305/305 [==============================] - 77s 251ms/step - loss: 0.7276 - price_loss: 0.5894 - type_loss: 0.8658 - price_sparse_categorical_accuracy: 0.7568 - type_sparse_categorical_accuracy: 0.7592 - val_loss: 0.9589 - val_price_loss: 0.8946 - val_type_loss: 1.0232 - val_price_sparse_categorical_accuracy: 0.6683 - val_type_sparse_categorical_accuracy: 0.7707\n",
            "Epoch 7/20\n",
            "305/305 [==============================] - 106s 349ms/step - loss: 0.6397 - price_loss: 0.4886 - type_loss: 0.7908 - price_sparse_categorical_accuracy: 0.8059 - type_sparse_categorical_accuracy: 0.7816 - val_loss: 0.9982 - val_price_loss: 0.9164 - val_type_loss: 1.0800 - val_price_sparse_categorical_accuracy: 0.6544 - val_type_sparse_categorical_accuracy: 0.6847\n",
            "Epoch 8/20\n",
            "305/305 [==============================] - 106s 347ms/step - loss: 0.5616 - price_loss: 0.4122 - type_loss: 0.7109 - price_sparse_categorical_accuracy: 0.8432 - type_sparse_categorical_accuracy: 0.7992 - val_loss: 1.0600 - val_price_loss: 1.1055 - val_type_loss: 1.0146 - val_price_sparse_categorical_accuracy: 0.6773 - val_type_sparse_categorical_accuracy: 0.7322\n",
            "Epoch 9/20\n",
            "305/305 [==============================] - 83s 273ms/step - loss: 0.4989 - price_loss: 0.3569 - type_loss: 0.6409 - price_sparse_categorical_accuracy: 0.8619 - type_sparse_categorical_accuracy: 0.8113 - val_loss: 1.1163 - val_price_loss: 1.1776 - val_type_loss: 1.0550 - val_price_sparse_categorical_accuracy: 0.6544 - val_type_sparse_categorical_accuracy: 0.7559\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "3bcb4450b3c74d49a7741b3bc98eb7d5",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/7360 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ub7qrrpE9G-R"
      },
      "source": [
        "### **Trial4**\n",
        "\n",
        "Trial3 results:\n",
        "\n",
        "Epoch 5/20: Does not improve after fifth epoch<br> - 78s 256ms/step<br> - loss: 0.8125<br> - price_loss: 0.6761<br> - type_loss: 0.9490<br> - price_sparse_categorical_accuracy: 0.7055<br> - type_sparse_categorical_accuracy: 0.7516<br> - val_loss: 0.8854<br> - val_price_loss: 0.8127<br> - val_type_loss: 0.9580<br> - val_price_sparse_categorical_accuracy: 0.6454<br> - val_type_sparse_categorical_accuracy: 0.7641\n",
        "\n",
        "Setting GRU units=100 seemed to yield similar results as trial 2, but the training and validation categorical accuracy scores are closer. There appears to be less underfitting.\n",
        "\n",
        "\n",
        "This trial I will explore using a BiDirectional Recurrent layer for the text layers. I predict that with the right pararmeters, the model performance should increase."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 946,
          "referenced_widgets": [
            "9ff140905e57422cb5ca19867338be5b",
            "2bd9fa89e2fe411db7cdc85798d44b85",
            "f24c091632944478a664420a521226f3",
            "1c79a82c17c940d4902450220729ffa2",
            "445590ec268840f0825631fc34f1a7b0",
            "65dcb22151fb493e98e09a1f249ac1a0",
            "b8e7bb47080b4321bb6cc40493291788",
            "3c1d01dbce3b4d5e987fc22ae7a33d79",
            "b2dbec4bc10542d3afb31539b0d70238",
            "81df72c43ec942a59d3c6d4aa847a76b",
            "a172bcbef1bb4bd9b523c7d79f2bd993",
            "17dd8f70f6804bb988a3c6e1153c922a",
            "2fb56b53c22546b2891e7dcac88a08b1",
            "c33442490c344236ada9baa8a969fe7f",
            "f50b48791b78418cbc8da0c6f9e4b39e",
            "00897492ec8e440c9eb4c3badfcda5e3",
            "b3c0ab07c09544e28c77e05e5c366692",
            "74a06df1e5714dfe9ecc65aff9387aec",
            "ee46281013f8444c9f5fef7be0e63bb4",
            "4d58a01e841543c9807f30cdb937a3ff",
            "ca8a629af0b4499d93c22c42bbab5e02",
            "9bb4f86196c546c0b5a729ee485f9aee"
          ]
        },
        "id": "I2oAjeMgCj-x",
        "outputId": "47ea15ad-8c78-4789-c31c-ba377a2c5f62"
      },
      "source": [
        "# Trial code cell\n",
        "\n",
        "# load modules\n",
        "import os\n",
        "\n",
        "import pandas as pd\n",
        "from tqdm.notebook import tqdm\n",
        "from PIL import Image\n",
        "import pandas as pd\n",
        "import os\n",
        "import numpy as np\n",
        "\n",
        "xy_train_df = pd.read_csv('train_xy.csv') # read training data into dataframe\n",
        "x_test_df = pd.read_csv('test_x.csv') # read test data into dataframe\n",
        "\n",
        "#===============================================================================\n",
        "\n",
        "# preprocess image data\n",
        "\n",
        "def load_image(file): # create function for loading images\n",
        "    try: # try this code\n",
        "        image = Image.open( # open and identify image file\n",
        "            file\n",
        "        ).convert('LA').resize((64, 64)) # convert to greyscale with alpha channel, resize to 64 by 64 pixels\n",
        "        arr = np.array(image) # return 3D array of image\n",
        "    except: # execute this code when an exception arises\n",
        "        arr = np.zeros((64, 64, 2)) # create 3D array of zeros with shape as (x,y,z)\n",
        "    return arr # return array\n",
        "\n",
        "\n",
        "# loading images:\n",
        "x_image = np.array([load_image(i) for i in tqdm(xy_train_df.image)]) # load training images as arrays with progress bar\n",
        "\n",
        "# loading summary: (force convert some of the non-string cell to string)\n",
        "x_text = xy_train_df.summary.astype('str')\n",
        "\n",
        "\n",
        "#===============================================================================\n",
        "\n",
        "from sklearn.model_selection import train_test_split # import function from module\n",
        "\n",
        "# labels:\n",
        "y_price = xy_train_df.price # subset price column\n",
        "y_type = xy_train_df.type.astype('category').cat.codes # encode type category variables\n",
        "len_price = len(y_price.unique()) # number of unique items in price category\n",
        "len_type = len(y_type.unique()) # number of unique items in type category\n",
        "# print('unique values for price category', len_price, y_price.unique()) # print number of unique items and values for price category\n",
        "# print('unique values for type category', len_type, y_type.unique()) # print number of unique items and values for type category\n",
        "\n",
        "# splitting:\n",
        "\n",
        "x_tr_image, x_vl_image, x_tr_text, x_vl_text, y_tr_price, y_vl_price, y_tr_type, y_vl_type = train_test_split(\n",
        "    x_image, # split image arrays into random train and validation subsets\n",
        "    x_text, # split series into random train and validation subsets\n",
        "    y_price, # split series into random train and validation subsets\n",
        "    y_type, # split series into random train and validation subsets\n",
        "    test_size=0.2) # training 80% validation/test 20% of data\n",
        "\n",
        "# scale image values to range of 0 to 1\n",
        "x_tr_image = x_tr_image/64.0\n",
        "x_vl_image = x_vl_image/64.0\n",
        "\n",
        "# print(np.shape(x_tr_image)) # print independent image feature training set shape\n",
        "# print(np.shape(x_vl_image)) # print independent image feature validation set shape\n",
        "# print(np.shape(y_tr_price)) # print dependent price feature training set shape\n",
        "# print(np.shape(y_vl_price)) # print dependent price feature validation set shape\n",
        "# print(np.shape(y_tr_type)) # print dependent type feature training set shape\n",
        "# print(np.shape(y_vl_type)) # print dependent type feature validation set shape\n",
        "\n",
        "#===============================================================================\n",
        "\n",
        "# preprocess text data\n",
        "\n",
        "# import modules and functions\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from sklearn.model_selection import train_test_split\n",
        "from pprint import pprint\n",
        "\n",
        "vocab_size = 40000 # set vocab_size variable to 40000\n",
        "max_len = 100 # # set max_len variable to 100\n",
        "\n",
        "\n",
        "# build vocabulary from training set\n",
        "tokenizer = Tokenizer(num_words=vocab_size) # set max number of words to keep for text tokenization\n",
        "tokenizer.fit_on_texts(x_tr_text) # create vocabulary index based on word frequency\n",
        "\n",
        "# create preprocessing function for text list\n",
        "def _preprocess(list_of_text): # param: list_of_text\n",
        "    return pad_sequences( # return padded sequences with same length\n",
        "        tokenizer.texts_to_sequences(list_of_text), # transforms each text to sequence of integers\n",
        "        maxlen=max_len, # set maximum length of all sequences\n",
        "        padding='post', # set to pad end of sequences\n",
        "    )\n",
        "\n",
        "\n",
        "# padding is done inside:\n",
        "x_tr_text_id = _preprocess(x_tr_text)\n",
        "x_vl_text_id = _preprocess(x_vl_text)\n",
        "\n",
        "# # print shapes of padded arrays\n",
        "# print(x_tr_text_id.shape)\n",
        "# print(x_vl_text_id.shape)\n",
        "\n",
        "#===============================================================================\n",
        "\n",
        "# import modules and functions\n",
        "from __future__ import absolute_import, division, print_function, unicode_literals\n",
        "import collections\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.layers import Conv2D, Flatten, Dense, MaxPool2D, Dropout # import dropout layer\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "# set input text and image shapes\n",
        "in_text = keras.Input(batch_shape=(None, max_len)) # set max length for input text\n",
        "in_image = keras.Input(batch_shape=(None, 64, 64, 2)) # set shape for input image\n",
        "\n",
        "# text part\n",
        "embedded = keras.layers.Embedding(tokenizer.num_words, 100)(in_text) # turn positive integers (indexes) into dense vectors of fixed size\n",
        "# averaged = tf.reduce_mean(embedded, axis=1) # reduce input_tensor along dimensions given in axis using mean of elements across dimensions in axis\n",
        "\n",
        "# GRU layer with Bidirectional wrapper\n",
        "# gru = tf.keras.layers.GRU(100)(embedded) # GRU layer with 100 units\n",
        "BiGRU = tf.keras.layers.Bidirectional(tf.keras.layers.GRU(100))(embedded) # gru with units=100 and bidirectional wrapper\n",
        "\n",
        "# image part\n",
        "cov = Conv2D(32, (16, 16))(in_image) # 2D convolution layer with 32 filters and 16 by 16 kernel_size\n",
        "pl = MaxPool2D((16, 16))(cov) # max pooling operation for 2D spatial data with 16 by 16 pool_size\n",
        "# add dropout after pooling\n",
        "pl = Dropout(0.5)(pl) # 50% dropout rate\n",
        "flattened = Flatten()(pl) # flatten input to 1D array\n",
        "\n",
        "\n",
        "# fusion:\n",
        "fused = tf.concat([BiGRU, flattened], axis=-1) # concatenate tensors along one dimension, switched 'gr' to 'BiGRU'\n",
        "\n",
        "# multi-objectives (each is a multi-class classification)\n",
        "p_price = Dense(len_price, activation='softmax', name='price')(fused) # dense layer with units equal to number of unique items in price category, softmax activation function\n",
        "p_type = Dense(len_type, activation='softmax', name='type')(fused) # dense layer with units equal to number of unique items in type category, softmax activation\n",
        "\n",
        "# create model by specifying inputs and outputs\n",
        "model = keras.Model(\n",
        "    inputs={\n",
        "        'summary': in_text, # input text is listing summary\n",
        "        'image': in_image # input image\n",
        "    },\n",
        "    outputs={\n",
        "        'price': p_price, # output predicted price\n",
        "        'type': p_type, # output predicted type\n",
        "    },\n",
        ")\n",
        "\n",
        "# configure model\n",
        "model.compile(\n",
        "    optimizer=Adam(), # use 'Adam' optimizer\n",
        "    loss={\n",
        "        'price': 'sparse_categorical_crossentropy', # loss for 'price' output\n",
        "        'type': 'sparse_categorical_crossentropy', # loss for 'type' output\n",
        "    },\n",
        "    loss_weights={\n",
        "        'price': 0.5, # weight for 'price' loss\n",
        "        'type': 0.5, # weight for 'type' loss\n",
        "    },\n",
        "    metrics={\n",
        "        'price': ['SparseCategoricalAccuracy'], # metric for 'price'\n",
        "        'type': ['SparseCategoricalAccuracy'], # metric for 'type'\n",
        "    },\n",
        ")\n",
        "\n",
        "# summary for model\n",
        "model.summary()\n",
        "\n",
        "#===============================================================================\n",
        "\n",
        "# fit model on data while monitoring performance on a validation split of 0.2\n",
        "history = model.fit(\n",
        "    x={\n",
        "        'summary': x_tr_text_id, # text training data\n",
        "        'image': x_tr_image # image training data\n",
        "    },\n",
        "    y={\n",
        "        'price': y_tr_price, # text training target data\n",
        "        'type': y_tr_type, # type training target data\n",
        "    },\n",
        "    epochs=20, # 20 cycles through training data\n",
        "    batch_size=16, # number of samples processed before model is updated\n",
        "    validation_data=(\n",
        "        {\n",
        "            'summary': x_vl_text_id, # text validation data\n",
        "            'image': x_vl_image # image validation data\n",
        "         },\n",
        "        {\n",
        "            'price': y_vl_price, # price validation target data\n",
        "            'type': y_vl_type, # type validation target data\n",
        "        }),\n",
        "    validation_split=0.2, # split training and validation 80/20\n",
        "    callbacks=[ # stop training when monitored metric has stopped improving after specified number of epochs\n",
        "        tf.keras.callbacks.EarlyStopping(monitor='val_price_loss', patience=5, ) # monitor loss for validation price with patience of 5 epochs\n",
        "    ],\n",
        "    verbose=1 # progress bar\n",
        ")\n",
        "\n",
        "#===============================================================================\n",
        "\n",
        "# preprocess test data for text and image\n",
        "x_test_summary = _preprocess(x_test_df.summary.astype(str)) # preprocess test summary data\n",
        "x_test_image = np.array([load_image(i) for i in tqdm(x_test_df.image)]) # load test images as arrays with progress bar\n",
        "\n",
        "# scale images for test data to range of 0 to 1\n",
        "x_test_image = x_test_image/64.0\n",
        "\n",
        "#===============================================================================\n",
        "\n",
        "\n",
        "# evaluate model on test data\n",
        "y_predict = model.predict( # use model to predict\n",
        "    {\n",
        "        'summary': x_test_summary, # text test data\n",
        "        'image': x_test_image # image test data\n",
        "    }\n",
        ")\n",
        "\n",
        "price_predicted = y_predict['price'] # target prediction\n",
        "# print(price_predicted) # print predictions\n",
        "price_category_predicted = np.argmax(price_predicted, axis=1) # return indices of maximum values along an axis\n",
        "# print(price_category_predicted) # print predicted categories for targets\n",
        "\n",
        "# create submission\n",
        "pd.DataFrame(\n",
        "    {'id': x_test_df.id,\n",
        "     'price': price_category_predicted}).to_csv('sample_submission4.csv', index=False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "9ff140905e57422cb5ca19867338be5b",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "  0%|          | 0/7627 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_2 (InputLayer)           [(None, 64, 64, 2)]  0           []                               \n",
            "                                                                                                  \n",
            " conv2d (Conv2D)                (None, 49, 49, 32)   16416       ['input_2[0][0]']                \n",
            "                                                                                                  \n",
            " input_1 (InputLayer)           [(None, 100)]        0           []                               \n",
            "                                                                                                  \n",
            " max_pooling2d (MaxPooling2D)   (None, 3, 3, 32)     0           ['conv2d[0][0]']                 \n",
            "                                                                                                  \n",
            " embedding (Embedding)          (None, 100, 100)     4000000     ['input_1[0][0]']                \n",
            "                                                                                                  \n",
            " dropout (Dropout)              (None, 3, 3, 32)     0           ['max_pooling2d[0][0]']          \n",
            "                                                                                                  \n",
            " bidirectional (Bidirectional)  (None, 200)          121200      ['embedding[0][0]']              \n",
            "                                                                                                  \n",
            " flatten (Flatten)              (None, 288)          0           ['dropout[0][0]']                \n",
            "                                                                                                  \n",
            " tf.concat (TFOpLambda)         (None, 488)          0           ['bidirectional[0][0]',          \n",
            "                                                                  'flatten[0][0]']                \n",
            "                                                                                                  \n",
            " price (Dense)                  (None, 3)            1467        ['tf.concat[0][0]']              \n",
            "                                                                                                  \n",
            " type (Dense)                   (None, 24)           11736       ['tf.concat[0][0]']              \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 4,150,819\n",
            "Trainable params: 4,150,819\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "Epoch 1/20\n",
            "305/305 [==============================] - 95s 299ms/step - loss: 1.2160 - price_loss: 1.1260 - type_loss: 1.3060 - price_sparse_categorical_accuracy: 0.5549 - type_sparse_categorical_accuracy: 0.7105 - val_loss: 0.8697 - val_price_loss: 0.7845 - val_type_loss: 0.9550 - val_price_sparse_categorical_accuracy: 0.6167 - val_type_sparse_categorical_accuracy: 0.7641\n",
            "Epoch 2/20\n",
            "305/305 [==============================] - 90s 294ms/step - loss: 0.8974 - price_loss: 0.8246 - type_loss: 0.9703 - price_sparse_categorical_accuracy: 0.6516 - type_sparse_categorical_accuracy: 0.7416 - val_loss: 0.8862 - val_price_loss: 0.7739 - val_type_loss: 0.9985 - val_price_sparse_categorical_accuracy: 0.6552 - val_type_sparse_categorical_accuracy: 0.7387\n",
            "Epoch 3/20\n",
            "305/305 [==============================] - 89s 292ms/step - loss: 0.7358 - price_loss: 0.6757 - type_loss: 0.7960 - price_sparse_categorical_accuracy: 0.7170 - type_sparse_categorical_accuracy: 0.7811 - val_loss: 0.8620 - val_price_loss: 0.7947 - val_type_loss: 0.9293 - val_price_sparse_categorical_accuracy: 0.6421 - val_type_sparse_categorical_accuracy: 0.7830\n",
            "Epoch 4/20\n",
            "305/305 [==============================] - 88s 288ms/step - loss: 0.6304 - price_loss: 0.5844 - type_loss: 0.6765 - price_sparse_categorical_accuracy: 0.7564 - type_sparse_categorical_accuracy: 0.8117 - val_loss: 0.9363 - val_price_loss: 0.8921 - val_type_loss: 0.9806 - val_price_sparse_categorical_accuracy: 0.6609 - val_type_sparse_categorical_accuracy: 0.7789\n",
            "Epoch 5/20\n",
            "305/305 [==============================] - 88s 288ms/step - loss: 0.5301 - price_loss: 0.4839 - type_loss: 0.5764 - price_sparse_categorical_accuracy: 0.8027 - type_sparse_categorical_accuracy: 0.8426 - val_loss: 0.9634 - val_price_loss: 0.9136 - val_type_loss: 1.0131 - val_price_sparse_categorical_accuracy: 0.6298 - val_type_sparse_categorical_accuracy: 0.7551\n",
            "Epoch 6/20\n",
            "305/305 [==============================] - 91s 297ms/step - loss: 0.4586 - price_loss: 0.4239 - type_loss: 0.4933 - price_sparse_categorical_accuracy: 0.8307 - type_sparse_categorical_accuracy: 0.8643 - val_loss: 1.0525 - val_price_loss: 0.9994 - val_type_loss: 1.1055 - val_price_sparse_categorical_accuracy: 0.6446 - val_type_sparse_categorical_accuracy: 0.7379\n",
            "Epoch 7/20\n",
            "305/305 [==============================] - 89s 291ms/step - loss: 0.3881 - price_loss: 0.3568 - type_loss: 0.4194 - price_sparse_categorical_accuracy: 0.8553 - type_sparse_categorical_accuracy: 0.8861 - val_loss: 1.2008 - val_price_loss: 1.2814 - val_type_loss: 1.1203 - val_price_sparse_categorical_accuracy: 0.6159 - val_type_sparse_categorical_accuracy: 0.7232\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "17dd8f70f6804bb988a3c6e1153c922a",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "  0%|          | 0/7360 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RNH7XiHFCqfg"
      },
      "source": [
        "### **Trial5**\n",
        "\n",
        "Trial4 results:\n",
        "\n",
        "Epoch 2/20: Does not improve after second epoch<br> - 90s 294ms/step<br> - loss: 0.8974<br> - price_loss: 0.8246<br> - type_loss: 0.9703<br> - price_sparse_categorical_accuracy: 0.6516<br> - type_sparse_categorical_accuracy: 0.7416<br> - val_loss: 0.8862<br> - val_price_loss: 0.7739<br> - val_type_loss: 0.9985<br> - val_price_sparse_categorical_accuracy: 0.6552<br> - val_type_sparse_categorical_accuracy: 0.7387\n",
        "\n",
        "The training and validation scores are similar. The previous trial did not improve after the second epoch and the losses started increasing. This may be due to the learning rate, which I will lower from the Adam default of 0.001 to 0.0001. I predict this will prevent the model from converging too quicky to a suboptimal solution and perhaps improve the model score. Additionally, I will reduce the embedding layer output from 100 to 20 since our vocabulary size is only 40000. I hope it will remove some noise and improve model performance."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 449,
          "referenced_widgets": [
            "2e39a17fa8fa45a6946c9765af874bc5",
            "7c75261168d64c55b6bdb9c76e22d218",
            "63100d8e57de4deea59629ab593c804e",
            "1f9a17df59ec4792897b667d27828ad7",
            "5479b9359a5641d58f1a1ca134e7e9bf",
            "f9138f3de0594b9f85cd35c6b0ed3370",
            "d3dc49c373ae4dd0a39fc3e72823e1a5",
            "43dd4cb4c14d496d9a9b0a8cf23c47eb",
            "14d2eb27fdd942da927d89dafb3ed731",
            "bb85c95ac7b04f34a20b8186a1c1a6ad",
            "e36cdf42fcaf4585861d71e4897ac28f"
          ]
        },
        "id": "UEfr7EeCeoP3",
        "outputId": "629f0e89-0592-4790-ed1f-498d9e9c7977"
      },
      "source": [
        "# Trial code cell\n",
        "\n",
        "# load modules\n",
        "import os\n",
        "\n",
        "import pandas as pd\n",
        "from tqdm.notebook import tqdm\n",
        "from PIL import Image\n",
        "import pandas as pd\n",
        "import os\n",
        "import numpy as np\n",
        "\n",
        "xy_train_df = pd.read_csv('train_xy.csv') # read training data into dataframe\n",
        "x_test_df = pd.read_csv('test_x.csv') # read test data into dataframe\n",
        "\n",
        "#===============================================================================\n",
        "\n",
        "# preprocess image data\n",
        "\n",
        "def load_image(file): # create function for loading images\n",
        "    try: # try this code\n",
        "        image = Image.open( # open and identify image file\n",
        "            file\n",
        "        ).convert('LA').resize((64, 64)) # convert to greyscale with alpha channel, resize to 64 by 64 pixels\n",
        "        arr = np.array(image) # return 3D array of image\n",
        "    except: # execute this code when an exception arises\n",
        "        arr = np.zeros((64, 64, 2)) # create 3D array of zeros with shape as (x,y,z)\n",
        "    return arr # return array\n",
        "\n",
        "\n",
        "# loading images:\n",
        "x_image = np.array([load_image(i) for i in tqdm(xy_train_df.image)]) # load training images as arrays with progress bar\n",
        "\n",
        "# loading summary: (force convert some of the non-string cell to string)\n",
        "x_text = xy_train_df.summary.astype('str')\n",
        "\n",
        "\n",
        "#===============================================================================\n",
        "\n",
        "from sklearn.model_selection import train_test_split # import function from module\n",
        "\n",
        "# labels:\n",
        "y_price = xy_train_df.price # subset price column\n",
        "y_type = xy_train_df.type.astype('category').cat.codes # encode type category variables\n",
        "len_price = len(y_price.unique()) # number of unique items in price category\n",
        "len_type = len(y_type.unique()) # number of unique items in type category\n",
        "# print('unique values for price category', len_price, y_price.unique()) # print number of unique items and values for price category\n",
        "# print('unique values for type category', len_type, y_type.unique()) # print number of unique items and values for type category\n",
        "\n",
        "# splitting:\n",
        "\n",
        "x_tr_image, x_vl_image, x_tr_text, x_vl_text, y_tr_price, y_vl_price, y_tr_type, y_vl_type = train_test_split(\n",
        "    x_image, # split image arrays into random train and validation subsets\n",
        "    x_text, # split series into random train and validation subsets\n",
        "    y_price, # split series into random train and validation subsets\n",
        "    y_type, # split series into random train and validation subsets\n",
        "    test_size=0.2) # training 80% validation/test 20% of data\n",
        "\n",
        "# scale image values to range of 0 to 1\n",
        "x_tr_image = x_tr_image/64.0\n",
        "x_vl_image = x_vl_image/64.0\n",
        "\n",
        "# print(np.shape(x_tr_image)) # print independent image feature training set shape\n",
        "# print(np.shape(x_vl_image)) # print independent image feature validation set shape\n",
        "# print(np.shape(y_tr_price)) # print dependent price feature training set shape\n",
        "# print(np.shape(y_vl_price)) # print dependent price feature validation set shape\n",
        "# print(np.shape(y_tr_type)) # print dependent type feature training set shape\n",
        "# print(np.shape(y_vl_type)) # print dependent type feature validation set shape\n",
        "\n",
        "#===============================================================================\n",
        "\n",
        "# preprocess text data\n",
        "\n",
        "# import modules and functions\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from sklearn.model_selection import train_test_split\n",
        "from pprint import pprint\n",
        "\n",
        "vocab_size = 40000 # set vocab_size variable to 40000\n",
        "max_len = 100 # # set max_len variable to 100\n",
        "\n",
        "\n",
        "# build vocabulary from training set\n",
        "tokenizer = Tokenizer(num_words=vocab_size) # set max number of words to keep for text tokenization\n",
        "tokenizer.fit_on_texts(x_tr_text) # create vocabulary index based on word frequency\n",
        "\n",
        "# create preprocessing function for text list\n",
        "def _preprocess(list_of_text): # param: list_of_text\n",
        "    return pad_sequences( # return padded sequences with same length\n",
        "        tokenizer.texts_to_sequences(list_of_text), # transforms each text to sequence of integers\n",
        "        maxlen=max_len, # set maximum length of all sequences\n",
        "        padding='post', # set to pad end of sequences\n",
        "    )\n",
        "\n",
        "\n",
        "# padding is done inside:\n",
        "x_tr_text_id = _preprocess(x_tr_text)\n",
        "x_vl_text_id = _preprocess(x_vl_text)\n",
        "\n",
        "# # print shapes of padded arrays\n",
        "# print(x_tr_text_id.shape)\n",
        "# print(x_vl_text_id.shape)\n",
        "\n",
        "#===============================================================================\n",
        "\n",
        "# import modules and functions\n",
        "from __future__ import absolute_import, division, print_function, unicode_literals\n",
        "import collections\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.layers import Conv2D, Flatten, Dense, MaxPool2D, Dropout # import dropout layer\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "# set input text and image shapes\n",
        "in_text = keras.Input(batch_shape=(None, max_len)) # set max length for input text\n",
        "in_image = keras.Input(batch_shape=(None, 64, 64, 2)) # set shape for input image\n",
        "\n",
        "# text part\n",
        "embedded = keras.layers.Embedding(tokenizer.num_words, 20)(in_text) # turn positive integers (indexes) into dense vectors of fixed size\n",
        "# averaged = tf.reduce_mean(embedded, axis=1) # reduce input_tensor along dimensions given in axis using mean of elements across dimensions in axis\n",
        "\n",
        "# GRU layer with Bidirectional wrapper\n",
        "# gru = tf.keras.layers.GRU(100)(embedded) # GRU layer with 100 units\n",
        "BiGRU = tf.keras.layers.Bidirectional(tf.keras.layers.GRU(100))(embedded) # gru with units=100 and bidirectional wrapper\n",
        "\n",
        "# image part\n",
        "cov = Conv2D(32, (16, 16))(in_image) # 2D convolution layer with 32 filters and 16 by 16 kernel_size\n",
        "pl = MaxPool2D((16, 16))(cov) # max pooling operation for 2D spatial data with 16 by 16 pool_size\n",
        "# add dropout after pooling\n",
        "pl = Dropout(0.5)(pl) # 50% dropout rate\n",
        "flattened = Flatten()(pl) # flatten input to 1D array\n",
        "\n",
        "\n",
        "# fusion:\n",
        "fused = tf.concat([BiGRU, flattened], axis=-1) # concatenate tensors along one dimension, switched 'gr' to 'BiGRU'\n",
        "\n",
        "# multi-objectives (each is a multi-class classification)\n",
        "p_price = Dense(len_price, activation='softmax', name='price')(fused) # dense layer with units equal to number of unique items in price category, softmax activation function\n",
        "p_type = Dense(len_type, activation='softmax', name='type')(fused) # dense layer with units equal to number of unique items in type category, softmax activation\n",
        "\n",
        "# create model by specifying inputs and outputs\n",
        "model = keras.Model(\n",
        "    inputs={\n",
        "        'summary': in_text, # input text is listing summary\n",
        "        'image': in_image # input image\n",
        "    },\n",
        "    outputs={\n",
        "        'price': p_price, # output predicted price\n",
        "        'type': p_type, # output predicted type\n",
        "    },\n",
        ")\n",
        "\n",
        "# configure model\n",
        "model.compile(\n",
        "    optimizer=Adam(learning_rate=0.0001), # use 'Adam' optimizer\n",
        "    loss={\n",
        "        'price': 'sparse_categorical_crossentropy', # loss for 'price' output\n",
        "        'type': 'sparse_categorical_crossentropy', # loss for 'type' output\n",
        "    },\n",
        "    loss_weights={\n",
        "        'price': 0.5, # weight for 'price' loss\n",
        "        'type': 0.5, # weight for 'type' loss\n",
        "    },\n",
        "    metrics={\n",
        "        'price': ['SparseCategoricalAccuracy'], # metric for 'price'\n",
        "        'type': ['SparseCategoricalAccuracy'], # metric for 'type'\n",
        "    },\n",
        ")\n",
        "\n",
        "# summary for model\n",
        "model.summary()\n",
        "\n",
        "#===============================================================================\n",
        "\n",
        "# fit model on data while monitoring performance on a validation split of 0.2\n",
        "history = model.fit(\n",
        "    x={\n",
        "        'summary': x_tr_text_id, # text training data\n",
        "        'image': x_tr_image # image training data\n",
        "    },\n",
        "    y={\n",
        "        'price': y_tr_price, # text training target data\n",
        "        'type': y_tr_type, # type training target data\n",
        "    },\n",
        "    epochs=20, # 20 cycles through training data\n",
        "    batch_size=16, # number of samples processed before model is updated\n",
        "    validation_data=(\n",
        "        {\n",
        "            'summary': x_vl_text_id, # text validation data\n",
        "            'image': x_vl_image # image validation data\n",
        "         },\n",
        "        {\n",
        "            'price': y_vl_price, # price validation target data\n",
        "            'type': y_vl_type, # type validation target data\n",
        "        }),\n",
        "    validation_split=0.2, # split training and validation 80/20\n",
        "    callbacks=[ # stop training when monitored metric has stopped improving after specified number of epochs\n",
        "        tf.keras.callbacks.EarlyStopping(monitor='val_price_loss', patience=5, ) # monitor loss for validation price with patience of 5 epochs\n",
        "    ],\n",
        "    verbose=1 # progress bar\n",
        ")\n",
        "\n",
        "#===============================================================================\n",
        "\n",
        "# preprocess test data for text and image\n",
        "x_test_summary = _preprocess(x_test_df.summary.astype(str)) # preprocess test summary data\n",
        "x_test_image = np.array([load_image(i) for i in tqdm(x_test_df.image)]) # load test images as arrays with progress bar\n",
        "\n",
        "# scale images for test data to range of 0 to 1\n",
        "x_test_image = x_test_image/64.0\n",
        "\n",
        "#===============================================================================\n",
        "\n",
        "\n",
        "# evaluate model on test data\n",
        "y_predict = model.predict( # use model to predict\n",
        "    {\n",
        "        'summary': x_test_summary, # text test data\n",
        "        'image': x_test_image # image test data\n",
        "    }\n",
        ")\n",
        "\n",
        "price_predicted = y_predict['price'] # target prediction\n",
        "# print(price_predicted) # print predictions\n",
        "price_category_predicted = np.argmax(price_predicted, axis=1) # return indices of maximum values along an axis\n",
        "# print(price_category_predicted) # print predicted categories for targets\n",
        "\n",
        "# create submission\n",
        "pd.DataFrame(\n",
        "    {'id': x_test_df.id,\n",
        "     'price': price_category_predicted}).to_csv('sample_submission5.csv', index=False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "2e39a17fa8fa45a6946c9765af874bc5",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "  0%|          | 0/7627 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-67cb094e21c2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;31m# loading images:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m \u001b[0mx_image\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mload_image\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxy_train_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# load training images as arrays with progress bar\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;31m# loading summary: (force convert some of the non-string cell to string)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-2-67cb094e21c2>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;31m# loading images:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m \u001b[0mx_image\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mload_image\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxy_train_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# load training images as arrays with progress bar\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;31m# loading summary: (force convert some of the non-string cell to string)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tqdm/notebook.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    255\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__iter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    256\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 257\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mobj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtqdm_notebook\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__iter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    258\u001b[0m                 \u001b[0;31m# return super(tqdm...) will not catch exception\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    259\u001b[0m                 \u001b[0;32myield\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tqdm/std.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1188\u001b[0m                     \u001b[0mdt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcur_t\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mlast_print_t\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1189\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mdt\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0mmininterval\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mcur_t\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0mmin_start_t\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1190\u001b[0;31m                         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mlast_print_n\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1191\u001b[0m                         \u001b[0mlast_print_n\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlast_print_n\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1192\u001b[0m                         \u001b[0mlast_print_t\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlast_print_t\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tqdm/notebook.py\u001b[0m in \u001b[0;36mupdate\u001b[0;34m(self, n)\u001b[0m\n\u001b[1;32m    267\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    268\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 269\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtqdm_notebook\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    270\u001b[0m         \u001b[0;31m# NB: except ... [ as ...] breaks IPython async KeyboardInterrupt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    271\u001b[0m         \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# NOQA\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tqdm/std.py\u001b[0m in \u001b[0;36mupdate\u001b[0;34m(self, n)\u001b[0m\n\u001b[1;32m   1239\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ema_dn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1240\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ema_dt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1241\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrefresh\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlock_args\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlock_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1242\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdynamic_miniters\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1243\u001b[0m                     \u001b[0;31m# If no `miniters` was specified, adjust automatically to the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tqdm/std.py\u001b[0m in \u001b[0;36mrefresh\u001b[0;34m(self, nolock, lock_args)\u001b[0m\n\u001b[1;32m   1344\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1345\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1346\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdisplay\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1347\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mnolock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1348\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelease\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tqdm/notebook.py\u001b[0m in \u001b[0;36mdisplay\u001b[0;34m(self, msg, pos, close, bar_style, check_delay)\u001b[0m\n\u001b[1;32m    178\u001b[0m             \u001b[0;31m# never clear the bar (signal: msg='')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    179\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mright\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 180\u001b[0;31m                 \u001b[0mrtext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mright\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    181\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    182\u001b[0m         \u001b[0;31m# Change bar style\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/traitlets/traitlets.py\u001b[0m in \u001b[0;36m__set__\u001b[0;34m(self, obj, value)\u001b[0m\n\u001b[1;32m    604\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTraitError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'The \"%s\" trait is read-only.'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    605\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 606\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    607\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    608\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_validate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/traitlets/traitlets.py\u001b[0m in \u001b[0;36mset\u001b[0;34m(self, obj, value)\u001b[0m\n\u001b[1;32m    593\u001b[0m             \u001b[0;31m# we explicitly compare silent to True just in case the equality\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    594\u001b[0m             \u001b[0;31m# comparison above returns something other than True/False\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 595\u001b[0;31m             \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_notify_trait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mold_value\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_value\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    596\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    597\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__set__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/traitlets/traitlets.py\u001b[0m in \u001b[0;36m_notify_trait\u001b[0;34m(self, name, old_value, new_value)\u001b[0m\n\u001b[1;32m   1222\u001b[0m             \u001b[0mnew\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnew_value\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1223\u001b[0m             \u001b[0mowner\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1224\u001b[0;31m             \u001b[0mtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'change'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1225\u001b[0m         ))\n\u001b[1;32m   1226\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/ipywidgets/widgets/widget.py\u001b[0m in \u001b[0;36mnotify_change\u001b[0;34m(self, change)\u001b[0m\n\u001b[1;32m    603\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_should_send_property\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    604\u001b[0m                 \u001b[0;31m# Send new state to front-end\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 605\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_state\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    606\u001b[0m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mWidget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnotify_change\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchange\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    607\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/ipywidgets/widgets/widget.py\u001b[0m in \u001b[0;36msend_state\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    487\u001b[0m             \u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuffer_paths\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuffers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_remove_buffers\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    488\u001b[0m             \u001b[0mmsg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'method'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'update'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'state'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'buffer_paths'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbuffer_paths\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 489\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_send\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuffers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbuffers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    490\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/ipywidgets/widgets/widget.py\u001b[0m in \u001b[0;36m_send\u001b[0;34m(self, msg, buffers)\u001b[0m\n\u001b[1;32m    735\u001b[0m         \u001b[0;34m\"\"\"Sends a message to the model in the front-end.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    736\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcomm\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcomm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkernel\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 737\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcomm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuffers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbuffers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    738\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    739\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_repr_keys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/ipykernel/comm/comm.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, data, metadata, buffers)\u001b[0m\n\u001b[1;32m    119\u001b[0m         \u001b[0;34m\"\"\"Send a message to the frontend-side version of this comm\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m         self._publish_msg('comm_msg',\n\u001b[0;32m--> 121\u001b[0;31m             \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmetadata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuffers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbuffers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    122\u001b[0m         )\n\u001b[1;32m    123\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/ipykernel/comm/comm.py\u001b[0m in \u001b[0;36m_publish_msg\u001b[0;34m(self, msg_type, data, metadata, buffers, **keys)\u001b[0m\n\u001b[1;32m     69\u001b[0m             \u001b[0mparent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkernel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_header\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m             \u001b[0mident\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtopic\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 71\u001b[0;31m             \u001b[0mbuffers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbuffers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     72\u001b[0m         )\n\u001b[1;32m     73\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/jupyter_client/session.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, stream, msg_or_type, content, parent, ident, buffers, track, header, metadata)\u001b[0m\n\u001b[1;32m    746\u001b[0m             \u001b[0;31m# use dummy tracker, which will be done immediately\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    747\u001b[0m             \u001b[0mtracker\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDONE\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 748\u001b[0;31m             \u001b[0mstream\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_multipart\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mto_send\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    749\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    750\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/ipykernel/iostream.py\u001b[0m in \u001b[0;36msend_multipart\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    260\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0msend_multipart\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    261\u001b[0m         \u001b[0;34m\"\"\"Schedule send in IO thread\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 262\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mio_thread\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_multipart\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    263\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    264\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/ipykernel/iostream.py\u001b[0m in \u001b[0;36msend_multipart\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    210\u001b[0m         \u001b[0mIf\u001b[0m \u001b[0mmy\u001b[0m \u001b[0mthread\u001b[0m \u001b[0misn\u001b[0m\u001b[0;31m'\u001b[0m\u001b[0mt\u001b[0m \u001b[0mrunning\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mforked\u001b[0m \u001b[0mprocess\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msend\u001b[0m \u001b[0mimmediately\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    211\u001b[0m         \"\"\"\n\u001b[0;32m--> 212\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mschedule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_really_send\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    213\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    214\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_really_send\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmsg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/ipykernel/iostream.py\u001b[0m in \u001b[0;36mschedule\u001b[0;34m(self, f)\u001b[0m\n\u001b[1;32m    201\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_events\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    202\u001b[0m             \u001b[0;31m# wake event thread (message content is ignored)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 203\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_event_pipe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mb''\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    204\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    205\u001b[0m             \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/zmq/sugar/socket.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, data, flags, copy, track, routing_id, group)\u001b[0m\n\u001b[1;32m    545\u001b[0m                 )\n\u001b[1;32m    546\u001b[0m             \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroup\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgroup\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 547\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSocket\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mflags\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrack\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrack\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    548\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0msend_multipart\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmsg_parts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrack\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32mzmq/backend/cython/socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket.Socket.send\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mzmq/backend/cython/socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket.Socket.send\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mzmq/backend/cython/socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket._send_copy\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/zmq/backend/cython/checkrc.pxd\u001b[0m in \u001b[0;36mzmq.backend.cython.checkrc._check_rc\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YDyM1C-5ezux"
      },
      "source": [
        "### **Trial6**\n",
        "\n",
        "Results from trial5:\n",
        "\n",
        "Epoch 20/20<br> - 76s 248ms/step<br> - loss: 0.5846<br> - price_loss: 0.5499<br> - type_loss: 0.6193<br> - price_sparse_categorical_accuracy: 0.7701<br> - type_sparse_categorical_accuracy: 0.8107<br> - val_loss: 0.8822<br> - val_price_loss: 0.7737<br> - val_type_loss: 0.9907<br> - val_price_sparse_categorical_accuracy: 0.6749<br> - val_type_sparse_categorical_accuracy: 0.7805\n",
        "\n",
        "The previous trial saw a minor improvement in overall performance. The training and validation scores are similar, but there is a slight bit of overfitting as the training score is greater. In addition, the learning rate appears to be too low. This is evident from the training and validation scores stagnating.\n",
        "\n",
        "This trial I will return the learning rate to the default for the 'Adam' optimizer and increase the embedding layer output from 20 up to 64. In addition I will try using an Attention layer to aggregate the time dimension.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "89cac7b9da714d1b920b897e057eefba",
            "aa482a22d03b4ac4bd42459eeb34890d",
            "5c0c9af5dffe41209f94a2b214e90055",
            "a871780c94c946d6aa5c09452ccc5634",
            "3814057e7cb5465da1abb5267e03373e",
            "7cb37aeaeb9a44d8bfb636b264ae5a3c",
            "1bb7ae4f631f4f5494fe2ac185373ebf",
            "7c31318e42264466bf1f879191dbf9d4",
            "0d77094de0864e4db4cc20366cc5d029",
            "5d015791e3194b44a954b338e4f8ad33",
            "d655ab160cf04bff9f297b95b1636aa6",
            "8325028fe578436babb486c1a255fd4b",
            "207f21601ea647a9acc174622f0865bc",
            "277151ade0c949079bb16a3ea43ce6bc",
            "ae63af268ef24547b438d750b663d3ce",
            "9e33dbd4623a4e9c8ba68c3675495aa2",
            "30e6421f20ae40b7b1a7335653781cd8",
            "023ab4f5f9594b02b9319954ce053167",
            "50c6a19985474966b974f10212e8306d",
            "4c93ff863e204f4d8d0bbdec71933d71",
            "aeff19da0ba04dc6b1bf97be1a8c9bf3",
            "94479f8ffd7743ec913107367c1e2fe3"
          ]
        },
        "id": "m_voSUws6R9X",
        "outputId": "bf2603b4-2589-498c-ff4a-2630575d49fa"
      },
      "source": [
        "# Trial code cell\n",
        "\n",
        "# load modules\n",
        "import os\n",
        "\n",
        "import pandas as pd\n",
        "from tqdm.notebook import tqdm\n",
        "from PIL import Image\n",
        "import pandas as pd\n",
        "import os\n",
        "import numpy as np\n",
        "\n",
        "xy_train_df = pd.read_csv('train_xy.csv') # read training data into dataframe\n",
        "x_test_df = pd.read_csv('test_x.csv') # read test data into dataframe\n",
        "\n",
        "#===============================================================================\n",
        "\n",
        "# preprocess image data\n",
        "\n",
        "def load_image(file): # create function for loading images\n",
        "    try: # try this code\n",
        "        image = Image.open( # open and identify image file\n",
        "            file\n",
        "        ).convert('LA').resize((64, 64)) # convert to greyscale with alpha channel, resize to 64 by 64 pixels\n",
        "        arr = np.array(image) # return 3D array of image\n",
        "    except: # execute this code when an exception arises\n",
        "        arr = np.zeros((64, 64, 2)) # create 3D array of zeros with shape as (x,y,z)\n",
        "    return arr # return array\n",
        "\n",
        "\n",
        "# loading images:\n",
        "x_image = np.array([load_image(i) for i in tqdm(xy_train_df.image)]) # load training images as arrays with progress bar\n",
        "\n",
        "# loading summary: (force convert some of the non-string cell to string)\n",
        "x_text = xy_train_df.summary.astype('str')\n",
        "\n",
        "\n",
        "#===============================================================================\n",
        "\n",
        "from sklearn.model_selection import train_test_split # import function from module\n",
        "\n",
        "# labels:\n",
        "y_price = xy_train_df.price # subset price column\n",
        "y_type = xy_train_df.type.astype('category').cat.codes # encode type category variables\n",
        "len_price = len(y_price.unique()) # number of unique items in price category\n",
        "len_type = len(y_type.unique()) # number of unique items in type category\n",
        "# print('unique values for price category', len_price, y_price.unique()) # print number of unique items and values for price category\n",
        "# print('unique values for type category', len_type, y_type.unique()) # print number of unique items and values for type category\n",
        "\n",
        "# splitting:\n",
        "\n",
        "x_tr_image, x_vl_image, x_tr_text, x_vl_text, y_tr_price, y_vl_price, y_tr_type, y_vl_type = train_test_split(\n",
        "    x_image, # split image arrays into random train and validation subsets\n",
        "    x_text, # split series into random train and validation subsets\n",
        "    y_price, # split series into random train and validation subsets\n",
        "    y_type, # split series into random train and validation subsets\n",
        "    test_size=0.2) # training 80% validation/test 20% of data\n",
        "\n",
        "# scale image values to range of 0 to 1\n",
        "x_tr_image = x_tr_image/64.0\n",
        "x_vl_image = x_vl_image/64.0\n",
        "\n",
        "# print(np.shape(x_tr_image)) # print independent image feature training set shape\n",
        "# print(np.shape(x_vl_image)) # print independent image feature validation set shape\n",
        "# print(np.shape(y_tr_price)) # print dependent price feature training set shape\n",
        "# print(np.shape(y_vl_price)) # print dependent price feature validation set shape\n",
        "# print(np.shape(y_tr_type)) # print dependent type feature training set shape\n",
        "# print(np.shape(y_vl_type)) # print dependent type feature validation set shape\n",
        "\n",
        "#===============================================================================\n",
        "\n",
        "# preprocess text data\n",
        "\n",
        "# import modules and functions\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from sklearn.model_selection import train_test_split\n",
        "from pprint import pprint\n",
        "\n",
        "vocab_size = 40000 # set vocab_size variable to 40000\n",
        "max_len = 100 # # set max_len variable to 100\n",
        "\n",
        "\n",
        "# build vocabulary from training set\n",
        "tokenizer = Tokenizer(num_words=vocab_size) # set max number of words to keep for text tokenization\n",
        "tokenizer.fit_on_texts(x_tr_text) # create vocabulary index based on word frequency\n",
        "\n",
        "# create preprocessing function for text list\n",
        "def _preprocess(list_of_text): # param: list_of_text\n",
        "    return pad_sequences( # return padded sequences with same length\n",
        "        tokenizer.texts_to_sequences(list_of_text), # transforms each text to sequence of integers\n",
        "        maxlen=max_len, # set maximum length of all sequences\n",
        "        padding='post', # set to pad end of sequences\n",
        "    )\n",
        "\n",
        "\n",
        "# padding is done inside:\n",
        "x_tr_text_id = _preprocess(x_tr_text)\n",
        "x_vl_text_id = _preprocess(x_vl_text)\n",
        "\n",
        "# # print shapes of padded arrays\n",
        "# print(x_tr_text_id.shape)\n",
        "# print(x_vl_text_id.shape)\n",
        "\n",
        "#===============================================================================\n",
        "\n",
        "# import modules and functions\n",
        "from __future__ import absolute_import, division, print_function, unicode_literals\n",
        "import collections\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.layers import Conv2D, Flatten, Dense, MaxPool2D, Dropout, Attention, Concatenate # import dropout and attention sets\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "# set input text and image shapes\n",
        "in_text = keras.Input(batch_shape=(None, max_len)) # set max length for input text\n",
        "in_image = keras.Input(batch_shape=(None, 64, 64, 2)) # set shape for input image\n",
        "\n",
        "# text part\n",
        "embedded = keras.layers.Embedding(tokenizer.num_words, 100)(in_text) # turn positive integers (indexes) into dense vectors of fixed size\n",
        "# averaged = tf.reduce_mean(embedded, axis=1) # reduce input_tensor along dimensions given in axis using mean of elements across dimensions in axis\n",
        "\n",
        "# Bi-directional RNN\n",
        "gru = tf.keras.layers.Bidirectional(tf.keras.layers.GRU(100,return_sequences=True),name=\"bi_gru_0\")(embedded) # bidirectional gru with units=100\n",
        "\n",
        "# calculate query, value, key for attention layer\n",
        "query = Dense(100)(gru[:,-1,:]) # transform with dense layer of 100 units, slide the tensor to use the output of the last time stamp (-1) as the query\n",
        "query = tf.expand_dims(query,1) # expand a new dimension on index 1\n",
        "key=Dense(100)(gru) # transform source with dense layer of 100 units\n",
        "value=Dense(100)(gru) # transform source with dense layer of 100 units\n",
        "\n",
        "weighted_average = Attention()([query,value,key]) # create attention layer and call with query, value, key in an array as input to layer\n",
        "output = tf.squeeze(weighted_average,[1]) # squeeze the dimension of dim 1 for weighted_average\n",
        "\n",
        "# image part\n",
        "cov = Conv2D(32, (16, 16))(in_image) # 2D convolution layer with 32 filters and 16 by 16 kernel_size\n",
        "pl = MaxPool2D((16, 16))(cov) # max pooling operation for 2D spatial data with 16 by 16 pool_size\n",
        "# add dropout after pooling\n",
        "pl = Dropout(0.5)(pl) # 50% dropout rate\n",
        "flattened = Flatten()(pl) # flatten input to 1D array\n",
        "\n",
        "\n",
        "# fusion:\n",
        "fused = tf.concat([output, flattened], axis=-1) # concatenate tensors along one dimension\n",
        "\n",
        "# multi-objectives (each is a multi-class classification)\n",
        "p_price = Dense(len_price, activation='softmax', name='price')(fused) # dense layer with units equal to number of unique items in price category, softmax activation function\n",
        "p_type = Dense(len_type, activation='softmax', name='type')(fused) # dense layer with units equal to number of unique items in type category, softmax activation\n",
        "\n",
        "# create model by specifying inputs and outputs\n",
        "model = keras.Model(\n",
        "    inputs={\n",
        "        'summary': in_text, # input text is listing summary\n",
        "        'image': in_image # input image\n",
        "    },\n",
        "    outputs={\n",
        "        'price': p_price, # output predicted price\n",
        "        'type': p_type, # output predicted type\n",
        "    },\n",
        ")\n",
        "\n",
        "# configure model\n",
        "model.compile(\n",
        "    optimizer=Adam(), # use 'Adam' optimizer\n",
        "    loss={\n",
        "        'price': 'sparse_categorical_crossentropy', # loss for 'price' output\n",
        "        'type': 'sparse_categorical_crossentropy', # loss for 'type' output\n",
        "    },\n",
        "    loss_weights={\n",
        "        'price': 0.5, # weight for 'price' loss\n",
        "        'type': 0.5, # weight for 'type' loss\n",
        "    },\n",
        "    metrics={\n",
        "        'price': ['SparseCategoricalAccuracy'], # metric for 'price'\n",
        "        'type': ['SparseCategoricalAccuracy'], # metric for 'type'\n",
        "    },\n",
        ")\n",
        "\n",
        "# summary for model\n",
        "model.summary()\n",
        "\n",
        "#===============================================================================\n",
        "\n",
        "# fit model on data while monitoring performance on a validation split of 0.2\n",
        "history = model.fit(\n",
        "    x={\n",
        "        'summary': x_tr_text_id, # text training data\n",
        "        'image': x_tr_image # image training data\n",
        "    },\n",
        "    y={\n",
        "        'price': y_tr_price, # text training target data\n",
        "        'type': y_tr_type, # type training target data\n",
        "    },\n",
        "    epochs=20, # 20 cycles through training data\n",
        "    batch_size=16, # number of samples processed before model is updated\n",
        "    validation_data=(\n",
        "        {\n",
        "            'summary': x_vl_text_id, # text validation data\n",
        "            'image': x_vl_image # image validation data\n",
        "         },\n",
        "        {\n",
        "            'price': y_vl_price, # price validation target data\n",
        "            'type': y_vl_type, # type validation target data\n",
        "        }),\n",
        "    validation_split=0.2, # split training and validation 80/20\n",
        "    callbacks=[ # stop training when monitored metric has stopped improving after specified number of epochs\n",
        "        tf.keras.callbacks.EarlyStopping(monitor='val_price_loss', patience=5, ) # monitor loss for validation price with patience of 5 epochs\n",
        "    ],\n",
        "    verbose=1 # progress bar\n",
        ")\n",
        "\n",
        "#===============================================================================\n",
        "\n",
        "# preprocess test data for text and image\n",
        "x_test_summary = _preprocess(x_test_df.summary.astype(str)) # preprocess test summary data\n",
        "x_test_image = np.array([load_image(i) for i in tqdm(x_test_df.image)]) # load test images as arrays with progress bar\n",
        "\n",
        "# scale images for test data to range of 0 to 1\n",
        "x_test_image = x_test_image/64.0\n",
        "\n",
        "#===============================================================================\n",
        "\n",
        "\n",
        "# evaluate model on test data\n",
        "y_predict = model.predict( # use model to predict\n",
        "    {\n",
        "        'summary': x_test_summary, # text test data\n",
        "        'image': x_test_image # image test data\n",
        "    }\n",
        ")\n",
        "\n",
        "price_predicted = y_predict['price'] # target prediction\n",
        "# print(price_predicted) # print predictions\n",
        "price_category_predicted = np.argmax(price_predicted, axis=1) # return indices of maximum values along an axis\n",
        "# print(price_category_predicted) # print predicted categories for targets\n",
        "\n",
        "# create submission\n",
        "pd.DataFrame(\n",
        "    {'id': x_test_df.id,\n",
        "     'price': price_category_predicted}).to_csv('sample_submission6.csv', index=False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "89cac7b9da714d1b920b897e057eefba",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "  0%|          | 0/7627 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_7 (InputLayer)           [(None, 100)]        0           []                               \n",
            "                                                                                                  \n",
            " embedding_3 (Embedding)        (None, 100, 100)     4000000     ['input_7[0][0]']                \n",
            "                                                                                                  \n",
            " bi_gru_0 (Bidirectional)       (None, 100, 200)     121200      ['embedding_3[0][0]']            \n",
            "                                                                                                  \n",
            " tf.__operators__.getitem_3 (Sl  (None, 200)         0           ['bi_gru_0[0][0]']               \n",
            " icingOpLambda)                                                                                   \n",
            "                                                                                                  \n",
            " input_8 (InputLayer)           [(None, 64, 64, 2)]  0           []                               \n",
            "                                                                                                  \n",
            " dense_9 (Dense)                (None, 100)          20100       ['tf.__operators__.getitem_3[0][0\n",
            "                                                                 ]']                              \n",
            "                                                                                                  \n",
            " conv2d_1 (Conv2D)              (None, 49, 49, 32)   16416       ['input_8[0][0]']                \n",
            "                                                                                                  \n",
            " tf.expand_dims_1 (TFOpLambda)  (None, 1, 100)       0           ['dense_9[0][0]']                \n",
            "                                                                                                  \n",
            " dense_11 (Dense)               (None, 100, 100)     20100       ['bi_gru_0[0][0]']               \n",
            "                                                                                                  \n",
            " dense_10 (Dense)               (None, 100, 100)     20100       ['bi_gru_0[0][0]']               \n",
            "                                                                                                  \n",
            " max_pooling2d_1 (MaxPooling2D)  (None, 3, 3, 32)    0           ['conv2d_1[0][0]']               \n",
            "                                                                                                  \n",
            " attention_3 (Attention)        (None, 1, 100)       0           ['tf.expand_dims_1[0][0]',       \n",
            "                                                                  'dense_11[0][0]',               \n",
            "                                                                  'dense_10[0][0]']               \n",
            "                                                                                                  \n",
            " dropout_1 (Dropout)            (None, 3, 3, 32)     0           ['max_pooling2d_1[0][0]']        \n",
            "                                                                                                  \n",
            " tf.compat.v1.squeeze_3 (TFOpLa  (None, 100)         0           ['attention_3[0][0]']            \n",
            " mbda)                                                                                            \n",
            "                                                                                                  \n",
            " flatten_1 (Flatten)            (None, 288)          0           ['dropout_1[0][0]']              \n",
            "                                                                                                  \n",
            " tf.concat_1 (TFOpLambda)       (None, 388)          0           ['tf.compat.v1.squeeze_3[0][0]', \n",
            "                                                                  'flatten_1[0][0]']              \n",
            "                                                                                                  \n",
            " price (Dense)                  (None, 3)            1167        ['tf.concat_1[0][0]']            \n",
            "                                                                                                  \n",
            " type (Dense)                   (None, 24)           9336        ['tf.concat_1[0][0]']            \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 4,208,419\n",
            "Trainable params: 4,208,419\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "Epoch 1/20\n",
            "305/305 [==============================] - 88s 276ms/step - loss: 1.2983 - price_loss: 1.1706 - type_loss: 1.4259 - price_sparse_categorical_accuracy: 0.5334 - type_sparse_categorical_accuracy: 0.6865 - val_loss: 0.9574 - val_price_loss: 0.8507 - val_type_loss: 1.0640 - val_price_sparse_categorical_accuracy: 0.5905 - val_type_sparse_categorical_accuracy: 0.7641\n",
            "Epoch 2/20\n",
            "305/305 [==============================] - 83s 271ms/step - loss: 1.0793 - price_loss: 0.9700 - type_loss: 1.1886 - price_sparse_categorical_accuracy: 0.5672 - type_sparse_categorical_accuracy: 0.7225 - val_loss: 0.9205 - val_price_loss: 0.8554 - val_type_loss: 0.9856 - val_price_sparse_categorical_accuracy: 0.6175 - val_type_sparse_categorical_accuracy: 0.7641\n",
            "Epoch 3/20\n",
            "305/305 [==============================] - 83s 272ms/step - loss: 0.9611 - price_loss: 0.8504 - type_loss: 1.0718 - price_sparse_categorical_accuracy: 0.6176 - type_sparse_categorical_accuracy: 0.7359 - val_loss: 0.8651 - val_price_loss: 0.8276 - val_type_loss: 0.9025 - val_price_sparse_categorical_accuracy: 0.6364 - val_type_sparse_categorical_accuracy: 0.7641\n",
            "Epoch 4/20\n",
            "305/305 [==============================] - 83s 273ms/step - loss: 0.8396 - price_loss: 0.7238 - type_loss: 0.9554 - price_sparse_categorical_accuracy: 0.6795 - type_sparse_categorical_accuracy: 0.7447 - val_loss: 0.8943 - val_price_loss: 0.8376 - val_type_loss: 0.9509 - val_price_sparse_categorical_accuracy: 0.6446 - val_type_sparse_categorical_accuracy: 0.7658\n",
            "Epoch 5/20\n",
            "305/305 [==============================] - 83s 271ms/step - loss: 0.7244 - price_loss: 0.6203 - type_loss: 0.8285 - price_sparse_categorical_accuracy: 0.7408 - type_sparse_categorical_accuracy: 0.7648 - val_loss: 0.8682 - val_price_loss: 0.8481 - val_type_loss: 0.8882 - val_price_sparse_categorical_accuracy: 0.6208 - val_type_sparse_categorical_accuracy: 0.7715\n",
            "Epoch 6/20\n",
            "305/305 [==============================] - 83s 273ms/step - loss: 0.5930 - price_loss: 0.4983 - type_loss: 0.6876 - price_sparse_categorical_accuracy: 0.7955 - type_sparse_categorical_accuracy: 0.8037 - val_loss: 0.9702 - val_price_loss: 0.9543 - val_type_loss: 0.9861 - val_price_sparse_categorical_accuracy: 0.6519 - val_type_sparse_categorical_accuracy: 0.7764\n",
            "Epoch 7/20\n",
            "305/305 [==============================] - 86s 281ms/step - loss: 0.5154 - price_loss: 0.4383 - type_loss: 0.5924 - price_sparse_categorical_accuracy: 0.8248 - type_sparse_categorical_accuracy: 0.8260 - val_loss: 0.9677 - val_price_loss: 0.9509 - val_type_loss: 0.9845 - val_price_sparse_categorical_accuracy: 0.6323 - val_type_sparse_categorical_accuracy: 0.7469\n",
            "Epoch 8/20\n",
            "305/305 [==============================] - 83s 273ms/step - loss: 0.4441 - price_loss: 0.3863 - type_loss: 0.5018 - price_sparse_categorical_accuracy: 0.8457 - type_sparse_categorical_accuracy: 0.8525 - val_loss: 1.0908 - val_price_loss: 1.1163 - val_type_loss: 1.0653 - val_price_sparse_categorical_accuracy: 0.6421 - val_type_sparse_categorical_accuracy: 0.7314\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "8325028fe578436babb486c1a255fd4b",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "  0%|          | 0/7360 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OwDd0DIFgWes"
      },
      "source": [
        "### **Trial7**\n",
        "\n",
        "Trial6 results:\n",
        "\n",
        "Epoch 3/20: val_price_loss does not decrease after third epoch<br> - 83s 272ms/step<br> - loss: 0.9611<br> - price_loss: 0.8504<br> - type_loss: 1.0718<br> - price_sparse_categorical_accuracy: 0.6176<br> - type_sparse_categorical_accuracy: 0.7359<br> - val_loss: 0.8651<br> - val_price_loss: 0.8276<br> - val_type_loss: 0.9025<br> - val_price_sparse_categorical_accuracy: 0.6364<br> - val_type_sparse_categorical_accuracy: 0.7641\n",
        "\n",
        "It appears that there is a slight bit of overfitting when comparing the training and validation categorical accuracy. I also don't think the attention layer parameters were correctly configured for the API, since the params show 0 for the layer. I will use another attention layer, but from a created class example I found online (https://colab.research.google.com/drive/16hleozlJZb00nX2Lyq8XKyg9ud0bY98N?usp=sharing#scrollTo=attenclass). To be clear, I have spent several days trying to figure out how to use the Attention layer API with no success (even after watching the lecture multiple times for that section - clearly I lack some sort of fundamental understanding). I will try this example I found for the sake of implementing an attention layer properly, which I predict should improve the scores slightly.\n",
        "\n",
        "If you are reading this, please provide a model answer on how to properly use the Attention layer API for the text layer in these circumstances. I was not able to find any examples or further explanations online after days of searching. Thanks!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "70fa367794724c1594e3f2ab3c1c325a",
            "236ab9a6304040b48c4a32fd62b559da",
            "1988306b4343417b908a92283dd0b4d6",
            "c6d23cf65b8e4822a45db67e74a897c1",
            "fe92d03038b3417fb3e714493b7b2009",
            "2978afdda1a049788973fc3ab63b34d4",
            "82a3eba3e87c44e7b5c294e0ce867ead",
            "59ca679591994e3ca492c0f8368f26ed",
            "227c98984e7f4e1799b2ff5ed39d689b",
            "3150738e2e1041f6a35bc290b17a1d48",
            "a7a6aeff67394352bd1022bbeb073fb3",
            "b3ee53a8cc7f4b04bb11210c835c4622",
            "3565ec3170d148aeb31b5c0e4938b8e9",
            "cb5cf8df3c944dc182665d10a6f2b668",
            "ea4a572a256340aeb998bdd7f672093a",
            "daa11880d9114635b465d0d6ddd3117c",
            "03d3f441e5bc4515988855f497186f42",
            "bb3fc2b7f69f4b75acc05c9f55173b90",
            "56354de99bc0449e8f20d37e49897789",
            "99c7916ea52d4a53b6ac473c3edcb160",
            "5fd34dcca80a46af93b1b32bed561a2a",
            "4633b2317bd24fa8853481dfe49f658e"
          ]
        },
        "id": "-gZFSIryhpSC",
        "outputId": "cbacba24-881f-433c-f04a-f26afc787f2b"
      },
      "source": [
        "# Trial code cell\n",
        "\n",
        "# load modules\n",
        "import os\n",
        "\n",
        "import pandas as pd\n",
        "from tqdm.notebook import tqdm\n",
        "from PIL import Image\n",
        "import pandas as pd\n",
        "import os\n",
        "import numpy as np\n",
        "\n",
        "xy_train_df = pd.read_csv('train_xy.csv') # read training data into dataframe\n",
        "x_test_df = pd.read_csv('test_x.csv') # read test data into dataframe\n",
        "\n",
        "#===============================================================================\n",
        "\n",
        "# preprocess image data\n",
        "\n",
        "def load_image(file): # create function for loading images\n",
        "    try: # try this code\n",
        "        image = Image.open( # open and identify image file\n",
        "            file\n",
        "        ).convert('LA').resize((64, 64)) # convert to greyscale with alpha channel, resize to 64 by 64 pixels\n",
        "        arr = np.array(image) # return 3D array of image\n",
        "    except: # execute this code when an exception arises\n",
        "        arr = np.zeros((64, 64, 2)) # create 3D array of zeros with shape as (x,y,z)\n",
        "    return arr # return array\n",
        "\n",
        "\n",
        "# loading images:\n",
        "x_image = np.array([load_image(i) for i in tqdm(xy_train_df.image)]) # load training images as arrays with progress bar\n",
        "\n",
        "# loading summary: (force convert some of the non-string cell to string)\n",
        "x_text = xy_train_df.summary.astype('str')\n",
        "\n",
        "\n",
        "#===============================================================================\n",
        "\n",
        "from sklearn.model_selection import train_test_split # import function from module\n",
        "\n",
        "# labels:\n",
        "y_price = xy_train_df.price # subset price column\n",
        "y_type = xy_train_df.type.astype('category').cat.codes # encode type category variables\n",
        "len_price = len(y_price.unique()) # number of unique items in price category\n",
        "len_type = len(y_type.unique()) # number of unique items in type category\n",
        "# print('unique values for price category', len_price, y_price.unique()) # print number of unique items and values for price category\n",
        "# print('unique values for type category', len_type, y_type.unique()) # print number of unique items and values for type category\n",
        "\n",
        "# splitting:\n",
        "\n",
        "x_tr_image, x_vl_image, x_tr_text, x_vl_text, y_tr_price, y_vl_price, y_tr_type, y_vl_type = train_test_split(\n",
        "    x_image, # split image arrays into random train and validation subsets\n",
        "    x_text, # split series into random train and validation subsets\n",
        "    y_price, # split series into random train and validation subsets\n",
        "    y_type, # split series into random train and validation subsets\n",
        "    test_size=0.2) # training 80% validation/test 20% of data\n",
        "\n",
        "# scale image values to range of 0 to 1\n",
        "x_tr_image = x_tr_image/64.0\n",
        "x_vl_image = x_vl_image/64.0\n",
        "\n",
        "# print(np.shape(x_tr_image)) # print independent image feature training set shape\n",
        "# print(np.shape(x_vl_image)) # print independent image feature validation set shape\n",
        "# print(np.shape(y_tr_price)) # print dependent price feature training set shape\n",
        "# print(np.shape(y_vl_price)) # print dependent price feature validation set shape\n",
        "# print(np.shape(y_tr_type)) # print dependent type feature training set shape\n",
        "# print(np.shape(y_vl_type)) # print dependent type feature validation set shape\n",
        "\n",
        "#===============================================================================\n",
        "\n",
        "# preprocess text data\n",
        "\n",
        "# import modules and functions\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from sklearn.model_selection import train_test_split\n",
        "from pprint import pprint\n",
        "\n",
        "vocab_size = 40000 # set vocab_size variable to 40000\n",
        "max_len = 100 # # set max_len variable to 100\n",
        "\n",
        "\n",
        "# build vocabulary from training set\n",
        "tokenizer = Tokenizer(num_words=vocab_size) # set max number of words to keep for text tokenization\n",
        "tokenizer.fit_on_texts(x_tr_text) # create vocabulary index based on word frequency\n",
        "\n",
        "# create preprocessing function for text list\n",
        "def _preprocess(list_of_text): # param: list_of_text\n",
        "    return pad_sequences( # return padded sequences with same length\n",
        "        tokenizer.texts_to_sequences(list_of_text), # transforms each text to sequence of integers\n",
        "        maxlen=max_len, # set maximum length of all sequences\n",
        "        padding='post', # set to pad end of sequences\n",
        "    )\n",
        "\n",
        "\n",
        "# padding is done inside:\n",
        "x_tr_text_id = _preprocess(x_tr_text)\n",
        "x_vl_text_id = _preprocess(x_vl_text)\n",
        "\n",
        "# # print shapes of padded arrays\n",
        "# print(x_tr_text_id.shape)\n",
        "# print(x_vl_text_id.shape)\n",
        "\n",
        "#===============================================================================\n",
        "\n",
        "# import modules and functions\n",
        "from __future__ import absolute_import, division, print_function, unicode_literals\n",
        "import collections\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.layers import Conv2D, Flatten, Dense, MaxPool2D, Dropout, Attention, Concatenate # import dropout and attention sets\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "# set input text and image shapes\n",
        "in_text = keras.Input(batch_shape=(None, max_len)) # set max length for input text\n",
        "in_image = keras.Input(batch_shape=(None, 64, 64, 2)) # set shape for input image\n",
        "\n",
        "# text part\n",
        "embedded = keras.layers.Embedding(tokenizer.num_words, 100)(in_text) # turn positive integers (indexes) into dense vectors of fixed size\n",
        "# averaged = tf.reduce_mean(embedded, axis=1) # reduce input_tensor along dimensions given in axis using mean of elements across dimensions in axis\n",
        "\n",
        "# create attention layer\n",
        "class Attention(tf.keras.Model):\n",
        "    def __init__(self, units):\n",
        "        super(Attention, self).__init__()\n",
        "        self.W1 = tf.keras.layers.Dense(units)\n",
        "        self.W2 = tf.keras.layers.Dense(units)\n",
        "        self.V = tf.keras.layers.Dense(1)\n",
        "\n",
        "    def call(self, features, hidden):\n",
        "        # hidden shape == (batch_size, hidden size)\n",
        "        # hidden_with_time_axis shape == (batch_size, 1, hidden size)\n",
        "        # we are doing this to perform addition to calculate the score\n",
        "        hidden_with_time_axis = tf.expand_dims(hidden, 1)\n",
        "\n",
        "        # score shape == (batch_size, max_length, 1)\n",
        "        # we get 1 at the last axis because we are applying score to self.V\n",
        "        # the shape of the tensor before applying self.V is (batch_size, max_length, units)\n",
        "        score = tf.nn.tanh(\n",
        "            self.W1(features) + self.W2(hidden_with_time_axis))\n",
        "\n",
        "        # attention_weights shape == (batch_size, max_length, 1)\n",
        "        attention_weights = tf.nn.softmax(self.V(score), axis=1)\n",
        "\n",
        "        # context_vector shape after sum == (batch_size, hidden_size)\n",
        "        context_vector = attention_weights * features\n",
        "        context_vector = tf.reduce_sum(context_vector, axis=1)\n",
        "\n",
        "        return context_vector, attention_weights\n",
        "\n",
        "\n",
        "\n",
        "# Bi-directional RNN\n",
        "gru = tf.keras.layers.Bidirectional(tf.keras.layers.GRU(100,return_sequences=True),name=\"bi_gru_0\")(embedded) # bidirectional gru with units=100\n",
        "# get GRU outputs\n",
        "(gru, hidden0, hidden1) = tf.keras.layers.Bidirectional(tf.keras.layers.GRU(100, return_sequences=True, return_state=True), name=\"bi_gru_1\")(gru)\n",
        "\n",
        "# # concatenate hidden states from each RNN since model is using bidirectional RNN\n",
        "hidden = Concatenate()([hidden0, hidden1])\n",
        "\n",
        "context_vector, attention_weights = Attention(10)(gru, hidden)\n",
        "\n",
        "\n",
        "# image part\n",
        "cov = Conv2D(32, (16, 16))(in_image) # 2D convolution layer with 32 filters and 16 by 16 kernel_size\n",
        "pl = MaxPool2D((16, 16))(cov) # max pooling operation for 2D spatial data with 16 by 16 pool_size\n",
        "# add dropout after pooling\n",
        "pl = Dropout(0.5)(pl) # 50% dropout rate\n",
        "flattened = Flatten()(pl) # flatten input to 1D array\n",
        "\n",
        "\n",
        "# fusion:\n",
        "fused = tf.concat([context_vector, flattened], axis=-1) # concatenate tensors along one dimension\n",
        "\n",
        "# multi-objectives (each is a multi-class classification)\n",
        "p_price = Dense(len_price, activation='softmax', name='price')(fused) # dense layer with units equal to number of unique items in price category, softmax activation function\n",
        "p_type = Dense(len_type, activation='softmax', name='type')(fused) # dense layer with units equal to number of unique items in type category, softmax activation\n",
        "\n",
        "# create model by specifying inputs and outputs\n",
        "model = keras.Model(\n",
        "    inputs={\n",
        "        'summary': in_text, # input text is listing summary\n",
        "        'image': in_image # input image\n",
        "    },\n",
        "    outputs={\n",
        "        'price': p_price, # output predicted price\n",
        "        'type': p_type, # output predicted type\n",
        "    },\n",
        ")\n",
        "\n",
        "# configure model\n",
        "model.compile(\n",
        "    optimizer=Adam(), # use 'Adam' optimizer\n",
        "    loss={\n",
        "        'price': 'sparse_categorical_crossentropy', # loss for 'price' output\n",
        "        'type': 'sparse_categorical_crossentropy', # loss for 'type' output\n",
        "    },\n",
        "    loss_weights={\n",
        "        'price': 0.5, # weight for 'price' loss\n",
        "        'type': 0.5, # weight for 'type' loss\n",
        "    },\n",
        "    metrics={\n",
        "        'price': ['SparseCategoricalAccuracy'], # metric for 'price'\n",
        "        'type': ['SparseCategoricalAccuracy'], # metric for 'type'\n",
        "    },\n",
        ")\n",
        "\n",
        "# summary for model\n",
        "model.summary()\n",
        "\n",
        "#===============================================================================\n",
        "\n",
        "# fit model on data while monitoring performance on a validation split of 0.2\n",
        "history = model.fit(\n",
        "    x={\n",
        "        'summary': x_tr_text_id, # text training data\n",
        "        'image': x_tr_image # image training data\n",
        "    },\n",
        "    y={\n",
        "        'price': y_tr_price, # text training target data\n",
        "        'type': y_tr_type, # type training target data\n",
        "    },\n",
        "    epochs=20, # 20 cycles through training data\n",
        "    batch_size=16, # number of samples processed before model is updated\n",
        "    validation_data=(\n",
        "        {\n",
        "            'summary': x_vl_text_id, # text validation data\n",
        "            'image': x_vl_image # image validation data\n",
        "         },\n",
        "        {\n",
        "            'price': y_vl_price, # price validation target data\n",
        "            'type': y_vl_type, # type validation target data\n",
        "        }),\n",
        "    validation_split=0.2, # split training and validation 80/20\n",
        "    callbacks=[ # stop training when monitored metric has stopped improving after specified number of epochs\n",
        "        tf.keras.callbacks.EarlyStopping(monitor='val_price_loss', patience=5, ) # monitor loss for validation price with patience of 5 epochs\n",
        "    ],\n",
        "    verbose=1 # progress bar\n",
        ")\n",
        "\n",
        "#===============================================================================\n",
        "\n",
        "# preprocess test data for text and image\n",
        "x_test_summary = _preprocess(x_test_df.summary.astype(str)) # preprocess test summary data\n",
        "x_test_image = np.array([load_image(i) for i in tqdm(x_test_df.image)]) # load test images as arrays with progress bar\n",
        "\n",
        "# scale images for test data to range of 0 to 1\n",
        "x_test_image = x_test_image/64.0\n",
        "\n",
        "#===============================================================================\n",
        "\n",
        "\n",
        "# evaluate model on test data\n",
        "y_predict = model.predict( # use model to predict\n",
        "    {\n",
        "        'summary': x_test_summary, # text test data\n",
        "        'image': x_test_image # image test data\n",
        "    }\n",
        ")\n",
        "\n",
        "price_predicted = y_predict['price'] # target prediction\n",
        "# print(price_predicted) # print predictions\n",
        "price_category_predicted = np.argmax(price_predicted, axis=1) # return indices of maximum values along an axis\n",
        "# print(price_category_predicted) # print predicted categories for targets\n",
        "\n",
        "# create submission\n",
        "pd.DataFrame(\n",
        "    {'id': x_test_df.id,\n",
        "     'price': price_category_predicted}).to_csv('sample_submission7.csv', index=False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "70fa367794724c1594e3f2ab3c1c325a",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "  0%|          | 0/7627 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_1 (InputLayer)           [(None, 100)]        0           []                               \n",
            "                                                                                                  \n",
            " embedding (Embedding)          (None, 100, 100)     4000000     ['input_1[0][0]']                \n",
            "                                                                                                  \n",
            " input_2 (InputLayer)           [(None, 64, 64, 2)]  0           []                               \n",
            "                                                                                                  \n",
            " bi_gru_0 (Bidirectional)       (None, 100, 200)     121200      ['embedding[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d (Conv2D)                (None, 49, 49, 32)   16416       ['input_2[0][0]']                \n",
            "                                                                                                  \n",
            " bi_gru_1 (Bidirectional)       [(None, 100, 200),   181200      ['bi_gru_0[0][0]']               \n",
            "                                 (None, 100),                                                     \n",
            "                                 (None, 100)]                                                     \n",
            "                                                                                                  \n",
            " max_pooling2d (MaxPooling2D)   (None, 3, 3, 32)     0           ['conv2d[0][0]']                 \n",
            "                                                                                                  \n",
            " concatenate (Concatenate)      (None, 200)          0           ['bi_gru_1[0][1]',               \n",
            "                                                                  'bi_gru_1[0][2]']               \n",
            "                                                                                                  \n",
            " dropout (Dropout)              (None, 3, 3, 32)     0           ['max_pooling2d[0][0]']          \n",
            "                                                                                                  \n",
            " attention (Attention)          ((None, 200),        4031        ['bi_gru_1[0][0]',               \n",
            "                                 (None, 100, 1))                  'concatenate[0][0]']            \n",
            "                                                                                                  \n",
            " flatten (Flatten)              (None, 288)          0           ['dropout[0][0]']                \n",
            "                                                                                                  \n",
            " tf.concat (TFOpLambda)         (None, 488)          0           ['attention[0][0]',              \n",
            "                                                                  'flatten[0][0]']                \n",
            "                                                                                                  \n",
            " price (Dense)                  (None, 3)            1467        ['tf.concat[0][0]']              \n",
            "                                                                                                  \n",
            " type (Dense)                   (None, 24)           11736       ['tf.concat[0][0]']              \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 4,336,050\n",
            "Trainable params: 4,336,050\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "Epoch 1/20\n",
            "305/305 [==============================] - 125s 391ms/step - loss: 1.2195 - price_loss: 1.1030 - type_loss: 1.3361 - price_sparse_categorical_accuracy: 0.5516 - type_sparse_categorical_accuracy: 0.7066 - val_loss: 0.9405 - val_price_loss: 0.8718 - val_type_loss: 1.0093 - val_price_sparse_categorical_accuracy: 0.6028 - val_type_sparse_categorical_accuracy: 0.7330\n",
            "Epoch 2/20\n",
            "305/305 [==============================] - 117s 384ms/step - loss: 0.9465 - price_loss: 0.8696 - type_loss: 1.0235 - price_sparse_categorical_accuracy: 0.6170 - type_sparse_categorical_accuracy: 0.7379 - val_loss: 0.8871 - val_price_loss: 0.8104 - val_type_loss: 0.9638 - val_price_sparse_categorical_accuracy: 0.6626 - val_type_sparse_categorical_accuracy: 0.7461\n",
            "Epoch 3/20\n",
            "305/305 [==============================] - 118s 388ms/step - loss: 0.7829 - price_loss: 0.7073 - type_loss: 0.8585 - price_sparse_categorical_accuracy: 0.6977 - type_sparse_categorical_accuracy: 0.7592 - val_loss: 0.8681 - val_price_loss: 0.7934 - val_type_loss: 0.9428 - val_price_sparse_categorical_accuracy: 0.6601 - val_type_sparse_categorical_accuracy: 0.7576\n",
            "Epoch 4/20\n",
            "305/305 [==============================] - 118s 385ms/step - loss: 0.6472 - price_loss: 0.5766 - type_loss: 0.7178 - price_sparse_categorical_accuracy: 0.7639 - type_sparse_categorical_accuracy: 0.7939 - val_loss: 0.8961 - val_price_loss: 0.8677 - val_type_loss: 0.9246 - val_price_sparse_categorical_accuracy: 0.6462 - val_type_sparse_categorical_accuracy: 0.7453\n",
            "Epoch 5/20\n",
            "305/305 [==============================] - 117s 384ms/step - loss: 0.5358 - price_loss: 0.4772 - type_loss: 0.5945 - price_sparse_categorical_accuracy: 0.8037 - type_sparse_categorical_accuracy: 0.8338 - val_loss: 0.9723 - val_price_loss: 0.9500 - val_type_loss: 0.9946 - val_price_sparse_categorical_accuracy: 0.6503 - val_type_sparse_categorical_accuracy: 0.7420\n",
            "Epoch 6/20\n",
            "305/305 [==============================] - 118s 386ms/step - loss: 0.4347 - price_loss: 0.3947 - type_loss: 0.4748 - price_sparse_categorical_accuracy: 0.8443 - type_sparse_categorical_accuracy: 0.8645 - val_loss: 1.0940 - val_price_loss: 1.0947 - val_type_loss: 1.0933 - val_price_sparse_categorical_accuracy: 0.6626 - val_type_sparse_categorical_accuracy: 0.7633\n",
            "Epoch 7/20\n",
            "305/305 [==============================] - 117s 385ms/step - loss: 0.3593 - price_loss: 0.3310 - type_loss: 0.3877 - price_sparse_categorical_accuracy: 0.8652 - type_sparse_categorical_accuracy: 0.8912 - val_loss: 1.2645 - val_price_loss: 1.2617 - val_type_loss: 1.2673 - val_price_sparse_categorical_accuracy: 0.6241 - val_type_sparse_categorical_accuracy: 0.7633\n",
            "Epoch 8/20\n",
            "305/305 [==============================] - 118s 386ms/step - loss: 0.2974 - price_loss: 0.2767 - type_loss: 0.3181 - price_sparse_categorical_accuracy: 0.8850 - type_sparse_categorical_accuracy: 0.9107 - val_loss: 1.4038 - val_price_loss: 1.3572 - val_type_loss: 1.4503 - val_price_sparse_categorical_accuracy: 0.6396 - val_type_sparse_categorical_accuracy: 0.7625\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b3ee53a8cc7f4b04bb11210c835c4622",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "  0%|          | 0/7360 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2k0YJjB3zLq6"
      },
      "source": [
        "### **Trial8**\n",
        "\n",
        "Results from Trial7:\n",
        "\n",
        "Epoch 4/20: val_price_loss does not improve after fourth epoch<br>- 118s 385ms/step<br> - loss: 0.6472 - price_loss: 0.5766<br> - type_loss: 0.7178<br> - price_sparse_categorical_accuracy: 0.7639<br> - type_sparse_categorical_accuracy: 0.7939<br> - val_loss: 0.8961<br> - val_price_loss: 0.8677<br> - val_type_loss: 0.9246<br> - val_price_sparse_categorical_accuracy: 0.6462<br> - val_type_sparse_categorical_accuracy: 0.7453\n",
        "\n",
        "The previous trial I concatenated the hidden states from the bidirectional GRU layers before computing the attention weights and applying the weighted sum. To my understanding, GRUs only have one hidden state transferred between time steps that  hold both the long-term and short-term dependencies. There appears to be quite a bit of overfitting based on the training and validation scores. I will apply 'l1_l2' regularization to the dense layers to prevent overfitting."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "01dda017f2294d4bb3f9cfad62834cab",
            "f7d252205fa847a8b5264f2c93a92cf6",
            "54bf1be6359e42ecb36d51d916d82006",
            "bf0cd69b20d242769d5b03ee5506b558",
            "80c8257dd0f7402a84bd9917ddfa45b2",
            "2269a0bfe4e64fa19b12b2917bebcb44",
            "fdcd27f77f4e450f8e827a7889ee9133",
            "fd7b203e301c4d3db5820939ed97b6e7",
            "de9aadf17fd242a8b6f7589bca752896",
            "aef0cbe8dcbb455e9a23cc876bbacb34",
            "998090d2982f4c1198f80cd9c1214e05",
            "9515901eebc141de820985958b1fb3f3",
            "ee848233c173467eab3235b48099d7d4",
            "e39f86b535a347bab63a8e7f5b779c2e",
            "e076a4e86d794e6f8b2ea98ab03234f0",
            "1f8dad1bd1d14fb2a79c9b0687e0e8d1",
            "7a39ba0c848d4bb0a8f946f882404b34",
            "b7979d21404c4a4e9aeb2ed08f81939a",
            "695d8a1973bb4a8d93fe17c8a8aec828",
            "62e3fe56c4d54331afe11ce672905470",
            "4ecea144aaba4ee68ac8d753fe9ae470",
            "3379ab86840f4fa2bac188cf5bf8978c"
          ]
        },
        "id": "6Vi6CmAY65RJ",
        "outputId": "fe9a22ba-8584-4670-fa63-ba8f5b6e762b"
      },
      "source": [
        "# Trial code cell\n",
        "\n",
        "# load modules\n",
        "import os\n",
        "\n",
        "import pandas as pd\n",
        "from tqdm.notebook import tqdm\n",
        "from PIL import Image\n",
        "import pandas as pd\n",
        "import os\n",
        "import numpy as np\n",
        "\n",
        "xy_train_df = pd.read_csv('train_xy.csv') # read training data into dataframe\n",
        "x_test_df = pd.read_csv('test_x.csv') # read test data into dataframe\n",
        "\n",
        "#===============================================================================\n",
        "\n",
        "# preprocess image data\n",
        "\n",
        "def load_image(file): # create function for loading images\n",
        "    try: # try this code\n",
        "        image = Image.open( # open and identify image file\n",
        "            file\n",
        "        ).convert('LA').resize((64, 64)) # convert to greyscale with alpha channel, resize to 64 by 64 pixels\n",
        "        arr = np.array(image) # return 3D array of image\n",
        "    except: # execute this code when an exception arises\n",
        "        arr = np.zeros((64, 64, 2)) # create 3D array of zeros with shape as (x,y,z)\n",
        "    return arr # return array\n",
        "\n",
        "\n",
        "# loading images:\n",
        "x_image = np.array([load_image(i) for i in tqdm(xy_train_df.image)]) # load training images as arrays with progress bar\n",
        "\n",
        "# loading summary: (force convert some of the non-string cell to string)\n",
        "x_text = xy_train_df.summary.astype('str')\n",
        "\n",
        "\n",
        "#===============================================================================\n",
        "\n",
        "from sklearn.model_selection import train_test_split # import function from module\n",
        "\n",
        "# labels:\n",
        "y_price = xy_train_df.price # subset price column\n",
        "y_type = xy_train_df.type.astype('category').cat.codes # encode type category variables\n",
        "len_price = len(y_price.unique()) # number of unique items in price category\n",
        "len_type = len(y_type.unique()) # number of unique items in type category\n",
        "# print('unique values for price category', len_price, y_price.unique()) # print number of unique items and values for price category\n",
        "# print('unique values for type category', len_type, y_type.unique()) # print number of unique items and values for type category\n",
        "\n",
        "# splitting:\n",
        "\n",
        "x_tr_image, x_vl_image, x_tr_text, x_vl_text, y_tr_price, y_vl_price, y_tr_type, y_vl_type = train_test_split(\n",
        "    x_image, # split image arrays into random train and validation subsets\n",
        "    x_text, # split series into random train and validation subsets\n",
        "    y_price, # split series into random train and validation subsets\n",
        "    y_type, # split series into random train and validation subsets\n",
        "    test_size=0.2) # training 80% validation/test 20% of data\n",
        "\n",
        "# scale image values to range of 0 to 1\n",
        "x_tr_image = x_tr_image/64.0\n",
        "x_vl_image = x_vl_image/64.0\n",
        "\n",
        "# print(np.shape(x_tr_image)) # print independent image feature training set shape\n",
        "# print(np.shape(x_vl_image)) # print independent image feature validation set shape\n",
        "# print(np.shape(y_tr_price)) # print dependent price feature training set shape\n",
        "# print(np.shape(y_vl_price)) # print dependent price feature validation set shape\n",
        "# print(np.shape(y_tr_type)) # print dependent type feature training set shape\n",
        "# print(np.shape(y_vl_type)) # print dependent type feature validation set shape\n",
        "\n",
        "#===============================================================================\n",
        "\n",
        "# preprocess text data\n",
        "\n",
        "# import modules and functions\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from sklearn.model_selection import train_test_split\n",
        "from pprint import pprint\n",
        "\n",
        "vocab_size = 40000 # set vocab_size variable to 40000\n",
        "max_len = 100 # # set max_len variable to 100\n",
        "\n",
        "\n",
        "# build vocabulary from training set\n",
        "tokenizer = Tokenizer(num_words=vocab_size) # set max number of words to keep for text tokenization\n",
        "tokenizer.fit_on_texts(x_tr_text) # create vocabulary index based on word frequency\n",
        "\n",
        "# create preprocessing function for text list\n",
        "def _preprocess(list_of_text): # param: list_of_text\n",
        "    return pad_sequences( # return padded sequences with same length\n",
        "        tokenizer.texts_to_sequences(list_of_text), # transforms each text to sequence of integers\n",
        "        maxlen=max_len, # set maximum length of all sequences\n",
        "        padding='post', # set to pad end of sequences\n",
        "    )\n",
        "\n",
        "\n",
        "# padding is done inside:\n",
        "x_tr_text_id = _preprocess(x_tr_text)\n",
        "x_vl_text_id = _preprocess(x_vl_text)\n",
        "\n",
        "# # print shapes of padded arrays\n",
        "# print(x_tr_text_id.shape)\n",
        "# print(x_vl_text_id.shape)\n",
        "\n",
        "#===============================================================================\n",
        "\n",
        "# import modules and functions\n",
        "from __future__ import absolute_import, division, print_function, unicode_literals\n",
        "import collections\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.layers import Conv2D, Flatten, Dense, MaxPool2D, Dropout, Attention, Concatenate # import dropout and attention sets\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "# set input text and image shapes\n",
        "in_text = keras.Input(batch_shape=(None, max_len)) # set max length for input text\n",
        "in_image = keras.Input(batch_shape=(None, 64, 64, 2)) # set shape for input image\n",
        "\n",
        "# text part\n",
        "embedded = keras.layers.Embedding(tokenizer.num_words, 100)(in_text) # turn positive integers (indexes) into dense vectors of fixed size\n",
        "# averaged = tf.reduce_mean(embedded, axis=1) # reduce input_tensor along dimensions given in axis using mean of elements across dimensions in axis\n",
        "\n",
        "# create attention layer consisting of three dense layers (additive attention)\n",
        "class Attention(tf.keras.Model):\n",
        "    def __init__(self, units):\n",
        "        super(Attention, self).__init__()\n",
        "        self.W1 = tf.keras.layers.Dense(units) #weight 1\n",
        "        self.W2 = tf.keras.layers.Dense(units) #weight 2\n",
        "        self.V = tf.keras.layers.Dense(1) #output vector\n",
        "\n",
        "    def call(self, features, hidden):\n",
        "        # hidden shape == (batch_size, hidden size)\n",
        "        # hidden_with_time_axis shape == (batch_size, 1, hidden size)\n",
        "        # we are doing this to perform addition to calculate the score\n",
        "        hidden_with_time_axis = tf.expand_dims(hidden, 1) # expand dimension index 1\n",
        "\n",
        "        # score shape == (batch_size, max_length, 1)\n",
        "        # we get 1 at the last axis because we are applying score to self.V\n",
        "        # the shape of the tensor before applying self.V is (batch_size, max_length, units)\n",
        "        score = tf.nn.tanh( # compute hyperbolic tangent of W1+W2 element-wise\n",
        "            self.W1(features) + self.W2(hidden_with_time_axis))\n",
        "\n",
        "        # attention_weights shape == (batch_size, max_length, 1)\n",
        "        attention_weights = tf.nn.softmax(self.V(score), axis=1) # compute softmax activation for attention weights\n",
        "\n",
        "        # context_vector shape after sum == (batch_size, hidden_size)\n",
        "        context_vector = attention_weights * features\n",
        "        context_vector = tf.reduce_sum(context_vector, axis=1) # compute sum of elements across dimensions of tensor\n",
        "\n",
        "        return context_vector, attention_weights\n",
        "\n",
        "\n",
        "\n",
        "# Bi-directional RNN\n",
        "gru = tf.keras.layers.Bidirectional(tf.keras.layers.GRU(100,return_sequences=True),name=\"bi_gru_0\")(embedded) # bidirectional gru with units=100\n",
        "# get GRU outputs\n",
        "(gru, hidden0, hidden1) = tf.keras.layers.Bidirectional(tf.keras.layers.GRU(100, return_sequences=True, return_state=True), name=\"bi_gru_1\")(gru)\n",
        "\n",
        "# concatenate hidden states from each RNN since model is using bidirectional RNN\n",
        "hidden = Concatenate()([hidden0, hidden1])\n",
        "# compute attention weights and apply weighted sum\n",
        "context_vector, attention_weights = Attention(10)(gru, hidden) #\n",
        "\n",
        "\n",
        "# image part\n",
        "cov = Conv2D(32, (16, 16))(in_image) # 2D convolution layer with 32 filters and 16 by 16 kernel_size\n",
        "pl = MaxPool2D((16, 16))(cov) # max pooling operation for 2D spatial data with 16 by 16 pool_size\n",
        "# add dropout after pooling\n",
        "pl = Dropout(0.5)(pl) # 50% dropout rate\n",
        "flattened = Flatten()(pl) # flatten input to 1D array\n",
        "\n",
        "\n",
        "# fusion:\n",
        "fused = tf.concat([context_vector, flattened], axis=-1) # concatenate tensors along one dimension\n",
        "\n",
        "# multi-objectives (each is a multi-class classification), added kernel_regularizer = 'l1l2' for both\n",
        "p_price = Dense(len_price, activation='softmax', name='price', kernel_regularizer = 'l1_l2')(fused) # dense layer with units equal to number of unique items in price category, softmax activation function\n",
        "p_type = Dense(len_type, activation='softmax', name='type', kernel_regularizer = 'l1_l2')(fused) # dense layer with units equal to number of unique items in type category, softmax activation\n",
        "\n",
        "# create model by specifying inputs and outputs\n",
        "model = keras.Model(\n",
        "    inputs={\n",
        "        'summary': in_text, # input text is listing summary\n",
        "        'image': in_image # input image\n",
        "    },\n",
        "    outputs={\n",
        "        'price': p_price, # output predicted price\n",
        "        'type': p_type, # output predicted type\n",
        "    },\n",
        ")\n",
        "\n",
        "# configure model\n",
        "model.compile(\n",
        "    optimizer=Adam(), # use 'Adam' optimizer\n",
        "    loss={\n",
        "        'price': 'sparse_categorical_crossentropy', # loss for 'price' output\n",
        "        'type': 'sparse_categorical_crossentropy', # loss for 'type' output\n",
        "    },\n",
        "    loss_weights={\n",
        "        'price': 0.5, # weight for 'price' loss\n",
        "        'type': 0.5, # weight for 'type' loss\n",
        "    },\n",
        "    metrics={\n",
        "        'price': ['SparseCategoricalAccuracy'], # metric for 'price'\n",
        "        'type': ['SparseCategoricalAccuracy'], # metric for 'type'\n",
        "    },\n",
        ")\n",
        "\n",
        "# summary for model\n",
        "model.summary()\n",
        "\n",
        "#===============================================================================\n",
        "\n",
        "# fit model on data while monitoring performance on a validation split of 0.2\n",
        "history = model.fit(\n",
        "    x={\n",
        "        'summary': x_tr_text_id, # text training data\n",
        "        'image': x_tr_image # image training data\n",
        "    },\n",
        "    y={\n",
        "        'price': y_tr_price, # text training target data\n",
        "        'type': y_tr_type, # type training target data\n",
        "    },\n",
        "    epochs=20, # 20 cycles through training data\n",
        "    batch_size=16, # number of samples processed before model is updated\n",
        "    validation_data=(\n",
        "        {\n",
        "            'summary': x_vl_text_id, # text validation data\n",
        "            'image': x_vl_image # image validation data\n",
        "         },\n",
        "        {\n",
        "            'price': y_vl_price, # price validation target data\n",
        "            'type': y_vl_type, # type validation target data\n",
        "        }),\n",
        "    validation_split=0.2, # split training and validation 80/20\n",
        "    callbacks=[ # stop training when monitored metric has stopped improving after specified number of epochs\n",
        "        tf.keras.callbacks.EarlyStopping(monitor='val_price_loss', patience=5, ) # monitor loss for validation price with patience of 5 epochs\n",
        "    ],\n",
        "    verbose=1 # progress bar\n",
        ")\n",
        "\n",
        "#===============================================================================\n",
        "\n",
        "# preprocess test data for text and image\n",
        "x_test_summary = _preprocess(x_test_df.summary.astype(str)) # preprocess test summary data\n",
        "x_test_image = np.array([load_image(i) for i in tqdm(x_test_df.image)]) # load test images as arrays with progress bar\n",
        "\n",
        "# scale images for test data to range of 0 to 1\n",
        "x_test_image = x_test_image/64.0\n",
        "\n",
        "#===============================================================================\n",
        "\n",
        "\n",
        "# evaluate model on test data\n",
        "y_predict = model.predict( # use model to predict\n",
        "    {\n",
        "        'summary': x_test_summary, # text test data\n",
        "        'image': x_test_image # image test data\n",
        "    }\n",
        ")\n",
        "\n",
        "price_predicted = y_predict['price'] # target prediction\n",
        "# print(price_predicted) # print predictions\n",
        "price_category_predicted = np.argmax(price_predicted, axis=1) # return indices of maximum values along an axis\n",
        "# print(price_category_predicted) # print predicted categories for targets\n",
        "\n",
        "# create submission\n",
        "pd.DataFrame(\n",
        "    {'id': x_test_df.id,\n",
        "     'price': price_category_predicted}).to_csv('sample_submission8.csv', index=False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "01dda017f2294d4bb3f9cfad62834cab",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "  0%|          | 0/7627 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_1 (InputLayer)           [(None, 100)]        0           []                               \n",
            "                                                                                                  \n",
            " embedding (Embedding)          (None, 100, 100)     4000000     ['input_1[0][0]']                \n",
            "                                                                                                  \n",
            " input_2 (InputLayer)           [(None, 64, 64, 2)]  0           []                               \n",
            "                                                                                                  \n",
            " bi_gru_0 (Bidirectional)       (None, 100, 200)     121200      ['embedding[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d (Conv2D)                (None, 49, 49, 32)   16416       ['input_2[0][0]']                \n",
            "                                                                                                  \n",
            " bi_gru_1 (Bidirectional)       [(None, 100, 200),   181200      ['bi_gru_0[0][0]']               \n",
            "                                 (None, 100),                                                     \n",
            "                                 (None, 100)]                                                     \n",
            "                                                                                                  \n",
            " max_pooling2d (MaxPooling2D)   (None, 3, 3, 32)     0           ['conv2d[0][0]']                 \n",
            "                                                                                                  \n",
            " concatenate (Concatenate)      (None, 200)          0           ['bi_gru_1[0][1]',               \n",
            "                                                                  'bi_gru_1[0][2]']               \n",
            "                                                                                                  \n",
            " dropout (Dropout)              (None, 3, 3, 32)     0           ['max_pooling2d[0][0]']          \n",
            "                                                                                                  \n",
            " attention (Attention)          ((None, 200),        4031        ['bi_gru_1[0][0]',               \n",
            "                                 (None, 100, 1))                  'concatenate[0][0]']            \n",
            "                                                                                                  \n",
            " flatten (Flatten)              (None, 288)          0           ['dropout[0][0]']                \n",
            "                                                                                                  \n",
            " tf.concat (TFOpLambda)         (None, 488)          0           ['attention[0][0]',              \n",
            "                                                                  'flatten[0][0]']                \n",
            "                                                                                                  \n",
            " price (Dense)                  (None, 3)            1467        ['tf.concat[0][0]']              \n",
            "                                                                                                  \n",
            " type (Dense)                   (None, 24)           11736       ['tf.concat[0][0]']              \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 4,336,050\n",
            "Trainable params: 4,336,050\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "Epoch 1/20\n",
            "305/305 [==============================] - 125s 391ms/step - loss: 3.1688 - price_loss: 1.1343 - type_loss: 1.3000 - price_sparse_categorical_accuracy: 0.5373 - type_sparse_categorical_accuracy: 0.7281 - val_loss: 1.5137 - val_price_loss: 0.8552 - val_type_loss: 1.0806 - val_price_sparse_categorical_accuracy: 0.6151 - val_type_sparse_categorical_accuracy: 0.7412\n",
            "Epoch 2/20\n",
            "305/305 [==============================] - 121s 396ms/step - loss: 1.3045 - price_loss: 0.8766 - type_loss: 1.0157 - price_sparse_categorical_accuracy: 0.5986 - type_sparse_categorical_accuracy: 0.7549 - val_loss: 1.1861 - val_price_loss: 0.8334 - val_type_loss: 1.0726 - val_price_sparse_categorical_accuracy: 0.6167 - val_type_sparse_categorical_accuracy: 0.7412\n",
            "Epoch 3/20\n",
            "305/305 [==============================] - 119s 389ms/step - loss: 1.0690 - price_loss: 0.8227 - type_loss: 0.9499 - price_sparse_categorical_accuracy: 0.6264 - type_sparse_categorical_accuracy: 0.7561 - val_loss: 1.0898 - val_price_loss: 0.8264 - val_type_loss: 1.0778 - val_price_sparse_categorical_accuracy: 0.6233 - val_type_sparse_categorical_accuracy: 0.7412\n",
            "Epoch 4/20\n",
            "305/305 [==============================] - 118s 388ms/step - loss: 0.9824 - price_loss: 0.7999 - type_loss: 0.8911 - price_sparse_categorical_accuracy: 0.6367 - type_sparse_categorical_accuracy: 0.7635 - val_loss: 1.0397 - val_price_loss: 0.8281 - val_type_loss: 0.9953 - val_price_sparse_categorical_accuracy: 0.6118 - val_type_sparse_categorical_accuracy: 0.7437\n",
            "Epoch 5/20\n",
            "305/305 [==============================] - 119s 389ms/step - loss: 0.9465 - price_loss: 0.7958 - type_loss: 0.8395 - price_sparse_categorical_accuracy: 0.6381 - type_sparse_categorical_accuracy: 0.7746 - val_loss: 1.0611 - val_price_loss: 0.8495 - val_type_loss: 1.0164 - val_price_sparse_categorical_accuracy: 0.5635 - val_type_sparse_categorical_accuracy: 0.7379\n",
            "Epoch 6/20\n",
            "305/305 [==============================] - 118s 386ms/step - loss: 0.9871 - price_loss: 0.8069 - type_loss: 0.9173 - price_sparse_categorical_accuracy: 0.6145 - type_sparse_categorical_accuracy: 0.7564 - val_loss: 1.1380 - val_price_loss: 0.8511 - val_type_loss: 1.1480 - val_price_sparse_categorical_accuracy: 0.6151 - val_type_sparse_categorical_accuracy: 0.7412\n",
            "Epoch 7/20\n",
            "305/305 [==============================] - 117s 384ms/step - loss: 0.9935 - price_loss: 0.7949 - type_loss: 0.9227 - price_sparse_categorical_accuracy: 0.6264 - type_sparse_categorical_accuracy: 0.7482 - val_loss: 1.0635 - val_price_loss: 0.8497 - val_type_loss: 1.0212 - val_price_sparse_categorical_accuracy: 0.5569 - val_type_sparse_categorical_accuracy: 0.7412\n",
            "Epoch 8/20\n",
            "305/305 [==============================] - 117s 385ms/step - loss: 0.9200 - price_loss: 0.7512 - type_loss: 0.8120 - price_sparse_categorical_accuracy: 0.6555 - type_sparse_categorical_accuracy: 0.7742 - val_loss: 1.1624 - val_price_loss: 0.8617 - val_type_loss: 1.1575 - val_price_sparse_categorical_accuracy: 0.5659 - val_type_sparse_categorical_accuracy: 0.6503\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "9515901eebc141de820985958b1fb3f3",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "  0%|          | 0/7360 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4keiof42pWA0"
      },
      "source": [
        "### **Trial9**\n",
        "\n",
        "Trial8 results:\n",
        "\n",
        "Epoch 3/20: does not improve after third epoch<br> - 119s 389ms/step - loss: 1.0690<br> - price_loss: 0.8227<br> - type_loss: 0.9499<br> - price_sparse_categorical_accuracy: 0.6264<br> - type_sparse_categorical_accuracy: 0.7561<br> - val_loss: 1.0898<br> - val_price_loss: 0.8264<br> - val_type_loss: 1.0778<br> - val_price_sparse_categorical_accuracy: 0.6233<br> - val_type_sparse_categorical_accuracy: 0.7412\n",
        "\n",
        "The overfitting seems to have been mitigated from the regularization.\n",
        "\n",
        "In this trial I will add a second convolution layer to the image layer, hoping it will increase the model performance."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "4eb4cc900b3d450fad02fb820028ef1d",
            "0200e0b685314bb6a27d565934414e87",
            "0b636acd683b4f3a83ee7520f9ac0f38",
            "502897b532234336a3e16b76888e6591",
            "380f64a2db064adc89996d87298330a6",
            "3e58c67d803b4c598fb4a706dd887cf4",
            "c84ea6e8d91e4773939f3f88ccc7c2ae",
            "cd0fb2a41e1b451db33cd58233a83124",
            "806e500ec153429dabe36be7b9782e8b",
            "72581956aa55462fb6fad7eb5c8f1ed2",
            "e105852f04da454dab04fbb78d2733f9",
            "d6507eb078024c1ca43166c38e12b557",
            "7e9a5774ffd64ac3a151f9511eb3a051",
            "061b1a3ae94c4887a9dcbe863c9a9c7c",
            "f4f2ecde492c43188ca4043bdbf414b6",
            "93d3049ac829454cbc899955d4367908",
            "b04861ea112f4fc2bb29ea9324ca3491",
            "93190f8c059e435784c00c590c08c259",
            "11cbcc3f441b4863af24c9014dfa7712",
            "d3934c374efc449085ff5e521b6b9c45",
            "9ad00219efb04b5bb06f635cd54a5f0d",
            "95910c2ecb4443baa33a75d24d2da254"
          ]
        },
        "id": "4RVUPvqJ65V4",
        "outputId": "a9b217e9-447e-479c-cb48-08aec7b83c62"
      },
      "source": [
        "# Trial code cell\n",
        "\n",
        "# load modules\n",
        "import os\n",
        "\n",
        "import pandas as pd\n",
        "from tqdm.notebook import tqdm\n",
        "from PIL import Image\n",
        "import pandas as pd\n",
        "import os\n",
        "import numpy as np\n",
        "\n",
        "xy_train_df = pd.read_csv('train_xy.csv') # read training data into dataframe\n",
        "x_test_df = pd.read_csv('test_x.csv') # read test data into dataframe\n",
        "\n",
        "#===============================================================================\n",
        "\n",
        "# preprocess image data\n",
        "\n",
        "def load_image(file): # create function for loading images\n",
        "    try: # try this code\n",
        "        image = Image.open( # open and identify image file\n",
        "            file\n",
        "        ).convert('LA').resize((64, 64)) # convert to greyscale with alpha channel, resize to 64 by 64 pixels\n",
        "        arr = np.array(image) # return 3D array of image\n",
        "    except: # execute this code when an exception arises\n",
        "        arr = np.zeros((64, 64, 2)) # create 3D array of zeros with shape as (x,y,z)\n",
        "    return arr # return array\n",
        "\n",
        "\n",
        "# loading images:\n",
        "x_image = np.array([load_image(i) for i in tqdm(xy_train_df.image)]) # load training images as arrays with progress bar\n",
        "\n",
        "# loading summary: (force convert some of the non-string cell to string)\n",
        "x_text = xy_train_df.summary.astype('str')\n",
        "\n",
        "\n",
        "#===============================================================================\n",
        "\n",
        "from sklearn.model_selection import train_test_split # import function from module\n",
        "\n",
        "# labels:\n",
        "y_price = xy_train_df.price # subset price column\n",
        "y_type = xy_train_df.type.astype('category').cat.codes # encode type category variables\n",
        "len_price = len(y_price.unique()) # number of unique items in price category\n",
        "len_type = len(y_type.unique()) # number of unique items in type category\n",
        "# print('unique values for price category', len_price, y_price.unique()) # print number of unique items and values for price category\n",
        "# print('unique values for type category', len_type, y_type.unique()) # print number of unique items and values for type category\n",
        "\n",
        "# splitting:\n",
        "\n",
        "x_tr_image, x_vl_image, x_tr_text, x_vl_text, y_tr_price, y_vl_price, y_tr_type, y_vl_type = train_test_split(\n",
        "    x_image, # split image arrays into random train and validation subsets\n",
        "    x_text, # split series into random train and validation subsets\n",
        "    y_price, # split series into random train and validation subsets\n",
        "    y_type, # split series into random train and validation subsets\n",
        "    test_size=0.2) # training 80% validation/test 20% of data\n",
        "\n",
        "# scale image values to range of 0 to 1\n",
        "x_tr_image = x_tr_image/64.0\n",
        "x_vl_image = x_vl_image/64.0\n",
        "\n",
        "# print(np.shape(x_tr_image)) # print independent image feature training set shape\n",
        "# print(np.shape(x_vl_image)) # print independent image feature validation set shape\n",
        "# print(np.shape(y_tr_price)) # print dependent price feature training set shape\n",
        "# print(np.shape(y_vl_price)) # print dependent price feature validation set shape\n",
        "# print(np.shape(y_tr_type)) # print dependent type feature training set shape\n",
        "# print(np.shape(y_vl_type)) # print dependent type feature validation set shape\n",
        "\n",
        "#===============================================================================\n",
        "\n",
        "# preprocess text data\n",
        "\n",
        "# import modules and functions\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from sklearn.model_selection import train_test_split\n",
        "from pprint import pprint\n",
        "\n",
        "vocab_size = 40000 # set vocab_size variable to 40000\n",
        "max_len = 100 # # set max_len variable to 100\n",
        "\n",
        "\n",
        "# build vocabulary from training set\n",
        "tokenizer = Tokenizer(num_words=vocab_size) # set max number of words to keep for text tokenization\n",
        "tokenizer.fit_on_texts(x_tr_text) # create vocabulary index based on word frequency\n",
        "\n",
        "# create preprocessing function for text list\n",
        "def _preprocess(list_of_text): # param: list_of_text\n",
        "    return pad_sequences( # return padded sequences with same length\n",
        "        tokenizer.texts_to_sequences(list_of_text), # transforms each text to sequence of integers\n",
        "        maxlen=max_len, # set maximum length of all sequences\n",
        "        padding='post', # set to pad end of sequences\n",
        "    )\n",
        "\n",
        "\n",
        "# padding is done inside:\n",
        "x_tr_text_id = _preprocess(x_tr_text)\n",
        "x_vl_text_id = _preprocess(x_vl_text)\n",
        "\n",
        "# # print shapes of padded arrays\n",
        "# print(x_tr_text_id.shape)\n",
        "# print(x_vl_text_id.shape)\n",
        "\n",
        "#===============================================================================\n",
        "\n",
        "# import modules and functions\n",
        "from __future__ import absolute_import, division, print_function, unicode_literals\n",
        "import collections\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.layers import Conv2D, Flatten, Dense, MaxPool2D, Dropout, Attention, Concatenate # import dropout and attention sets\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "# set input text and image shapes\n",
        "in_text = keras.Input(batch_shape=(None, max_len)) # set max length for input text\n",
        "in_image = keras.Input(batch_shape=(None, 64, 64, 2)) # set shape for input image\n",
        "\n",
        "# text part\n",
        "embedded = keras.layers.Embedding(tokenizer.num_words, 100)(in_text) # turn positive integers (indexes) into dense vectors of fixed size\n",
        "# averaged = tf.reduce_mean(embedded, axis=1) # reduce input_tensor along dimensions given in axis using mean of elements across dimensions in axis\n",
        "\n",
        "# create attention layer consisting of three dense layers (additive attention)\n",
        "class Attention(tf.keras.Model):\n",
        "    def __init__(self, units):\n",
        "        super(Attention, self).__init__()\n",
        "        self.W1 = tf.keras.layers.Dense(units) #weight 1\n",
        "        self.W2 = tf.keras.layers.Dense(units) #weight 2\n",
        "        self.V = tf.keras.layers.Dense(1) #output vector\n",
        "\n",
        "    def call(self, features, hidden):\n",
        "        # hidden shape == (batch_size, hidden size)\n",
        "        # hidden_with_time_axis shape == (batch_size, 1, hidden size)\n",
        "        # we are doing this to perform addition to calculate the score\n",
        "        hidden_with_time_axis = tf.expand_dims(hidden, 1) # expand dimension index 1\n",
        "\n",
        "        # score shape == (batch_size, max_length, 1)\n",
        "        # we get 1 at the last axis because we are applying score to self.V\n",
        "        # the shape of the tensor before applying self.V is (batch_size, max_length, units)\n",
        "        score = tf.nn.tanh( # compute hyperbolic tangent of W1+W2 element-wise\n",
        "            self.W1(features) + self.W2(hidden_with_time_axis))\n",
        "\n",
        "        # attention_weights shape == (batch_size, max_length, 1)\n",
        "        attention_weights = tf.nn.softmax(self.V(score), axis=1) # compute softmax activation for attention weights\n",
        "\n",
        "        # context_vector shape after sum == (batch_size, hidden_size)\n",
        "        context_vector = attention_weights * features\n",
        "        context_vector = tf.reduce_sum(context_vector, axis=1) # compute sum of elements across dimensions of tensor\n",
        "\n",
        "        return context_vector, attention_weights\n",
        "\n",
        "\n",
        "\n",
        "# Bi-directional RNN\n",
        "gru = tf.keras.layers.Bidirectional(tf.keras.layers.GRU(100,return_sequences=True),name=\"bi_gru_0\")(embedded) # bidirectional gru with units=100\n",
        "# get GRU outputs\n",
        "(gru, hidden0, hidden1) = tf.keras.layers.Bidirectional(tf.keras.layers.GRU(100, return_sequences=True, return_state=True), name=\"bi_gru_1\")(gru)\n",
        "\n",
        "# concatenate hidden states from each RNN since model is using bidirectional RNN\n",
        "hidden = Concatenate()([hidden0, hidden1])\n",
        "# compute attention weights and apply weighted sum\n",
        "context_vector, attention_weights = Attention(10)(gru, hidden) #\n",
        "\n",
        "\n",
        "# image part\n",
        "cov = Conv2D(32, (16, 16))(in_image) # 2D convolution layer with 32 filters and 16 by 16 kernel_size\n",
        "cov1 = Conv2D(32, (16, 16))(cov) # 2D convolution layer with 32 filters and 16 by 16 kernel_size\n",
        "pl = MaxPool2D((16, 16))(cov1) # max pooling operation for 2D spatial data with 16 by 16 pool_size\n",
        "# add dropout after pooling\n",
        "pl = Dropout(0.5)(pl) # 50% dropout rate\n",
        "flattened = Flatten()(pl) # flatten input to 1D array\n",
        "\n",
        "\n",
        "# fusion:\n",
        "fused = tf.concat([context_vector, flattened], axis=-1) # concatenate tensors along one dimension\n",
        "\n",
        "# multi-objectives (each is a multi-class classification), added kernel_regularizer = 'l1l2' for both\n",
        "p_price = Dense(len_price, activation='softmax', name='price', kernel_regularizer = 'l1_l2')(fused) # dense layer with units equal to number of unique items in price category, softmax activation function\n",
        "p_type = Dense(len_type, activation='softmax', name='type', kernel_regularizer = 'l1_l2')(fused) # dense layer with units equal to number of unique items in type category, softmax activation\n",
        "\n",
        "# create model by specifying inputs and outputs\n",
        "model = keras.Model(\n",
        "    inputs={\n",
        "        'summary': in_text, # input text is listing summary\n",
        "        'image': in_image # input image\n",
        "    },\n",
        "    outputs={\n",
        "        'price': p_price, # output predicted price\n",
        "        'type': p_type, # output predicted type\n",
        "    },\n",
        ")\n",
        "\n",
        "# configure model\n",
        "model.compile(\n",
        "    optimizer=Adam(), # use 'Adam' optimizer\n",
        "    loss={\n",
        "        'price': 'sparse_categorical_crossentropy', # loss for 'price' output\n",
        "        'type': 'sparse_categorical_crossentropy', # loss for 'type' output\n",
        "    },\n",
        "    loss_weights={\n",
        "        'price': 0.5, # weight for 'price' loss\n",
        "        'type': 0.5, # weight for 'type' loss\n",
        "    },\n",
        "    metrics={\n",
        "        'price': ['SparseCategoricalAccuracy'], # metric for 'price'\n",
        "        'type': ['SparseCategoricalAccuracy'], # metric for 'type'\n",
        "    },\n",
        ")\n",
        "\n",
        "# summary for model\n",
        "model.summary()\n",
        "\n",
        "#===============================================================================\n",
        "\n",
        "# fit model on data while monitoring performance on a validation split of 0.2\n",
        "history = model.fit(\n",
        "    x={\n",
        "        'summary': x_tr_text_id, # text training data\n",
        "        'image': x_tr_image # image training data\n",
        "    },\n",
        "    y={\n",
        "        'price': y_tr_price, # text training target data\n",
        "        'type': y_tr_type, # type training target data\n",
        "    },\n",
        "    epochs=20, # 20 cycles through training data\n",
        "    batch_size=16, # number of samples processed before model is updated\n",
        "    validation_data=(\n",
        "        {\n",
        "            'summary': x_vl_text_id, # text validation data\n",
        "            'image': x_vl_image # image validation data\n",
        "         },\n",
        "        {\n",
        "            'price': y_vl_price, # price validation target data\n",
        "            'type': y_vl_type, # type validation target data\n",
        "        }),\n",
        "    validation_split=0.2, # split training and validation 80/20\n",
        "    callbacks=[ # stop training when monitored metric has stopped improving after specified number of epochs\n",
        "        tf.keras.callbacks.EarlyStopping(monitor='val_price_loss', patience=5, ) # monitor loss for validation price with patience of 5 epochs\n",
        "    ],\n",
        "    verbose=1 # progress bar\n",
        ")\n",
        "\n",
        "#===============================================================================\n",
        "\n",
        "# preprocess test data for text and image\n",
        "x_test_summary = _preprocess(x_test_df.summary.astype(str)) # preprocess test summary data\n",
        "x_test_image = np.array([load_image(i) for i in tqdm(x_test_df.image)]) # load test images as arrays with progress bar\n",
        "\n",
        "# scale images for test data to range of 0 to 1\n",
        "x_test_image = x_test_image/64.0\n",
        "\n",
        "#===============================================================================\n",
        "\n",
        "\n",
        "# evaluate model on test data\n",
        "y_predict = model.predict( # use model to predict\n",
        "    {\n",
        "        'summary': x_test_summary, # text test data\n",
        "        'image': x_test_image # image test data\n",
        "    }\n",
        ")\n",
        "\n",
        "price_predicted = y_predict['price'] # target prediction\n",
        "# print(price_predicted) # print predictions\n",
        "price_category_predicted = np.argmax(price_predicted, axis=1) # return indices of maximum values along an axis\n",
        "# print(price_category_predicted) # print predicted categories for targets\n",
        "\n",
        "# create submission\n",
        "pd.DataFrame(\n",
        "    {'id': x_test_df.id,\n",
        "     'price': price_category_predicted}).to_csv('sample_submission9.csv', index=False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "4eb4cc900b3d450fad02fb820028ef1d",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "  0%|          | 0/7627 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_1 (InputLayer)           [(None, 100)]        0           []                               \n",
            "                                                                                                  \n",
            " input_2 (InputLayer)           [(None, 64, 64, 2)]  0           []                               \n",
            "                                                                                                  \n",
            " embedding (Embedding)          (None, 100, 100)     4000000     ['input_1[0][0]']                \n",
            "                                                                                                  \n",
            " conv2d (Conv2D)                (None, 49, 49, 32)   16416       ['input_2[0][0]']                \n",
            "                                                                                                  \n",
            " bi_gru_0 (Bidirectional)       (None, 100, 200)     121200      ['embedding[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_1 (Conv2D)              (None, 34, 34, 32)   262176      ['conv2d[0][0]']                 \n",
            "                                                                                                  \n",
            " bi_gru_1 (Bidirectional)       [(None, 100, 200),   181200      ['bi_gru_0[0][0]']               \n",
            "                                 (None, 100),                                                     \n",
            "                                 (None, 100)]                                                     \n",
            "                                                                                                  \n",
            " max_pooling2d (MaxPooling2D)   (None, 2, 2, 32)     0           ['conv2d_1[0][0]']               \n",
            "                                                                                                  \n",
            " concatenate (Concatenate)      (None, 200)          0           ['bi_gru_1[0][1]',               \n",
            "                                                                  'bi_gru_1[0][2]']               \n",
            "                                                                                                  \n",
            " dropout (Dropout)              (None, 2, 2, 32)     0           ['max_pooling2d[0][0]']          \n",
            "                                                                                                  \n",
            " attention (Attention)          ((None, 200),        4031        ['bi_gru_1[0][0]',               \n",
            "                                 (None, 100, 1))                  'concatenate[0][0]']            \n",
            "                                                                                                  \n",
            " flatten (Flatten)              (None, 128)          0           ['dropout[0][0]']                \n",
            "                                                                                                  \n",
            " tf.concat (TFOpLambda)         (None, 328)          0           ['attention[0][0]',              \n",
            "                                                                  'flatten[0][0]']                \n",
            "                                                                                                  \n",
            " price (Dense)                  (None, 3)            987         ['tf.concat[0][0]']              \n",
            "                                                                                                  \n",
            " type (Dense)                   (None, 24)           7896        ['tf.concat[0][0]']              \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 4,593,906\n",
            "Trainable params: 4,593,906\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "Epoch 1/20\n",
            "305/305 [==============================] - 83s 152ms/step - loss: 4.1312 - price_loss: 1.7324 - type_loss: 1.9689 - price_sparse_categorical_accuracy: 0.5445 - type_sparse_categorical_accuracy: 0.6977 - val_loss: 2.0291 - val_price_loss: 0.8230 - val_type_loss: 1.0749 - val_price_sparse_categorical_accuracy: 0.6216 - val_type_sparse_categorical_accuracy: 0.7617\n",
            "Epoch 2/20\n",
            "305/305 [==============================] - 44s 144ms/step - loss: 1.7261 - price_loss: 0.9330 - type_loss: 1.0673 - price_sparse_categorical_accuracy: 0.5928 - type_sparse_categorical_accuracy: 0.7436 - val_loss: 1.3858 - val_price_loss: 0.8479 - val_type_loss: 0.9813 - val_price_sparse_categorical_accuracy: 0.6249 - val_type_sparse_categorical_accuracy: 0.7592\n",
            "Epoch 3/20\n",
            "305/305 [==============================] - 44s 145ms/step - loss: 1.2553 - price_loss: 0.8537 - type_loss: 0.9496 - price_sparse_categorical_accuracy: 0.6217 - type_sparse_categorical_accuracy: 0.7504 - val_loss: 1.2244 - val_price_loss: 0.8859 - val_type_loss: 1.0216 - val_price_sparse_categorical_accuracy: 0.6323 - val_type_sparse_categorical_accuracy: 0.7543\n",
            "Epoch 4/20\n",
            "305/305 [==============================] - 44s 145ms/step - loss: 1.0337 - price_loss: 0.7557 - type_loss: 0.8682 - price_sparse_categorical_accuracy: 0.6709 - type_sparse_categorical_accuracy: 0.7684 - val_loss: 1.0665 - val_price_loss: 0.8171 - val_type_loss: 0.9344 - val_price_sparse_categorical_accuracy: 0.6233 - val_type_sparse_categorical_accuracy: 0.7494\n",
            "Epoch 5/20\n",
            "305/305 [==============================] - 44s 146ms/step - loss: 0.9194 - price_loss: 0.6986 - type_loss: 0.7987 - price_sparse_categorical_accuracy: 0.6992 - type_sparse_categorical_accuracy: 0.7811 - val_loss: 1.0176 - val_price_loss: 0.7782 - val_type_loss: 0.9625 - val_price_sparse_categorical_accuracy: 0.6626 - val_type_sparse_categorical_accuracy: 0.7330\n",
            "Epoch 6/20\n",
            "305/305 [==============================] - 45s 147ms/step - loss: 0.8265 - price_loss: 0.6008 - type_loss: 0.7574 - price_sparse_categorical_accuracy: 0.7709 - type_sparse_categorical_accuracy: 0.7912 - val_loss: 1.0370 - val_price_loss: 0.8162 - val_type_loss: 0.9840 - val_price_sparse_categorical_accuracy: 0.6560 - val_type_sparse_categorical_accuracy: 0.7281\n",
            "Epoch 7/20\n",
            "305/305 [==============================] - 45s 148ms/step - loss: 0.7774 - price_loss: 0.5383 - type_loss: 0.7328 - price_sparse_categorical_accuracy: 0.8086 - type_sparse_categorical_accuracy: 0.7941 - val_loss: 1.0712 - val_price_loss: 0.8450 - val_type_loss: 1.0220 - val_price_sparse_categorical_accuracy: 0.6470 - val_type_sparse_categorical_accuracy: 0.7461\n",
            "Epoch 8/20\n",
            "305/305 [==============================] - 45s 147ms/step - loss: 0.7286 - price_loss: 0.4740 - type_loss: 0.7146 - price_sparse_categorical_accuracy: 0.8416 - type_sparse_categorical_accuracy: 0.7996 - val_loss: 1.0632 - val_price_loss: 0.8746 - val_type_loss: 0.9900 - val_price_sparse_categorical_accuracy: 0.6274 - val_type_sparse_categorical_accuracy: 0.7428\n",
            "Epoch 9/20\n",
            "305/305 [==============================] - 45s 147ms/step - loss: 0.6919 - price_loss: 0.4212 - type_loss: 0.6957 - price_sparse_categorical_accuracy: 0.8574 - type_sparse_categorical_accuracy: 0.8027 - val_loss: 1.1207 - val_price_loss: 0.9401 - val_type_loss: 1.0222 - val_price_sparse_categorical_accuracy: 0.6568 - val_type_sparse_categorical_accuracy: 0.7232\n",
            "Epoch 10/20\n",
            "305/305 [==============================] - 45s 147ms/step - loss: 0.6761 - price_loss: 0.3896 - type_loss: 0.6868 - price_sparse_categorical_accuracy: 0.8686 - type_sparse_categorical_accuracy: 0.8018 - val_loss: 1.1027 - val_price_loss: 0.9433 - val_type_loss: 0.9827 - val_price_sparse_categorical_accuracy: 0.6413 - val_type_sparse_categorical_accuracy: 0.7412\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d6507eb078024c1ca43166c38e12b557",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "  0%|          | 0/7360 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7PJ1vDLby6Rg"
      },
      "source": [
        "### **Trial10**\n",
        "\n",
        "Trial9 results:\n",
        "\n",
        "Epoch 5/20<br> - 44s 146ms/step<br>  - loss: 0.9194<br>  - price_loss: 0.6986<br>  - type_loss: 0.7987<br>  - price_sparse_categorical_accuracy: 0.6992<br>  - type_sparse_categorical_accuracy: 0.7811<br>  - val_loss: 1.0176<br>  - val_price_loss: 0.7782<br>  - val_type_loss: 0.9625<br>  - val_price_sparse_categorical_accuracy: 0.6626<br>  - val_type_sparse_categorical_accuracy: 0.7330\n",
        "\n",
        "Model did not improve, some overfitting is evident. Will add a third conv, pooling, and dropout layer to try and improve model performance while addressing the overfitting. Additionally I will increase attention layer units to 100, and add data augmentation for images."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gQfeiFQhy6bI",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "b2a249f69d494efbb9149aaa61d7a991",
            "2a9782171814454aa191e1d0c73e629b",
            "c9717639910845bab86d2b8c2296e5aa",
            "f2a4a9e3e8cf42e38b095c64f9e1317f",
            "bb086071c54141c38aa49d29163e7ead",
            "6a40ce4671cd4b8895ac5025856b1a5f",
            "9d6c81133df146a893631082e9ccfcae",
            "6c127fd81e634012b6db2abd3030efa9",
            "4e696ede1fab48fbbee147b2615a082b",
            "546426f7b645426db32aed99d6b51200",
            "f7441508ab0e4ab999b7fb7e34f5e623",
            "60bde454b1984215bea5e51558115079",
            "1d9ca7a19e024061b7145e56d059eb00",
            "6f1e680bcb0749acb22cdd5bd206eea0",
            "589a0688ecf844bfa248c9ce95585f13",
            "b53b75c3c86b4beaaee8641c27c9bff3",
            "95b732346307492ca2e0f7a8fe7e8925",
            "202d432512b143bdaca921811c90271f",
            "2887ee0f11de49bba66b17a11492be9e",
            "fe04f5d8cb9c43df85051b7229a00e89",
            "823b7d142cef4bce96b7ec44fa20e309",
            "317991a6e77c48749842e9b2192fbe0a"
          ]
        },
        "outputId": "98a9ac49-6ecf-43bf-ffb6-4343d452ae55"
      },
      "source": [
        "# Trial code cell\n",
        "\n",
        "# load modules\n",
        "import os\n",
        "\n",
        "import pandas as pd\n",
        "from tqdm.notebook import tqdm\n",
        "from PIL import Image\n",
        "import pandas as pd\n",
        "import os\n",
        "import numpy as np\n",
        "\n",
        "xy_train_df = pd.read_csv('train_xy.csv') # read training data into dataframe\n",
        "x_test_df = pd.read_csv('test_x.csv') # read test data into dataframe\n",
        "\n",
        "#===============================================================================\n",
        "\n",
        "# preprocess image data\n",
        "\n",
        "def load_image(file): # create function for loading images\n",
        "    try: # try this code\n",
        "        image = Image.open( # open and identify image file\n",
        "            file\n",
        "        ).convert('LA').resize((64, 64)) # convert to greyscale with alpha channel, resize to 64 by 64 pixels\n",
        "        arr = np.array(image) # return 3D array of image\n",
        "    except: # execute this code when an exception arises\n",
        "        arr = np.zeros((64, 64, 2)) # create 3D array of zeros with shape as (x,y,z)\n",
        "    return arr # return array\n",
        "\n",
        "\n",
        "# loading images:\n",
        "x_image = np.array([load_image(i) for i in tqdm(xy_train_df.image)]) # load training images as arrays with progress bar\n",
        "\n",
        "# loading summary: (force convert some of the non-string cell to string)\n",
        "x_text = xy_train_df.summary.astype('str')\n",
        "\n",
        "\n",
        "#===============================================================================\n",
        "\n",
        "from sklearn.model_selection import train_test_split # import function from module\n",
        "\n",
        "# labels:\n",
        "y_price = xy_train_df.price # subset price column\n",
        "y_type = xy_train_df.type.astype('category').cat.codes # encode type category variables\n",
        "len_price = len(y_price.unique()) # number of unique items in price category\n",
        "len_type = len(y_type.unique()) # number of unique items in type category\n",
        "# print('unique values for price category', len_price, y_price.unique()) # print number of unique items and values for price category\n",
        "# print('unique values for type category', len_type, y_type.unique()) # print number of unique items and values for type category\n",
        "\n",
        "# splitting:\n",
        "\n",
        "x_tr_image, x_vl_image, x_tr_text, x_vl_text, y_tr_price, y_vl_price, y_tr_type, y_vl_type = train_test_split(\n",
        "    x_image, # split image arrays into random train and validation subsets\n",
        "    x_text, # split series into random train and validation subsets\n",
        "    y_price, # split series into random train and validation subsets\n",
        "    y_type, # split series into random train and validation subsets\n",
        "    test_size=0.2) # training 80% validation/test 20% of data\n",
        "\n",
        "# scale image values to range of 0 to 1\n",
        "x_tr_image = x_tr_image/64.0\n",
        "x_vl_image = x_vl_image/64.0\n",
        "\n",
        "# print(np.shape(x_tr_image)) # print independent image feature training set shape\n",
        "# print(np.shape(x_vl_image)) # print independent image feature validation set shape\n",
        "# print(np.shape(y_tr_price)) # print dependent price feature training set shape\n",
        "# print(np.shape(y_vl_price)) # print dependent price feature validation set shape\n",
        "# print(np.shape(y_tr_type)) # print dependent type feature training set shape\n",
        "# print(np.shape(y_vl_type)) # print dependent type feature validation set shape\n",
        "\n",
        "#===============================================================================\n",
        "\n",
        "# preprocess text data\n",
        "\n",
        "# import modules and functions\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from sklearn.model_selection import train_test_split\n",
        "from pprint import pprint\n",
        "\n",
        "vocab_size = 40000 # set vocab_size variable to 40000\n",
        "max_len = 100 # # set max_len variable to 100\n",
        "\n",
        "\n",
        "# build vocabulary from training set\n",
        "tokenizer = Tokenizer(num_words=vocab_size) # set max number of words to keep for text tokenization\n",
        "tokenizer.fit_on_texts(x_tr_text) # create vocabulary index based on word frequency\n",
        "\n",
        "# create preprocessing function for text list\n",
        "def _preprocess(list_of_text): # param: list_of_text\n",
        "    return pad_sequences( # return padded sequences with same length\n",
        "        tokenizer.texts_to_sequences(list_of_text), # transforms each text to sequence of integers\n",
        "        maxlen=max_len, # set maximum length of all sequences\n",
        "        padding='post', # set to pad end of sequences\n",
        "    )\n",
        "\n",
        "\n",
        "# padding is done inside:\n",
        "x_tr_text_id = _preprocess(x_tr_text)\n",
        "x_vl_text_id = _preprocess(x_vl_text)\n",
        "\n",
        "# # print shapes of padded arrays\n",
        "# print(x_tr_text_id.shape)\n",
        "# print(x_vl_text_id.shape)\n",
        "\n",
        "#===============================================================================\n",
        "\n",
        "# import modules and functions\n",
        "from __future__ import absolute_import, division, print_function, unicode_literals\n",
        "import collections\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.layers import Conv2D, Flatten, Dense, MaxPool2D, Dropout, Attention, Concatenate # import dropout and attention sets\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras import layers # required for data augmentation layers\n",
        "\n",
        "# create data augmentation stage\n",
        "data_augmentation = tf.keras.Sequential(\n",
        "    [\n",
        "     layers.RandomFlip('horizontal_and_vertical'), # random 'horizontal_and_vertical' flipping\n",
        "     layers.RandomRotation(0.1) # rotation by random amount in range as fraction of 2 Pi\n",
        "    ]\n",
        ")\n",
        "\n",
        "# set input text and image shapes\n",
        "in_text = keras.Input(batch_shape=(None, max_len)) # set max length for input text\n",
        "in_image = keras.Input(batch_shape=(None, 64, 64, 2)) # set shape for input image\n",
        "in_image = data_augmentation(in_image) # augmentation of input image\n",
        "\n",
        "# text part\n",
        "embedded = keras.layers.Embedding(tokenizer.num_words, 100)(in_text) # turn positive integers (indexes) into dense vectors of fixed size\n",
        "# averaged = tf.reduce_mean(embedded, axis=1) # reduce input_tensor along dimensions given in axis using mean of elements across dimensions in axis\n",
        "\n",
        "# create attention layer consisting of three dense layers (additive attention)\n",
        "class Attention(tf.keras.Model):\n",
        "    def __init__(self, units):\n",
        "        super(Attention, self).__init__()\n",
        "        self.W1 = tf.keras.layers.Dense(units) #weight 1\n",
        "        self.W2 = tf.keras.layers.Dense(units) #weight 2\n",
        "        self.V = tf.keras.layers.Dense(1) #output vector\n",
        "\n",
        "    def call(self, features, hidden):\n",
        "        # hidden shape == (batch_size, hidden size)\n",
        "        # hidden_with_time_axis shape == (batch_size, 1, hidden size)\n",
        "        # we are doing this to perform addition to calculate the score\n",
        "        hidden_with_time_axis = tf.expand_dims(hidden, 1) # expand dimension index 1\n",
        "\n",
        "        # score shape == (batch_size, max_length, 1)\n",
        "        # we get 1 at the last axis because we are applying score to self.V\n",
        "        # the shape of the tensor before applying self.V is (batch_size, max_length, units)\n",
        "        score = tf.nn.tanh( # compute hyperbolic tangent of W1+W2 element-wise\n",
        "            self.W1(features) + self.W2(hidden_with_time_axis))\n",
        "\n",
        "        # attention_weights shape == (batch_size, max_length, 1)\n",
        "        attention_weights = tf.nn.softmax(self.V(score), axis=1) # compute softmax activation for attention weights\n",
        "\n",
        "        # context_vector shape after sum == (batch_size, hidden_size)\n",
        "        context_vector = attention_weights * features\n",
        "        context_vector = tf.reduce_sum(context_vector, axis=1) # compute sum of elements across dimensions of tensor\n",
        "\n",
        "        return context_vector, attention_weights\n",
        "\n",
        "\n",
        "\n",
        "# Bi-directional RNN\n",
        "gru = tf.keras.layers.Bidirectional(tf.keras.layers.GRU(100,return_sequences=True),name=\"bi_gru_0\")(embedded) # bidirectional gru with units=100\n",
        "# get GRU outputs\n",
        "(gru, hidden0, hidden1) = tf.keras.layers.Bidirectional(tf.keras.layers.GRU(100, return_sequences=True, return_state=True), name=\"bi_gru_1\")(gru)\n",
        "\n",
        "# concatenate hidden states from each RNN since model is using bidirectional RNN\n",
        "hidden = Concatenate()([hidden0, hidden1])\n",
        "# compute attention weights and apply weighted sum\n",
        "context_vector, attention_weights = Attention(100)(gru, hidden) #\n",
        "\n",
        "\n",
        "# image part\n",
        "cov = Conv2D(32, (4, 4))(in_image) # 2D convolution layer with 64 filters and 16 by 16 kernel_size\n",
        "cov1 = Conv2D(32, (4, 4))(cov) # 2D convolution layer with 64 filters and 16 by 16 kernel_size\n",
        "pl = MaxPool2D((4, 4))(cov1) # max pooling operation for 2D spatial data with 16 by 16 pool_size\n",
        "# add dropout after pooling\n",
        "pl = Dropout(0.5)(pl) # 50% dropout rate\n",
        "cov3 = Conv2D(16, (2, 2))(pl) # 2D convolution layer with 32 filters and 16 by 16 kernel_size\n",
        "pl1 = MaxPool2D((2, 2))(cov3) # max pooling operation for 2D spatial data with 16 by 16 pool_size\n",
        "# add dropout after pooling\n",
        "pl1 = Dropout(0.5)(pl1) # 50% dropout rate\n",
        "flattened = Flatten()(pl1) # flatten input to 1D array\n",
        "\n",
        "\n",
        "# fusion:\n",
        "fused = tf.concat([context_vector, flattened], axis=-1) # concatenate tensors along one dimension\n",
        "\n",
        "# multi-objectives (each is a multi-class classification), added kernel_regularizer = 'l1l2' for both\n",
        "p_price = Dense(len_price, activation='softmax', name='price', kernel_regularizer = 'l1_l2')(fused) # dense layer with units equal to number of unique items in price category, softmax activation function\n",
        "p_type = Dense(len_type, activation='softmax', name='type', kernel_regularizer = 'l1_l2')(fused) # dense layer with units equal to number of unique items in type category, softmax activation\n",
        "\n",
        "# create model by specifying inputs and outputs\n",
        "model = keras.Model(\n",
        "    inputs={\n",
        "        'summary': in_text, # input text is listing summary\n",
        "        'image': in_image # input image\n",
        "    },\n",
        "    outputs={\n",
        "        'price': p_price, # output predicted price\n",
        "        'type': p_type, # output predicted type\n",
        "    },\n",
        ")\n",
        "\n",
        "# configure model\n",
        "model.compile(\n",
        "    optimizer=Adam(), # use 'Adam' optimizer\n",
        "    loss={\n",
        "        'price': 'sparse_categorical_crossentropy', # loss for 'price' output\n",
        "        'type': 'sparse_categorical_crossentropy', # loss for 'type' output\n",
        "    },\n",
        "    loss_weights={\n",
        "        'price': 0.5, # weight for 'price' loss\n",
        "        'type': 0.5, # weight for 'type' loss\n",
        "    },\n",
        "    metrics={\n",
        "        'price': ['SparseCategoricalAccuracy'], # metric for 'price'\n",
        "        'type': ['SparseCategoricalAccuracy'], # metric for 'type'\n",
        "    },\n",
        ")\n",
        "\n",
        "# summary for model\n",
        "model.summary()\n",
        "\n",
        "#===============================================================================\n",
        "\n",
        "# fit model on data while monitoring performance on a validation split of 0.2\n",
        "history = model.fit(\n",
        "    x={\n",
        "        'summary': x_tr_text_id, # text training data\n",
        "        'image': x_tr_image # image training data\n",
        "    },\n",
        "    y={\n",
        "        'price': y_tr_price, # text training target data\n",
        "        'type': y_tr_type, # type training target data\n",
        "    },\n",
        "    epochs=20, # 20 cycles through training data\n",
        "    batch_size=16, # number of samples processed before model is updated\n",
        "    validation_data=(\n",
        "        {\n",
        "            'summary': x_vl_text_id, # text validation data\n",
        "            'image': x_vl_image # image validation data\n",
        "         },\n",
        "        {\n",
        "            'price': y_vl_price, # price validation target data\n",
        "            'type': y_vl_type, # type validation target data\n",
        "        }),\n",
        "    validation_split=0.2, # split training and validation 80/20\n",
        "    callbacks=[ # stop training when monitored metric has stopped improving after specified number of epochs\n",
        "        tf.keras.callbacks.EarlyStopping(monitor='val_price_loss', patience=5, ) # monitor loss for validation price with patience of 5 epochs\n",
        "    ],\n",
        "    verbose=1 # progress bar\n",
        ")\n",
        "\n",
        "#===============================================================================\n",
        "\n",
        "# preprocess test data for text and image\n",
        "x_test_summary = _preprocess(x_test_df.summary.astype(str)) # preprocess test summary data\n",
        "x_test_image = np.array([load_image(i) for i in tqdm(x_test_df.image)]) # load test images as arrays with progress bar\n",
        "\n",
        "# scale images for test data to range of 0 to 1\n",
        "x_test_image = x_test_image/64.0\n",
        "\n",
        "#===============================================================================\n",
        "\n",
        "\n",
        "# evaluate model on test data\n",
        "y_predict = model.predict( # use model to predict\n",
        "    {\n",
        "        'summary': x_test_summary, # text test data\n",
        "        'image': x_test_image # image test data\n",
        "    }\n",
        ")\n",
        "\n",
        "price_predicted = y_predict['price'] # target prediction\n",
        "# print(price_predicted) # print predictions\n",
        "price_category_predicted = np.argmax(price_predicted, axis=1) # return indices of maximum values along an axis\n",
        "# print(price_category_predicted) # print predicted categories for targets\n",
        "\n",
        "# create submission\n",
        "pd.DataFrame(\n",
        "    {'id': x_test_df.id,\n",
        "     'price': price_category_predicted}).to_csv('sample_submission10.csv', index=False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b2a249f69d494efbb9149aaa61d7a991",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "  0%|          | 0/7627 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_3 (InputLayer)           [(None, 64, 64, 2)]  0           []                               \n",
            "                                                                                                  \n",
            " conv2d (Conv2D)                (None, 61, 61, 32)   1056        ['input_3[0][0]']                \n",
            "                                                                                                  \n",
            " conv2d_1 (Conv2D)              (None, 58, 58, 32)   16416       ['conv2d[1][0]']                 \n",
            "                                                                                                  \n",
            " input_1 (InputLayer)           [(None, 100)]        0           []                               \n",
            "                                                                                                  \n",
            " max_pooling2d (MaxPooling2D)   (None, 14, 14, 32)   0           ['conv2d_1[1][0]']               \n",
            "                                                                                                  \n",
            " embedding (Embedding)          (None, 100, 100)     4000000     ['input_1[0][0]']                \n",
            "                                                                                                  \n",
            " dropout (Dropout)              (None, 14, 14, 32)   0           ['max_pooling2d[1][0]']          \n",
            "                                                                                                  \n",
            " bi_gru_0 (Bidirectional)       (None, 100, 200)     121200      ['embedding[1][0]']              \n",
            "                                                                                                  \n",
            " conv2d_2 (Conv2D)              (None, 13, 13, 16)   2064        ['dropout[1][0]']                \n",
            "                                                                                                  \n",
            " bi_gru_1 (Bidirectional)       [(None, 100, 200),   181200      ['bi_gru_0[1][0]']               \n",
            "                                 (None, 100),                                                     \n",
            "                                 (None, 100)]                                                     \n",
            "                                                                                                  \n",
            " max_pooling2d_1 (MaxPooling2D)  (None, 6, 6, 16)    0           ['conv2d_2[1][0]']               \n",
            "                                                                                                  \n",
            " concatenate (Concatenate)      (None, 200)          0           ['bi_gru_1[1][1]',               \n",
            "                                                                  'bi_gru_1[1][2]']               \n",
            "                                                                                                  \n",
            " dropout_1 (Dropout)            (None, 6, 6, 16)     0           ['max_pooling2d_1[1][0]']        \n",
            "                                                                                                  \n",
            " attention (Attention)          ((None, 200),        40301       ['bi_gru_1[1][0]',               \n",
            "                                 (None, 100, 1))                  'concatenate[1][0]']            \n",
            "                                                                                                  \n",
            " flatten (Flatten)              (None, 576)          0           ['dropout_1[1][0]']              \n",
            "                                                                                                  \n",
            " tf.concat (TFOpLambda)         (None, 776)          0           ['attention[1][0]',              \n",
            "                                                                  'flatten[1][0]']                \n",
            "                                                                                                  \n",
            " price (Dense)                  (None, 3)            2331        ['tf.concat[1][0]']              \n",
            "                                                                                                  \n",
            " type (Dense)                   (None, 24)           18648       ['tf.concat[1][0]']              \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 4,383,216\n",
            "Trainable params: 4,383,216\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "Epoch 1/20\n",
            "305/305 [==============================] - 55s 154ms/step - loss: 3.0295 - price_loss: 0.9260 - type_loss: 1.2046 - price_sparse_categorical_accuracy: 0.5787 - type_sparse_categorical_accuracy: 0.7395 - val_loss: 1.3672 - val_price_loss: 0.8245 - val_type_loss: 1.2734 - val_price_sparse_categorical_accuracy: 0.6446 - val_type_sparse_categorical_accuracy: 0.7649\n",
            "Epoch 2/20\n",
            "305/305 [==============================] - 45s 148ms/step - loss: 1.1923 - price_loss: 0.8622 - type_loss: 1.0592 - price_sparse_categorical_accuracy: 0.5912 - type_sparse_categorical_accuracy: 0.7525 - val_loss: 1.1852 - val_price_loss: 0.8740 - val_type_loss: 1.1179 - val_price_sparse_categorical_accuracy: 0.6364 - val_type_sparse_categorical_accuracy: 0.7641\n",
            "Epoch 3/20\n",
            "305/305 [==============================] - 45s 147ms/step - loss: 1.1017 - price_loss: 0.8598 - type_loss: 0.9565 - price_sparse_categorical_accuracy: 0.5986 - type_sparse_categorical_accuracy: 0.7494 - val_loss: 1.1685 - val_price_loss: 0.8247 - val_type_loss: 1.1353 - val_price_sparse_categorical_accuracy: 0.6478 - val_type_sparse_categorical_accuracy: 0.7273\n",
            "Epoch 4/20\n",
            "305/305 [==============================] - 45s 148ms/step - loss: 1.0636 - price_loss: 0.8513 - type_loss: 0.8971 - price_sparse_categorical_accuracy: 0.5912 - type_sparse_categorical_accuracy: 0.7570 - val_loss: 1.0774 - val_price_loss: 0.8075 - val_type_loss: 0.9615 - val_price_sparse_categorical_accuracy: 0.6347 - val_type_sparse_categorical_accuracy: 0.7412\n",
            "Epoch 5/20\n",
            "305/305 [==============================] - 45s 147ms/step - loss: 1.0328 - price_loss: 0.8548 - type_loss: 0.8397 - price_sparse_categorical_accuracy: 0.5908 - type_sparse_categorical_accuracy: 0.7682 - val_loss: 1.1054 - val_price_loss: 0.8431 - val_type_loss: 1.0071 - val_price_sparse_categorical_accuracy: 0.6536 - val_type_sparse_categorical_accuracy: 0.7256\n",
            "Epoch 6/20\n",
            "305/305 [==============================] - 45s 147ms/step - loss: 1.0188 - price_loss: 0.8512 - type_loss: 0.8211 - price_sparse_categorical_accuracy: 0.5986 - type_sparse_categorical_accuracy: 0.7699 - val_loss: 1.1046 - val_price_loss: 0.8201 - val_type_loss: 1.0056 - val_price_sparse_categorical_accuracy: 0.6298 - val_type_sparse_categorical_accuracy: 0.7633\n",
            "Epoch 7/20\n",
            "305/305 [==============================] - 45s 147ms/step - loss: 1.0057 - price_loss: 0.8627 - type_loss: 0.7789 - price_sparse_categorical_accuracy: 0.5918 - type_sparse_categorical_accuracy: 0.7797 - val_loss: 1.1188 - val_price_loss: 0.8089 - val_type_loss: 1.0351 - val_price_sparse_categorical_accuracy: 0.6527 - val_type_sparse_categorical_accuracy: 0.7240\n",
            "Epoch 8/20\n",
            "305/305 [==============================] - 44s 145ms/step - loss: 0.9787 - price_loss: 0.8494 - type_loss: 0.7476 - price_sparse_categorical_accuracy: 0.6027 - type_sparse_categorical_accuracy: 0.7908 - val_loss: 1.1698 - val_price_loss: 0.9744 - val_type_loss: 1.0129 - val_price_sparse_categorical_accuracy: 0.3227 - val_type_sparse_categorical_accuracy: 0.7453\n",
            "Epoch 9/20\n",
            "305/305 [==============================] - 45s 147ms/step - loss: 0.9727 - price_loss: 0.8523 - type_loss: 0.7369 - price_sparse_categorical_accuracy: 0.6033 - type_sparse_categorical_accuracy: 0.7879 - val_loss: 1.1054 - val_price_loss: 0.8617 - val_type_loss: 1.0058 - val_price_sparse_categorical_accuracy: 0.5463 - val_type_sparse_categorical_accuracy: 0.7346\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "60bde454b1984215bea5e51558115079",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "  0%|          | 0/7360 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "irv9XAY1qMsb"
      },
      "source": [
        "### **Trial11**\n",
        "Epoch 4/20<br> - 45s 148ms/step<br> - loss: 1.0636<br> - price_loss: 0.8513<br> - type_loss: 0.8971<br> - price_sparse_categorical_accuracy: 0.5912<br> - type_sparse_categorical_accuracy: 0.7570<br> - val_loss: 1.0774<br> - val_price_loss: 0.8075<br> - val_type_loss: 0.9615<br> - val_price_sparse_categorical_accuracy: 0.6347<br> - val_type_sparse_categorical_accuracy: 0.7412\n",
        "Epoch 5/20\n",
        "\n",
        "Score has not improved, underfitting is less\n",
        "\n",
        "Adjust conv and pooling layer parameters. Increase resolution to 128 for resizing. Increase image rotation from 0.1 to 0.2."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "988292bf479c4575aff2f27c4db37201",
            "4aa41749dd3141ff88c43d79914fd7c4",
            "283f043765d34cbcafe926c06e7c2d13",
            "4c820ec431f749a4ab3c39136c640803",
            "264ee4dc926642ca8362906f269a55ac",
            "21bc189f2cb342aa83dd822e87bd9f40",
            "eade1d47febc454bbdcb12d6c86481e1",
            "c95f5667c2b946739eb7ad73c49f01ac",
            "0e96b5325daa48cca469c88cd306d488",
            "a97bae54ddeb4f64baa87db48f1cca1b",
            "ad97b403cb894443ac7788159f7a6458",
            "b6bef90831d94fd9ab94f358ce509454",
            "7355bb71e91944b7a7cac0f4c2ec666c",
            "b4667ab88af24a039c6c899b1f181cb6",
            "39a8b635ac3c423ab5eb147f1f552dd5",
            "8c32c48b94c64b8f9280b5bf6e1177be",
            "fbe205f9156d46d88798bf4406179282",
            "fce7621ec1234c6eaeaecb9a53286214",
            "0875849edadc40a6974b6246ddf54ab4",
            "58a5075fe5f34aa0aad91cd48440fe07",
            "629e00b6fb2848fdae5155cdee67a4a9",
            "ee6d31fedf20412b82da6af163f67060"
          ]
        },
        "id": "urnY305OqNmJ",
        "outputId": "60f426f7-af0e-46e0-9617-729647e6b7ed"
      },
      "source": [
        "# Trial code cell\n",
        "\n",
        "# load modules\n",
        "import os\n",
        "\n",
        "import pandas as pd\n",
        "from tqdm.notebook import tqdm\n",
        "from PIL import Image\n",
        "import pandas as pd\n",
        "import os\n",
        "import numpy as np\n",
        "\n",
        "xy_train_df = pd.read_csv('train_xy.csv') # read training data into dataframe\n",
        "x_test_df = pd.read_csv('test_x.csv') # read test data into dataframe\n",
        "\n",
        "#===============================================================================\n",
        "\n",
        "# preprocess image data\n",
        "\n",
        "def load_image(file): # create function for loading images\n",
        "    try: # try this code\n",
        "        image = Image.open( # open and identify image file\n",
        "            file\n",
        "        ).convert('LA').resize((128, 128)) # convert to greyscale with alpha channel, resize to 128 by 128 pixels\n",
        "        arr = np.array(image) # return 3D array of image\n",
        "    except: # execute this code when an exception arises\n",
        "        arr = np.zeros((128, 128, 2)) # create 3D array of zeros with shape as (x,y,z)\n",
        "    return arr # return array\n",
        "\n",
        "\n",
        "# loading images:\n",
        "x_image = np.array([load_image(i) for i in tqdm(xy_train_df.image)]) # load training images as arrays with progress bar\n",
        "\n",
        "# loading summary: (force convert some of the non-string cell to string)\n",
        "x_text = xy_train_df.summary.astype('str')\n",
        "\n",
        "\n",
        "#===============================================================================\n",
        "\n",
        "from sklearn.model_selection import train_test_split # import function from module\n",
        "\n",
        "# labels:\n",
        "y_price = xy_train_df.price # subset price column\n",
        "y_type = xy_train_df.type.astype('category').cat.codes # encode type category variables\n",
        "len_price = len(y_price.unique()) # number of unique items in price category\n",
        "len_type = len(y_type.unique()) # number of unique items in type category\n",
        "# print('unique values for price category', len_price, y_price.unique()) # print number of unique items and values for price category\n",
        "# print('unique values for type category', len_type, y_type.unique()) # print number of unique items and values for type category\n",
        "\n",
        "# splitting:\n",
        "\n",
        "x_tr_image, x_vl_image, x_tr_text, x_vl_text, y_tr_price, y_vl_price, y_tr_type, y_vl_type = train_test_split(\n",
        "    x_image, # split image arrays into random train and validation subsets\n",
        "    x_text, # split series into random train and validation subsets\n",
        "    y_price, # split series into random train and validation subsets\n",
        "    y_type, # split series into random train and validation subsets\n",
        "    test_size=0.2) # training 80% validation/test 20% of data\n",
        "\n",
        "# scale image values to range of 0 to 1\n",
        "x_tr_image = x_tr_image/128.0\n",
        "x_vl_image = x_vl_image/128.0\n",
        "\n",
        "# print(np.shape(x_tr_image)) # print independent image feature training set shape\n",
        "# print(np.shape(x_vl_image)) # print independent image feature validation set shape\n",
        "# print(np.shape(y_tr_price)) # print dependent price feature training set shape\n",
        "# print(np.shape(y_vl_price)) # print dependent price feature validation set shape\n",
        "# print(np.shape(y_tr_type)) # print dependent type feature training set shape\n",
        "# print(np.shape(y_vl_type)) # print dependent type feature validation set shape\n",
        "\n",
        "#===============================================================================\n",
        "\n",
        "# preprocess text data\n",
        "\n",
        "# import modules and functions\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from sklearn.model_selection import train_test_split\n",
        "from pprint import pprint\n",
        "\n",
        "vocab_size = 40000 # set vocab_size variable to 40000\n",
        "max_len = 100 # # set max_len variable to 100\n",
        "\n",
        "\n",
        "# build vocabulary from training set\n",
        "tokenizer = Tokenizer(num_words=vocab_size) # set max number of words to keep for text tokenization\n",
        "tokenizer.fit_on_texts(x_tr_text) # create vocabulary index based on word frequency\n",
        "\n",
        "# create preprocessing function for text list\n",
        "def _preprocess(list_of_text): # param: list_of_text\n",
        "    return pad_sequences( # return padded sequences with same length\n",
        "        tokenizer.texts_to_sequences(list_of_text), # transforms each text to sequence of integers\n",
        "        maxlen=max_len, # set maximum length of all sequences\n",
        "        padding='post', # set to pad end of sequences\n",
        "    )\n",
        "\n",
        "\n",
        "# padding is done inside:\n",
        "x_tr_text_id = _preprocess(x_tr_text)\n",
        "x_vl_text_id = _preprocess(x_vl_text)\n",
        "\n",
        "# # print shapes of padded arrays\n",
        "# print(x_tr_text_id.shape)\n",
        "# print(x_vl_text_id.shape)\n",
        "\n",
        "#===============================================================================\n",
        "\n",
        "# import modules and functions\n",
        "from __future__ import absolute_import, division, print_function, unicode_literals\n",
        "import collections\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.layers import Conv2D, Flatten, Dense, MaxPool2D, Dropout, Attention, Concatenate # import dropout and attention sets\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras import layers # required for data augmentation layers\n",
        "\n",
        "# create data augmentation stage\n",
        "data_augmentation = tf.keras.Sequential(\n",
        "    [\n",
        "     layers.RandomFlip('horizontal_and_vertical'), # random 'horizontal_and_vertical' flipping\n",
        "     layers.RandomRotation(0.2) # rotation by random amount in range as fraction of 2 Pi\n",
        "    ]\n",
        ")\n",
        "\n",
        "# set input text and image shapes\n",
        "in_text = keras.Input(batch_shape=(None, max_len)) # set max length for input text\n",
        "in_image = keras.Input(batch_shape=(None, 128, 128, 2)) # set shape for input image\n",
        "in_image = data_augmentation(in_image) # augmentation of input image\n",
        "\n",
        "# text part\n",
        "embedded = keras.layers.Embedding(tokenizer.num_words, 100)(in_text) # turn positive integers (indexes) into dense vectors of fixed size\n",
        "# averaged = tf.reduce_mean(embedded, axis=1) # reduce input_tensor along dimensions given in axis using mean of elements across dimensions in axis\n",
        "\n",
        "# create attention layer consisting of three dense layers (additive attention)\n",
        "class Attention(tf.keras.Model):\n",
        "    def __init__(self, units):\n",
        "        super(Attention, self).__init__()\n",
        "        self.W1 = tf.keras.layers.Dense(units) #weight 1\n",
        "        self.W2 = tf.keras.layers.Dense(units) #weight 2\n",
        "        self.V = tf.keras.layers.Dense(1) #output vector\n",
        "\n",
        "    def call(self, features, hidden):\n",
        "        # hidden shape == (batch_size, hidden size)\n",
        "        # hidden_with_time_axis shape == (batch_size, 1, hidden size)\n",
        "        # we are doing this to perform addition to calculate the score\n",
        "        hidden_with_time_axis = tf.expand_dims(hidden, 1) # expand dimension index 1\n",
        "\n",
        "        # score shape == (batch_size, max_length, 1)\n",
        "        # we get 1 at the last axis because we are applying score to self.V\n",
        "        # the shape of the tensor before applying self.V is (batch_size, max_length, units)\n",
        "        score = tf.nn.tanh( # compute hyperbolic tangent of W1+W2 element-wise\n",
        "            self.W1(features) + self.W2(hidden_with_time_axis))\n",
        "\n",
        "        # attention_weights shape == (batch_size, max_length, 1)\n",
        "        attention_weights = tf.nn.softmax(self.V(score), axis=1) # compute softmax activation for attention weights\n",
        "\n",
        "        # context_vector shape after sum == (batch_size, hidden_size)\n",
        "        context_vector = attention_weights * features\n",
        "        context_vector = tf.reduce_sum(context_vector, axis=1) # compute sum of elements across dimensions of tensor\n",
        "\n",
        "        return context_vector, attention_weights\n",
        "\n",
        "\n",
        "\n",
        "# Bi-directional RNN\n",
        "gru = tf.keras.layers.Bidirectional(tf.keras.layers.GRU(100,return_sequences=True),name=\"bi_gru_0\")(embedded) # bidirectional gru with units=100\n",
        "# get GRU outputs\n",
        "(gru, hidden0, hidden1) = tf.keras.layers.Bidirectional(tf.keras.layers.GRU(100, return_sequences=True, return_state=True), name=\"bi_gru_1\")(gru)\n",
        "\n",
        "# concatenate hidden states from each RNN since model is using bidirectional RNN\n",
        "hidden = Concatenate()([hidden0, hidden1])\n",
        "# compute attention weights and apply weighted sum\n",
        "context_vector, attention_weights = Attention(100)(gru, hidden) #\n",
        "\n",
        "\n",
        "# image part\n",
        "cov = Conv2D(64, (8, 8))(in_image) # 2D convolution layer with 64 filters and 8 by 8 kernel_size\n",
        "cov1 = Conv2D(64, (8, 8))(cov) # 2D convolution layer with 64 filters and 8 by 8 kernel_size\n",
        "pl = MaxPool2D((8, 8))(cov1) # max pooling operation for 2D spatial data with 8 by 8 pool_size\n",
        "# add dropout after pooling\n",
        "pl = Dropout(0.5)(pl) # 50% dropout rate\n",
        "cov3 = Conv2D(16, (4, 4))(pl) # 2D convolution layer with 32 filters and 4 by 4 kernel_size\n",
        "pl1 = MaxPool2D((2, 2))(cov3) # max pooling operation for 2D spatial data with 2 by 2 pool_size\n",
        "# add dropout after pooling\n",
        "pl1 = Dropout(0.5)(pl1) # 50% dropout rate\n",
        "flattened = Flatten()(pl1) # flatten input to 1D array\n",
        "\n",
        "\n",
        "# fusion:\n",
        "fused = tf.concat([context_vector, flattened], axis=-1) # concatenate tensors along one dimension\n",
        "\n",
        "# multi-objectives (each is a multi-class classification), added kernel_regularizer = 'l1l2' for both\n",
        "p_price = Dense(len_price, activation='softmax', name='price', kernel_regularizer = 'l1_l2')(fused) # dense layer with units equal to number of unique items in price category, softmax activation function\n",
        "p_type = Dense(len_type, activation='softmax', name='type', kernel_regularizer = 'l1_l2')(fused) # dense layer with units equal to number of unique items in type category, softmax activation\n",
        "\n",
        "# create model by specifying inputs and outputs\n",
        "model = keras.Model(\n",
        "    inputs={\n",
        "        'summary': in_text, # input text is listing summary\n",
        "        'image': in_image # input image\n",
        "    },\n",
        "    outputs={\n",
        "        'price': p_price, # output predicted price\n",
        "        'type': p_type, # output predicted type\n",
        "    },\n",
        ")\n",
        "\n",
        "# configure model\n",
        "model.compile(\n",
        "    optimizer=Adam(), # use 'Adam' optimizer\n",
        "    loss={\n",
        "        'price': 'sparse_categorical_crossentropy', # loss for 'price' output\n",
        "        'type': 'sparse_categorical_crossentropy', # loss for 'type' output\n",
        "    },\n",
        "    loss_weights={\n",
        "        'price': 0.5, # weight for 'price' loss\n",
        "        'type': 0.5, # weight for 'type' loss\n",
        "    },\n",
        "    metrics={\n",
        "        'price': ['SparseCategoricalAccuracy'], # metric for 'price'\n",
        "        'type': ['SparseCategoricalAccuracy'], # metric for 'type'\n",
        "    },\n",
        ")\n",
        "\n",
        "# summary for model\n",
        "model.summary()\n",
        "\n",
        "#===============================================================================\n",
        "\n",
        "# fit model on data while monitoring performance on a validation split of 0.2\n",
        "history = model.fit(\n",
        "    x={\n",
        "        'summary': x_tr_text_id, # text training data\n",
        "        'image': x_tr_image # image training data\n",
        "    },\n",
        "    y={\n",
        "        'price': y_tr_price, # text training target data\n",
        "        'type': y_tr_type, # type training target data\n",
        "    },\n",
        "    epochs=20, # 20 cycles through training data\n",
        "    batch_size=16, # number of samples processed before model is updated\n",
        "    validation_data=(\n",
        "        {\n",
        "            'summary': x_vl_text_id, # text validation data\n",
        "            'image': x_vl_image # image validation data\n",
        "         },\n",
        "        {\n",
        "            'price': y_vl_price, # price validation target data\n",
        "            'type': y_vl_type, # type validation target data\n",
        "        }),\n",
        "    validation_split=0.2, # split training and validation 80/20\n",
        "    callbacks=[ # stop training when monitored metric has stopped improving after specified number of epochs\n",
        "        tf.keras.callbacks.EarlyStopping(monitor='val_price_loss', patience=5, ) # monitor loss for validation price with patience of 5 epochs\n",
        "    ],\n",
        "    verbose=1 # progress bar\n",
        ")\n",
        "\n",
        "#===============================================================================\n",
        "\n",
        "# preprocess test data for text and image\n",
        "x_test_summary = _preprocess(x_test_df.summary.astype(str)) # preprocess test summary data\n",
        "x_test_image = np.array([load_image(i) for i in tqdm(x_test_df.image)]) # load test images as arrays with progress bar\n",
        "\n",
        "# scale images for test data to range of 0 to 1\n",
        "x_test_image = x_test_image/64.0\n",
        "\n",
        "#===============================================================================\n",
        "\n",
        "\n",
        "# evaluate model on test data\n",
        "y_predict = model.predict( # use model to predict\n",
        "    {\n",
        "        'summary': x_test_summary, # text test data\n",
        "        'image': x_test_image # image test data\n",
        "    }\n",
        ")\n",
        "\n",
        "price_predicted = y_predict['price'] # target prediction\n",
        "# print(price_predicted) # print predictions\n",
        "price_category_predicted = np.argmax(price_predicted, axis=1) # return indices of maximum values along an axis\n",
        "# print(price_category_predicted) # print predicted categories for targets\n",
        "\n",
        "# create submission\n",
        "pd.DataFrame(\n",
        "    {'id': x_test_df.id,\n",
        "     'price': price_category_predicted}).to_csv('sample_submission10.csv', index=False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "988292bf479c4575aff2f27c4db37201",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "  0%|          | 0/7627 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_3 (InputLayer)           [(None, 128, 128, 2  0           []                               \n",
            "                                )]                                                                \n",
            "                                                                                                  \n",
            " conv2d (Conv2D)                (None, 121, 121, 64  8256        ['input_3[0][0]']                \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_1 (Conv2D)              (None, 114, 114, 64  262208      ['conv2d[1][0]']                 \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " input_1 (InputLayer)           [(None, 100)]        0           []                               \n",
            "                                                                                                  \n",
            " max_pooling2d (MaxPooling2D)   (None, 14, 14, 64)   0           ['conv2d_1[1][0]']               \n",
            "                                                                                                  \n",
            " embedding (Embedding)          (None, 100, 100)     4000000     ['input_1[0][0]']                \n",
            "                                                                                                  \n",
            " dropout (Dropout)              (None, 14, 14, 64)   0           ['max_pooling2d[1][0]']          \n",
            "                                                                                                  \n",
            " bi_gru_0 (Bidirectional)       (None, 100, 200)     121200      ['embedding[1][0]']              \n",
            "                                                                                                  \n",
            " conv2d_2 (Conv2D)              (None, 11, 11, 16)   16400       ['dropout[1][0]']                \n",
            "                                                                                                  \n",
            " bi_gru_1 (Bidirectional)       [(None, 100, 200),   181200      ['bi_gru_0[1][0]']               \n",
            "                                 (None, 100),                                                     \n",
            "                                 (None, 100)]                                                     \n",
            "                                                                                                  \n",
            " max_pooling2d_1 (MaxPooling2D)  (None, 5, 5, 16)    0           ['conv2d_2[1][0]']               \n",
            "                                                                                                  \n",
            " concatenate (Concatenate)      (None, 200)          0           ['bi_gru_1[1][1]',               \n",
            "                                                                  'bi_gru_1[1][2]']               \n",
            "                                                                                                  \n",
            " dropout_1 (Dropout)            (None, 5, 5, 16)     0           ['max_pooling2d_1[1][0]']        \n",
            "                                                                                                  \n",
            " attention (Attention)          ((None, 200),        40301       ['bi_gru_1[1][0]',               \n",
            "                                 (None, 100, 1))                  'concatenate[1][0]']            \n",
            "                                                                                                  \n",
            " flatten (Flatten)              (None, 400)          0           ['dropout_1[1][0]']              \n",
            "                                                                                                  \n",
            " tf.concat (TFOpLambda)         (None, 600)          0           ['attention[1][0]',              \n",
            "                                                                  'flatten[1][0]']                \n",
            "                                                                                                  \n",
            " price (Dense)                  (None, 3)            1803        ['tf.concat[1][0]']              \n",
            "                                                                                                  \n",
            " type (Dense)                   (None, 24)           14424       ['tf.concat[1][0]']              \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 4,645,792\n",
            "Trainable params: 4,645,792\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "Epoch 1/20\n",
            "305/305 [==============================] - 68s 183ms/step - loss: 3.2772 - price_loss: 1.0190 - type_loss: 1.3027 - price_sparse_categorical_accuracy: 0.5480 - type_sparse_categorical_accuracy: 0.7225 - val_loss: 1.4458 - val_price_loss: 0.8582 - val_type_loss: 1.0694 - val_price_sparse_categorical_accuracy: 0.6257 - val_type_sparse_categorical_accuracy: 0.7764\n",
            "Epoch 2/20\n",
            "305/305 [==============================] - 53s 175ms/step - loss: 1.3051 - price_loss: 0.8789 - type_loss: 1.1200 - price_sparse_categorical_accuracy: 0.5873 - type_sparse_categorical_accuracy: 0.7500 - val_loss: 1.2828 - val_price_loss: 0.8856 - val_type_loss: 1.2573 - val_price_sparse_categorical_accuracy: 0.6274 - val_type_sparse_categorical_accuracy: 0.7633\n",
            "Epoch 3/20\n",
            "305/305 [==============================] - 54s 176ms/step - loss: 1.1413 - price_loss: 0.8504 - type_loss: 1.0431 - price_sparse_categorical_accuracy: 0.6051 - type_sparse_categorical_accuracy: 0.7504 - val_loss: 1.0790 - val_price_loss: 0.8358 - val_type_loss: 0.9548 - val_price_sparse_categorical_accuracy: 0.6331 - val_type_sparse_categorical_accuracy: 0.7764\n",
            "Epoch 4/20\n",
            "305/305 [==============================] - 53s 175ms/step - loss: 1.0756 - price_loss: 0.8264 - type_loss: 0.9652 - price_sparse_categorical_accuracy: 0.6244 - type_sparse_categorical_accuracy: 0.7508 - val_loss: 1.0820 - val_price_loss: 0.8211 - val_type_loss: 0.9603 - val_price_sparse_categorical_accuracy: 0.6290 - val_type_sparse_categorical_accuracy: 0.7756\n",
            "Epoch 5/20\n",
            "305/305 [==============================] - 53s 175ms/step - loss: 1.0468 - price_loss: 0.8240 - type_loss: 0.8938 - price_sparse_categorical_accuracy: 0.6217 - type_sparse_categorical_accuracy: 0.7615 - val_loss: 1.0471 - val_price_loss: 0.8112 - val_type_loss: 0.9075 - val_price_sparse_categorical_accuracy: 0.6314 - val_type_sparse_categorical_accuracy: 0.7699\n",
            "Epoch 6/20\n",
            "305/305 [==============================] - 53s 175ms/step - loss: 1.0135 - price_loss: 0.8130 - type_loss: 0.8420 - price_sparse_categorical_accuracy: 0.6197 - type_sparse_categorical_accuracy: 0.7740 - val_loss: 1.1511 - val_price_loss: 0.8396 - val_type_loss: 1.0515 - val_price_sparse_categorical_accuracy: 0.6265 - val_type_sparse_categorical_accuracy: 0.7289\n",
            "Epoch 7/20\n",
            "305/305 [==============================] - 53s 175ms/step - loss: 1.0986 - price_loss: 0.8642 - type_loss: 0.8404 - price_sparse_categorical_accuracy: 0.6145 - type_sparse_categorical_accuracy: 0.7764 - val_loss: 1.2700 - val_price_loss: 0.8717 - val_type_loss: 1.1327 - val_price_sparse_categorical_accuracy: 0.6126 - val_type_sparse_categorical_accuracy: 0.7559\n",
            "Epoch 8/20\n",
            "305/305 [==============================] - 53s 175ms/step - loss: 1.0284 - price_loss: 0.7935 - type_loss: 0.7849 - price_sparse_categorical_accuracy: 0.6412 - type_sparse_categorical_accuracy: 0.7830 - val_loss: 1.2896 - val_price_loss: 0.9803 - val_type_loss: 1.1503 - val_price_sparse_categorical_accuracy: 0.5070 - val_type_sparse_categorical_accuracy: 0.7109\n",
            "Epoch 9/20\n",
            "305/305 [==============================] - 54s 176ms/step - loss: 0.9968 - price_loss: 0.7709 - type_loss: 0.7643 - price_sparse_categorical_accuracy: 0.6564 - type_sparse_categorical_accuracy: 0.7932 - val_loss: 1.1806 - val_price_loss: 0.8587 - val_type_loss: 1.0607 - val_price_sparse_categorical_accuracy: 0.6257 - val_type_sparse_categorical_accuracy: 0.7715\n",
            "Epoch 10/20\n",
            "305/305 [==============================] - 53s 175ms/step - loss: 0.9935 - price_loss: 0.7548 - type_loss: 0.7654 - price_sparse_categorical_accuracy: 0.6707 - type_sparse_categorical_accuracy: 0.7920 - val_loss: 1.5893 - val_price_loss: 1.1866 - val_type_loss: 1.2145 - val_price_sparse_categorical_accuracy: 0.4644 - val_type_sparse_categorical_accuracy: 0.7297\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b6bef90831d94fd9ab94f358ce509454",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "  0%|          | 0/7360 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AvnwnZSZ4bp9"
      },
      "source": [
        "### **Trial12**\n",
        "\n",
        "Trial11 results:\n",
        "\n",
        "Epoch 5/20<br> - 53s 175ms/step<br> - loss: 1.0468<br> - price_loss: 0.8240<br> - type_loss: 0.8938<br> - price_sparse_categorical_accuracy: 0.6217<br> - type_sparse_categorical_accuracy: 0.7615<br> - val_loss: 1.0471<br> - val_price_loss: 0.8112<br> - val_type_loss: 0.9075<br> - val_price_sparse_categorical_accuracy: 0.6314<br> - val_type_sparse_categorical_accuracy: 0.7699\n",
        "\n",
        "Tinkering with all those parameters and making those adjustments decreased my model performance based on my submission score (0.29732 - yikes!). Continuing with code from Trial10, I will try increasing batch size to 32 and decreasing epochs to 10."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "04f05b0c955444e2a9baeadcea4aa399",
            "4c6513b6af48429c96d81efee9e71f7f",
            "36802cbffd4b49ad9e443614f7337699",
            "51857f3ffd32418e840d586c8a2ee1cc",
            "27d18efda46c4a8fa769cbe91ca1cb1c",
            "02b0cabb205c463b92847b8f9b2a1955",
            "6d2f2642a0d84d8e81357866c7d98a24",
            "77a9f617469e4f0b89df655cf481fd8b",
            "432b4c976ca54b8cbd3b701cab57aef1",
            "0a2575df909c4f6fa0d5eed8d50988d7",
            "cc804bfdc4084f2283109a492497a947",
            "44361c1f263f4514856db1be5183a05b",
            "a1afc3e12f234207afbd5b9ddd02dbaf",
            "35ea90cc45144251b48ed4938e52a782",
            "79778a7580b84f6fbda6a8980ec2e4e4",
            "4a25a545adc84ceda1ae76ef5728aa09",
            "9c8288856d96428489eaaa1007e42e7c",
            "d0700a37f2184c8b84594bfd452325a0",
            "ebd675c034994808b2fa2c71a6d8f41f",
            "1af0034a5f9b487fb324c1e01ea8c654",
            "6772fa1035a04e78beab73f8d2b7cf7c",
            "fb33c5f52e9d4b2094c1b07aeee89b96"
          ]
        },
        "id": "nSfr9MT540Jw",
        "outputId": "cc3d4a33-b859-4223-c485-05277b779eb0"
      },
      "source": [
        "# Trial code cell\n",
        "\n",
        "# load modules\n",
        "import os\n",
        "\n",
        "import pandas as pd\n",
        "from tqdm.notebook import tqdm\n",
        "from PIL import Image\n",
        "import pandas as pd\n",
        "import os\n",
        "import numpy as np\n",
        "\n",
        "xy_train_df = pd.read_csv('train_xy.csv') # read training data into dataframe\n",
        "x_test_df = pd.read_csv('test_x.csv') # read test data into dataframe\n",
        "\n",
        "#===============================================================================\n",
        "\n",
        "# preprocess image data\n",
        "\n",
        "def load_image(file): # create function for loading images\n",
        "    try: # try this code\n",
        "        image = Image.open( # open and identify image file\n",
        "            file\n",
        "        ).convert('LA').resize((64, 64)) # convert to greyscale with alpha channel, resize to 64 by 64 pixels\n",
        "        arr = np.array(image) # return 3D array of image\n",
        "    except: # execute this code when an exception arises\n",
        "        arr = np.zeros((64, 64, 2)) # create 3D array of zeros with shape as (x,y,z)\n",
        "    return arr # return array\n",
        "\n",
        "\n",
        "# loading images:\n",
        "x_image = np.array([load_image(i) for i in tqdm(xy_train_df.image)]) # load training images as arrays with progress bar\n",
        "\n",
        "# loading summary: (force convert some of the non-string cell to string)\n",
        "x_text = xy_train_df.summary.astype('str')\n",
        "\n",
        "\n",
        "#===============================================================================\n",
        "\n",
        "from sklearn.model_selection import train_test_split # import function from module\n",
        "\n",
        "# labels:\n",
        "y_price = xy_train_df.price # subset price column\n",
        "y_type = xy_train_df.type.astype('category').cat.codes # encode type category variables\n",
        "len_price = len(y_price.unique()) # number of unique items in price category\n",
        "len_type = len(y_type.unique()) # number of unique items in type category\n",
        "# print('unique values for price category', len_price, y_price.unique()) # print number of unique items and values for price category\n",
        "# print('unique values for type category', len_type, y_type.unique()) # print number of unique items and values for type category\n",
        "\n",
        "# splitting:\n",
        "\n",
        "x_tr_image, x_vl_image, x_tr_text, x_vl_text, y_tr_price, y_vl_price, y_tr_type, y_vl_type = train_test_split(\n",
        "    x_image, # split image arrays into random train and validation subsets\n",
        "    x_text, # split series into random train and validation subsets\n",
        "    y_price, # split series into random train and validation subsets\n",
        "    y_type, # split series into random train and validation subsets\n",
        "    test_size=0.2) # training 80% validation/test 20% of data\n",
        "\n",
        "# scale image values to range of 0 to 1\n",
        "x_tr_image = x_tr_image/64.0\n",
        "x_vl_image = x_vl_image/64.0\n",
        "\n",
        "# print(np.shape(x_tr_image)) # print independent image feature training set shape\n",
        "# print(np.shape(x_vl_image)) # print independent image feature validation set shape\n",
        "# print(np.shape(y_tr_price)) # print dependent price feature training set shape\n",
        "# print(np.shape(y_vl_price)) # print dependent price feature validation set shape\n",
        "# print(np.shape(y_tr_type)) # print dependent type feature training set shape\n",
        "# print(np.shape(y_vl_type)) # print dependent type feature validation set shape\n",
        "\n",
        "#===============================================================================\n",
        "\n",
        "# preprocess text data\n",
        "\n",
        "# import modules and functions\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from sklearn.model_selection import train_test_split\n",
        "from pprint import pprint\n",
        "\n",
        "vocab_size = 40000 # set vocab_size variable to 40000\n",
        "max_len = 100 # # set max_len variable to 100\n",
        "\n",
        "\n",
        "# build vocabulary from training set\n",
        "tokenizer = Tokenizer(num_words=vocab_size) # set max number of words to keep for text tokenization\n",
        "tokenizer.fit_on_texts(x_tr_text) # create vocabulary index based on word frequency\n",
        "\n",
        "# create preprocessing function for text list\n",
        "def _preprocess(list_of_text): # param: list_of_text\n",
        "    return pad_sequences( # return padded sequences with same length\n",
        "        tokenizer.texts_to_sequences(list_of_text), # transforms each text to sequence of integers\n",
        "        maxlen=max_len, # set maximum length of all sequences\n",
        "        padding='post', # set to pad end of sequences\n",
        "    )\n",
        "\n",
        "\n",
        "# padding is done inside:\n",
        "x_tr_text_id = _preprocess(x_tr_text)\n",
        "x_vl_text_id = _preprocess(x_vl_text)\n",
        "\n",
        "# # print shapes of padded arrays\n",
        "# print(x_tr_text_id.shape)\n",
        "# print(x_vl_text_id.shape)\n",
        "\n",
        "#===============================================================================\n",
        "\n",
        "# import modules and functions\n",
        "from __future__ import absolute_import, division, print_function, unicode_literals\n",
        "import collections\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.layers import Conv2D, Flatten, Dense, MaxPool2D, Dropout, Attention, Concatenate # import dropout and attention sets\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras import layers # required for data augmentation layers\n",
        "\n",
        "# create data augmentation stage\n",
        "data_augmentation = tf.keras.Sequential(\n",
        "    [\n",
        "     layers.RandomFlip('horizontal_and_vertical'), # random 'horizontal_and_vertical' flipping\n",
        "     layers.RandomRotation(0.1) # rotation by random amount in range as fraction of 2 Pi\n",
        "    ]\n",
        ")\n",
        "\n",
        "# set input text and image shapes\n",
        "in_text = keras.Input(batch_shape=(None, max_len)) # set max length for input text\n",
        "in_image = keras.Input(batch_shape=(None, 64, 64, 2)) # set shape for input image\n",
        "in_image = data_augmentation(in_image) # augmentation of input image\n",
        "\n",
        "# text part\n",
        "embedded = keras.layers.Embedding(tokenizer.num_words, 100)(in_text) # turn positive integers (indexes) into dense vectors of fixed size\n",
        "# averaged = tf.reduce_mean(embedded, axis=1) # reduce input_tensor along dimensions given in axis using mean of elements across dimensions in axis\n",
        "\n",
        "# create attention layer consisting of three dense layers (additive attention)\n",
        "class Attention(tf.keras.Model):\n",
        "    def __init__(self, units):\n",
        "        super(Attention, self).__init__()\n",
        "        self.W1 = tf.keras.layers.Dense(units) #weight 1\n",
        "        self.W2 = tf.keras.layers.Dense(units) #weight 2\n",
        "        self.V = tf.keras.layers.Dense(1) #output vector\n",
        "\n",
        "    def call(self, features, hidden):\n",
        "        # hidden shape == (batch_size, hidden size)\n",
        "        # hidden_with_time_axis shape == (batch_size, 1, hidden size)\n",
        "        # we are doing this to perform addition to calculate the score\n",
        "        hidden_with_time_axis = tf.expand_dims(hidden, 1) # expand dimension index 1\n",
        "\n",
        "        # score shape == (batch_size, max_length, 1)\n",
        "        # we get 1 at the last axis because we are applying score to self.V\n",
        "        # the shape of the tensor before applying self.V is (batch_size, max_length, units)\n",
        "        score = tf.nn.tanh( # compute hyperbolic tangent of W1+W2 element-wise\n",
        "            self.W1(features) + self.W2(hidden_with_time_axis))\n",
        "\n",
        "        # attention_weights shape == (batch_size, max_length, 1)\n",
        "        attention_weights = tf.nn.softmax(self.V(score), axis=1) # compute softmax activation for attention weights\n",
        "\n",
        "        # context_vector shape after sum == (batch_size, hidden_size)\n",
        "        context_vector = attention_weights * features\n",
        "        context_vector = tf.reduce_sum(context_vector, axis=1) # compute sum of elements across dimensions of tensor\n",
        "\n",
        "        return context_vector, attention_weights\n",
        "\n",
        "\n",
        "\n",
        "# Bi-directional RNN\n",
        "gru = tf.keras.layers.Bidirectional(tf.keras.layers.GRU(100,return_sequences=True),name=\"bi_gru_0\")(embedded) # bidirectional gru with units=100\n",
        "# get GRU outputs\n",
        "(gru, hidden0, hidden1) = tf.keras.layers.Bidirectional(tf.keras.layers.GRU(100, return_sequences=True, return_state=True), name=\"bi_gru_1\")(gru)\n",
        "\n",
        "# concatenate hidden states from each RNN since model is using bidirectional RNN\n",
        "hidden = Concatenate()([hidden0, hidden1])\n",
        "# compute attention weights and apply weighted sum\n",
        "context_vector, attention_weights = Attention(100)(gru, hidden) #\n",
        "\n",
        "\n",
        "# image part\n",
        "cov = Conv2D(32, (4, 4))(in_image) # 2D convolution layer with 64 filters and 16 by 16 kernel_size\n",
        "cov1 = Conv2D(32, (4, 4))(cov) # 2D convolution layer with 64 filters and 16 by 16 kernel_size\n",
        "pl = MaxPool2D((4, 4))(cov1) # max pooling operation for 2D spatial data with 16 by 16 pool_size\n",
        "# add dropout after pooling\n",
        "pl = Dropout(0.5)(pl) # 50% dropout rate\n",
        "cov3 = Conv2D(16, (2, 2))(pl) # 2D convolution layer with 32 filters and 16 by 16 kernel_size\n",
        "pl1 = MaxPool2D((2, 2))(cov3) # max pooling operation for 2D spatial data with 16 by 16 pool_size\n",
        "# add dropout after pooling\n",
        "pl1 = Dropout(0.5)(pl1) # 50% dropout rate\n",
        "flattened = Flatten()(pl1) # flatten input to 1D array\n",
        "\n",
        "\n",
        "# fusion:\n",
        "fused = tf.concat([context_vector, flattened], axis=-1) # concatenate tensors along one dimension\n",
        "\n",
        "# multi-objectives (each is a multi-class classification), added kernel_regularizer = 'l1l2' for both\n",
        "p_price = Dense(len_price, activation='softmax', name='price', kernel_regularizer = 'l1_l2')(fused) # dense layer with units equal to number of unique items in price category, softmax activation function\n",
        "p_type = Dense(len_type, activation='softmax', name='type', kernel_regularizer = 'l1_l2')(fused) # dense layer with units equal to number of unique items in type category, softmax activation\n",
        "\n",
        "# create model by specifying inputs and outputs\n",
        "model = keras.Model(\n",
        "    inputs={\n",
        "        'summary': in_text, # input text is listing summary\n",
        "        'image': in_image # input image\n",
        "    },\n",
        "    outputs={\n",
        "        'price': p_price, # output predicted price\n",
        "        'type': p_type, # output predicted type\n",
        "    },\n",
        ")\n",
        "\n",
        "# configure model\n",
        "model.compile(\n",
        "    optimizer=Adam(), # use 'Adam' optimizer\n",
        "    loss={\n",
        "        'price': 'sparse_categorical_crossentropy', # loss for 'price' output\n",
        "        'type': 'sparse_categorical_crossentropy', # loss for 'type' output\n",
        "    },\n",
        "    loss_weights={\n",
        "        'price': 0.5, # weight for 'price' loss\n",
        "        'type': 0.5, # weight for 'type' loss\n",
        "    },\n",
        "    metrics={\n",
        "        'price': ['SparseCategoricalAccuracy'], # metric for 'price'\n",
        "        'type': ['SparseCategoricalAccuracy'], # metric for 'type'\n",
        "    },\n",
        ")\n",
        "\n",
        "# summary for model\n",
        "model.summary()\n",
        "\n",
        "#===============================================================================\n",
        "\n",
        "# fit model on data while monitoring performance on a validation split of 0.2\n",
        "history = model.fit(\n",
        "    x={\n",
        "        'summary': x_tr_text_id, # text training data\n",
        "        'image': x_tr_image # image training data\n",
        "    },\n",
        "    y={\n",
        "        'price': y_tr_price, # text training target data\n",
        "        'type': y_tr_type, # type training target data\n",
        "    },\n",
        "    epochs=10, # 10 cycles through training data\n",
        "    batch_size=32, # number of samples processed before model is updated\n",
        "    validation_data=(\n",
        "        {\n",
        "            'summary': x_vl_text_id, # text validation data\n",
        "            'image': x_vl_image # image validation data\n",
        "         },\n",
        "        {\n",
        "            'price': y_vl_price, # price validation target data\n",
        "            'type': y_vl_type, # type validation target data\n",
        "        }),\n",
        "    validation_split=0.2, # split training and validation 80/20\n",
        "    callbacks=[ # stop training when monitored metric has stopped improving after specified number of epochs\n",
        "        tf.keras.callbacks.EarlyStopping(monitor='val_price_loss', patience=5, ) # monitor loss for validation price with patience of 5 epochs\n",
        "    ],\n",
        "    verbose=1 # progress bar\n",
        ")\n",
        "\n",
        "#===============================================================================\n",
        "\n",
        "# preprocess test data for text and image\n",
        "x_test_summary = _preprocess(x_test_df.summary.astype(str)) # preprocess test summary data\n",
        "x_test_image = np.array([load_image(i) for i in tqdm(x_test_df.image)]) # load test images as arrays with progress bar\n",
        "\n",
        "# scale images for test data to range of 0 to 1\n",
        "x_test_image = x_test_image/64.0\n",
        "\n",
        "#===============================================================================\n",
        "\n",
        "\n",
        "# evaluate model on test data\n",
        "y_predict = model.predict( # use model to predict\n",
        "    {\n",
        "        'summary': x_test_summary, # text test data\n",
        "        'image': x_test_image # image test data\n",
        "    }\n",
        ")\n",
        "\n",
        "price_predicted = y_predict['price'] # target prediction\n",
        "# print(price_predicted) # print predictions\n",
        "price_category_predicted = np.argmax(price_predicted, axis=1) # return indices of maximum values along an axis\n",
        "# print(price_category_predicted) # print predicted categories for targets\n",
        "\n",
        "# create submission\n",
        "pd.DataFrame(\n",
        "    {'id': x_test_df.id,\n",
        "     'price': price_category_predicted}).to_csv('sample_submission12.csv', index=False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "04f05b0c955444e2a9baeadcea4aa399",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "  0%|          | 0/7627 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_3 (InputLayer)           [(None, 64, 64, 2)]  0           []                               \n",
            "                                                                                                  \n",
            " conv2d (Conv2D)                (None, 61, 61, 32)   1056        ['input_3[0][0]']                \n",
            "                                                                                                  \n",
            " conv2d_1 (Conv2D)              (None, 58, 58, 32)   16416       ['conv2d[1][0]']                 \n",
            "                                                                                                  \n",
            " input_1 (InputLayer)           [(None, 100)]        0           []                               \n",
            "                                                                                                  \n",
            " max_pooling2d (MaxPooling2D)   (None, 14, 14, 32)   0           ['conv2d_1[1][0]']               \n",
            "                                                                                                  \n",
            " embedding (Embedding)          (None, 100, 100)     4000000     ['input_1[0][0]']                \n",
            "                                                                                                  \n",
            " dropout (Dropout)              (None, 14, 14, 32)   0           ['max_pooling2d[1][0]']          \n",
            "                                                                                                  \n",
            " bi_gru_0 (Bidirectional)       (None, 100, 200)     121200      ['embedding[1][0]']              \n",
            "                                                                                                  \n",
            " conv2d_2 (Conv2D)              (None, 13, 13, 16)   2064        ['dropout[1][0]']                \n",
            "                                                                                                  \n",
            " bi_gru_1 (Bidirectional)       [(None, 100, 200),   181200      ['bi_gru_0[1][0]']               \n",
            "                                 (None, 100),                                                     \n",
            "                                 (None, 100)]                                                     \n",
            "                                                                                                  \n",
            " max_pooling2d_1 (MaxPooling2D)  (None, 6, 6, 16)    0           ['conv2d_2[1][0]']               \n",
            "                                                                                                  \n",
            " concatenate (Concatenate)      (None, 200)          0           ['bi_gru_1[1][1]',               \n",
            "                                                                  'bi_gru_1[1][2]']               \n",
            "                                                                                                  \n",
            " dropout_1 (Dropout)            (None, 6, 6, 16)     0           ['max_pooling2d_1[1][0]']        \n",
            "                                                                                                  \n",
            " attention (Attention)          ((None, 200),        40301       ['bi_gru_1[1][0]',               \n",
            "                                 (None, 100, 1))                  'concatenate[1][0]']            \n",
            "                                                                                                  \n",
            " flatten (Flatten)              (None, 576)          0           ['dropout_1[1][0]']              \n",
            "                                                                                                  \n",
            " tf.concat (TFOpLambda)         (None, 776)          0           ['attention[1][0]',              \n",
            "                                                                  'flatten[1][0]']                \n",
            "                                                                                                  \n",
            " price (Dense)                  (None, 3)            2331        ['tf.concat[1][0]']              \n",
            "                                                                                                  \n",
            " type (Dense)                   (None, 24)           18648       ['tf.concat[1][0]']              \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 4,383,216\n",
            "Trainable params: 4,383,216\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "Epoch 1/10\n",
            "153/153 [==============================] - 36s 159ms/step - loss: 4.6119 - price_loss: 0.9948 - type_loss: 1.2571 - price_sparse_categorical_accuracy: 0.5746 - type_sparse_categorical_accuracy: 0.7367 - val_loss: 1.9325 - val_price_loss: 0.8900 - val_type_loss: 1.1646 - val_price_sparse_categorical_accuracy: 0.5307 - val_type_sparse_categorical_accuracy: 0.7486\n",
            "Epoch 2/10\n",
            "153/153 [==============================] - 22s 144ms/step - loss: 1.5138 - price_loss: 0.8771 - type_loss: 1.1019 - price_sparse_categorical_accuracy: 0.5877 - type_sparse_categorical_accuracy: 0.7586 - val_loss: 1.3373 - val_price_loss: 0.8486 - val_type_loss: 1.2451 - val_price_sparse_categorical_accuracy: 0.6372 - val_type_sparse_categorical_accuracy: 0.7486\n",
            "Epoch 3/10\n",
            "153/153 [==============================] - 22s 144ms/step - loss: 1.1824 - price_loss: 0.8551 - type_loss: 1.0593 - price_sparse_categorical_accuracy: 0.6092 - type_sparse_categorical_accuracy: 0.7584 - val_loss: 1.1320 - val_price_loss: 0.8307 - val_type_loss: 1.0538 - val_price_sparse_categorical_accuracy: 0.6364 - val_type_sparse_categorical_accuracy: 0.7486\n",
            "Epoch 4/10\n",
            "153/153 [==============================] - 22s 144ms/step - loss: 1.0814 - price_loss: 0.8478 - type_loss: 0.9663 - price_sparse_categorical_accuracy: 0.6113 - type_sparse_categorical_accuracy: 0.7572 - val_loss: 1.0670 - val_price_loss: 0.7997 - val_type_loss: 1.0004 - val_price_sparse_categorical_accuracy: 0.6364 - val_type_sparse_categorical_accuracy: 0.7445\n",
            "Epoch 5/10\n",
            "153/153 [==============================] - 22s 144ms/step - loss: 1.0415 - price_loss: 0.8460 - type_loss: 0.9119 - price_sparse_categorical_accuracy: 0.6113 - type_sparse_categorical_accuracy: 0.7596 - val_loss: 1.1081 - val_price_loss: 0.8134 - val_type_loss: 1.0675 - val_price_sparse_categorical_accuracy: 0.6323 - val_type_sparse_categorical_accuracy: 0.7117\n",
            "Epoch 6/10\n",
            "153/153 [==============================] - 22s 143ms/step - loss: 1.0115 - price_loss: 0.8425 - type_loss: 0.8674 - price_sparse_categorical_accuracy: 0.6053 - type_sparse_categorical_accuracy: 0.7600 - val_loss: 1.0825 - val_price_loss: 0.8439 - val_type_loss: 1.0209 - val_price_sparse_categorical_accuracy: 0.6151 - val_type_sparse_categorical_accuracy: 0.7281\n",
            "Epoch 7/10\n",
            "153/153 [==============================] - 22s 141ms/step - loss: 0.9900 - price_loss: 0.8403 - type_loss: 0.8399 - price_sparse_categorical_accuracy: 0.6076 - type_sparse_categorical_accuracy: 0.7680 - val_loss: 1.0451 - val_price_loss: 0.8002 - val_type_loss: 0.9908 - val_price_sparse_categorical_accuracy: 0.6347 - val_type_sparse_categorical_accuracy: 0.7346\n",
            "Epoch 8/10\n",
            "153/153 [==============================] - 22s 141ms/step - loss: 0.9718 - price_loss: 0.8368 - type_loss: 0.8051 - price_sparse_categorical_accuracy: 0.6123 - type_sparse_categorical_accuracy: 0.7734 - val_loss: 1.0691 - val_price_loss: 0.8299 - val_type_loss: 0.9998 - val_price_sparse_categorical_accuracy: 0.6093 - val_type_sparse_categorical_accuracy: 0.7297\n",
            "Epoch 9/10\n",
            "153/153 [==============================] - 22s 141ms/step - loss: 0.9673 - price_loss: 0.8407 - type_loss: 0.7861 - price_sparse_categorical_accuracy: 0.6088 - type_sparse_categorical_accuracy: 0.7793 - val_loss: 1.0615 - val_price_loss: 0.7929 - val_type_loss: 1.0355 - val_price_sparse_categorical_accuracy: 0.6323 - val_type_sparse_categorical_accuracy: 0.7387\n",
            "Epoch 10/10\n",
            "153/153 [==============================] - 22s 142ms/step - loss: 0.9492 - price_loss: 0.8320 - type_loss: 0.7577 - price_sparse_categorical_accuracy: 0.6172 - type_sparse_categorical_accuracy: 0.7889 - val_loss: 1.0558 - val_price_loss: 0.7990 - val_type_loss: 1.0127 - val_price_sparse_categorical_accuracy: 0.6462 - val_type_sparse_categorical_accuracy: 0.7355\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "44361c1f263f4514856db1be5183a05b",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "  0%|          | 0/7360 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c0jB9d_v6-HS"
      },
      "source": [
        "### **End of Trials**\n",
        "\n",
        "Epoch 9/10<br> - 22s 141ms/step<br> - loss: 0.9673<br> - price_loss: 0.8407<br> - type_loss: 0.7861<br> - price_sparse_categorical_accuracy: 0.6088<br> - type_sparse_categorical_accuracy: 0.7793<br> - val_loss: 1.0615<br> - val_price_loss: 0.7929<br> - val_type_loss: 1.0355<br> - val_price_sparse_categorical_accuracy: 0.6323<br> - val_type_sparse_categorical_accuracy: 0.7387\n",
        "\n",
        "Model does not appear to have improved and there is overfitting. It's likely that there is a need for better text and image preprocessing, such as converting all text to the same language, to improve the score. More regularization and/or dropout layers could be used to mitigate the overfitting."
      ]
    }
  ]
}